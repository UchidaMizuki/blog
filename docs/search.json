[
  {
    "objectID": "posts/2024/01/relational-data-models-with-r's-dm.html",
    "href": "posts/2024/01/relational-data-models-with-r's-dm.html",
    "title": "Rのdmパッケージでデータ前処理の質を高めよう",
    "section": "",
    "text": "データ分析に要する時間のうち，8割は前処理に費やされているといわれています．前処理は，その後のデータ分析の質を左右しますから，前処理の質の向上は非常に重要です．一方で，前処理に膨大な時間を要するということは，作業ミスが起こる確率もそれだけ高くなるということを意味しています．\n一般的な（データ構造に対する）前処理には，データフレームの”抽出”・”集約”・”結合”がありますが，なかでも”結合”は，コードが長くなりやすく，作業ミスが起こりやすい作業であると思われます．また，分析で必要となるデータフレームが1つにまとまっていることは稀ですから，データフレームの結合は特に頻出する処理でもあります．\nデータフレームの”結合”で起こりがちな典型的なミスとして，以下のようなものがあります1．\n\n結合するデータフレームがMECE（「漏れなく・ダブりなく」）の状態でない\n結合のためのキーを取り違える，または，データ形式が異なる\n\nもしも，これまでデータフレームの結合において，何らかの作業ミスや”ヒヤリ・ハット”を経験したことがあるのであれば，それらを放置せず何らかのパッケージに頼るほうが得策かもしれません．また，仮に作業ミスがなかったとしても，私たちは過去の作業が正しかったかについて疑心暗鬼になりがちです2．\nこの記事では，データフレームの”結合”における作業ミスや疑心暗鬼の解決策として有力なRのdmパッケージを紹介します．"
  },
  {
    "objectID": "posts/2024/01/relational-data-models-with-r's-dm.html#データ前処理はなぜ重要か",
    "href": "posts/2024/01/relational-data-models-with-r's-dm.html#データ前処理はなぜ重要か",
    "title": "Rのdmパッケージでデータ前処理の質を高めよう",
    "section": "",
    "text": "データ分析に要する時間のうち，8割は前処理に費やされているといわれています．前処理は，その後のデータ分析の質を左右しますから，前処理の質の向上は非常に重要です．一方で，前処理に膨大な時間を要するということは，作業ミスが起こる確率もそれだけ高くなるということを意味しています．\n一般的な（データ構造に対する）前処理には，データフレームの”抽出”・”集約”・”結合”がありますが，なかでも”結合”は，コードが長くなりやすく，作業ミスが起こりやすい作業であると思われます．また，分析で必要となるデータフレームが1つにまとまっていることは稀ですから，データフレームの結合は特に頻出する処理でもあります．\nデータフレームの”結合”で起こりがちな典型的なミスとして，以下のようなものがあります1．\n\n結合するデータフレームがMECE（「漏れなく・ダブりなく」）の状態でない\n結合のためのキーを取り違える，または，データ形式が異なる\n\nもしも，これまでデータフレームの結合において，何らかの作業ミスや”ヒヤリ・ハット”を経験したことがあるのであれば，それらを放置せず何らかのパッケージに頼るほうが得策かもしれません．また，仮に作業ミスがなかったとしても，私たちは過去の作業が正しかったかについて疑心暗鬼になりがちです2．\nこの記事では，データフレームの”結合”における作業ミスや疑心暗鬼の解決策として有力なRのdmパッケージを紹介します．"
  },
  {
    "objectID": "posts/2024/01/relational-data-models-with-r's-dm.html#dmによるリレーショナルデータモデル",
    "href": "posts/2024/01/relational-data-models-with-r's-dm.html#dmによるリレーショナルデータモデル",
    "title": "Rのdmパッケージでデータ前処理の質を高めよう",
    "section": "dmによるリレーショナルデータモデル",
    "text": "dmによるリレーショナルデータモデル\ndmの提供するリレーショナルデータモデルは，複数のデータ間の関係性を私たちの代わりに管理してくれます．\nこの記事では，repurrrsiveパッケージで提供されているStarWarsのデータセットを使って，dmの提供するリレーショナルデータモデルを構築します．あらかじめ，tidyverse，dm，repurrrsiveの3つのパッケージを読み込んでおきましょう．\n\nlibrary(tidyverse)\nlibrary(dm)\nlibrary(repurrrsive)\n\nrepurrrsiveで提供されているStarWarsのデータセットには，以下のようなものが含まれています3．\n\n\nrepurrrsiveで提供されているStarWarsのデータセット\ndata(package = \"repurrrsive\") |&gt; \n  chuck(\"results\") |&gt; \n  as_tibble() |&gt; \n  filter(str_starts(Item, \"sw_\")) |&gt; \n  pull(Item)\n\n\n[1] \"sw_films\"     \"sw_people\"    \"sw_planets\"   \"sw_species\"   \"sw_starships\"\n[6] \"sw_vehicles\" \n\n\nここでは，データ分析の題材として，複数のデータ間の関係を扱う必要のある，以下の2つの分析内容を考えてみましょう．正直に言うと，2つの分析の難易度はほぼ同じですが，基礎編では，主にdmのリレーショナルデータモデルの構築する方法を，応用編では，リレーショナルデータモデルの拡張したりキーを検証したりする方法について説明します．\n\n基礎編：StarWars作品の登場人物の故郷の惑星の構成比を調べる\n\nsw_films・sw_people・sw_planetsの3つのデータが必要\n\n応用編：StarWars作品の登場人物の種族の構成比を調べる\n\nsw_films・sw_people・sw_speciesの3つのデータが必要\n\n\n\n1. 基礎編：StarWars作品の登場人物の故郷の惑星の構成比を調べる\n基礎編として，リレーショナルデータモデルを構築して，StarWars作品の登場人物の故郷の惑星の構成比を調べてみましょう．この分析を行うために，以下のように3つのデータフレームfilms・people・planetsを準備しておきます4．ここでは，分析をシンプルにするため，必要なデータのみをselectしました5．\n\nfilms &lt;- tibble(film = sw_films) |&gt; \n  unnest_wider(film) |&gt; \n  select(url, title, characters)\npeople &lt;- tibble(person = sw_people) |&gt;\n  unnest_wider(person) |&gt; \n  select(url, name, homeworld, species)\nplanets &lt;- tibble(planet = sw_planets) |&gt;\n  unnest_wider(planet) |&gt; \n  select(url, name)\n\n\nfilms\n\n\n  \n\n\npeople\n\n\n  \n\n\nplanets\n\n\n  \n\n\n\n準備したデータフレームを確認すると，各データフレームのurl列がキーとして用いられていることがわかりますので，データフレーム間の関係は以下のようにまとめることができます6．特に，1つの映画作品には複数の登場人物が登場することが一般的ですので，filmsのcharacters列が登場人物のリストになっていることに注意が必要です．そのため，このままでは，filmsのcharacters列をpeopleのurl列と対応付けることができません．\n\n\n\n\n\nflowchart TB\n  films.characters --&gt; people.url\n  people.homeworld --&gt; planets.url\n  subgraph films\n    films.url[url]\n    films.title[title]\n    films.characters[List of characters] \n  end\n  subgraph people\n    people.url[url]\n    people.name[name]\n    people.homeworld[homeworld]\n  end\n  subgraph planets\n    planets.url[url]\n    planets.name[name]\n  end\n\n\n\n\n\n\nそこで，filmsとpeopleの関係，すなわち，どの作品にどの登場人物が登場するかを表すデータfilms_x_charactersを新たに作成することを考えます7．films_x_charactersを介すことで，データ間の関係を以下のようにまとめることができます．\n\n\n\n\n\nflowchart TB\n  films_x_characters.url --&gt; films.url\n  films_x_characters.characters ---&gt; people.url\n  people.homeworld --&gt; planets.url\n  subgraph films_x_characters\n    films_x_characters.url[url]\n    films_x_characters.characters[characters]\n  end\n  subgraph films\n    films.url[url]\n    films.title[title]\n  end\n  subgraph people\n    people.url[url]\n    people.name[name]\n    people.homeworld[homeworld]\n  end\n  subgraph planets\n    planets.url[url]\n    planets.name[name]\n  end\n\n\n\n\n\n\nそれでは，上のイメージに従って，実際にリレーショナルデータモデルを構築してみましょう．まず，filmsのurl・characters列を使ってfilms_x_charactersを作成します．ついでにfilmsから不要となったcharacters列を削除しておきます．\n\n# Create films_x_characters and remove characters column from films\nfilms_x_characters &lt;- films |&gt; \n  select(url, characters) |&gt; \n  unnest_longer(characters)\nfilms &lt;- films |&gt; \n  select(!characters)\n\nfilms_x_characters\n\n\n  \n\n\n\n最後に，dm()に準備したfilms・people・planets・films_x_charactersを渡した後，主キー（primary keys）と外部キー（foreign keys）を追加することで，リレーショナルデータモデルを構築することができます．\ndmでは，主キーをdm_add_pk()で8，外部キーをdm_add_fk()で設定します9．\n\ndm_starwars_1 &lt;- dm(films, people, planets, films_x_characters) |&gt; \n  \n  # 1. Add primary keys\n  dm_add_pk(films, url) |&gt;\n  dm_add_pk(people, url) |&gt;\n  dm_add_pk(planets, url) |&gt;\n  dm_add_pk(films_x_characters, c(url, characters)) |&gt;\n  \n  # 2. Add foreign keys\n  dm_add_fk(films_x_characters, url, films) |&gt; \n  dm_add_fk(films_x_characters, characters, people) |&gt;\n  dm_add_fk(people, homeworld, planets) \n\ndm_starwars_1\n\n── Metadata ────────────────────────────────────────────────────────────────────\nTables: `films`, `people`, `planets`, `films_x_characters`\nColumns: 10\nPrimary keys: 4\nForeign keys: 3\n\n\ndm_draw()を用いて，リレーショナルデータモデルを描画することもできます．描画してみると，上のイメージと同様の関係が構築されていることがわかります．\n\ndm_draw(dm_starwars_1)\n\n\n\n\n\n以下のようにdm_flatten_to_tbl()を用いることで，films_x_charactersデータにfilms・people・planetsデータを結合したデータフレームを作成することができます10．この際，異なるデータ間で同名の列名が存在する場合には，データ名に応じて自動的に列名が変更されます．このように，リレーショナルデータモデルが私たちの代わりにデータ間の関係を管理してくれるおかげで，他のデータ間との関係に基づいて自動的にデータフレームを結合することができます．\n\ndata_films_x_characters_1 &lt;- dm_starwars_1 |&gt; \n  dm_flatten_to_tbl(films_x_characters,\n                    .recursive = TRUE) \n\nRenaming ambiguous columns: %&gt;%\n  dm_rename(people, name.people = name) %&gt;%\n  dm_rename(planets, name.planets = name)\n\ndata_films_x_characters_1\n\n\n  \n\n\n\n作成したdata_films_x_characters_1を使うことで，以下のように，登場人物の故郷の惑星の構成比をグラフにすることができます． このグラフへの考察はひとまず措くとして，リレーショナルデータモデルを用いることでデータフレームの結合を自動化できることが確認できました．\nしかし，上のような分析であれば，left_join()を用いてデータフレームを結合することも簡単で， あまりリレーショナルデータモデルを用いるメリットが感じられないかもしれません． そこで応用編では，リレーショナルデータモデルが本領を発揮する，より込み入った状況を考えてみます．\n\n\n登場人物の故郷の惑星の構成比のグラフ\ndata_films_x_characters_1 |&gt; \n  mutate(name.planets = fct_lump_n(name.planets, 7,\n                                   ties.method = \"first\") |&gt; \n           fct_relevel(\"Other\", \n                       after = Inf)) |&gt; \n  count(title, name.planets) |&gt; \n  mutate(prop = n / sum(n),\n         .by = title,\n         .keep = \"unused\") |&gt; \n  ggplot(aes(fct_rev(title), prop,\n             fill = name.planets)) +\n  geom_col(position = position_stack(reverse = TRUE)) +\n  geom_text(aes(label = if_else(prop &lt; 5e-2, \n                                \"\",\n                                scales::label_percent(accuracy = 1)(prop))),\n            position = position_stack(vjust = 0.5,\n                                      reverse = TRUE)) +\n  scale_x_discrete(\"作品タイトル\") +\n  scale_y_continuous(\"登場人物の故郷の惑星の構成比\",\n                     labels = scales::percent) +\n  scale_fill_brewer(\"惑星名\",\n                    palette = \"Set2\") +\n  coord_flip() +\n  theme(legend.position = \"bottom\") +\n  guides(fill = guide_legend(nrow = 2,\n                             byrow = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n2. 応用編：StarWars作品の登場人物の種族の構成比を調べる\n応用編では，StarWars作品の登場人物の種族の構成比を調べてみます． この分析の難易度は基礎編とさほど変わりませんが，通常，扱うデータが増えるとコードが煩雑化しやすいため，リレーショナルデータモデルのメリットが大きくなります． さらに，リレーショナルデータモデルのメリットには，以下のようなものもあります．\n\n既存のリレーショナルデータモデルに新たなデータを追加することが可能\n結合のためのキーの整合性を確認することが可能\n\nあらかじめ，この分析で必要となるspeciesデータを準備しておきます．\n\nspecies &lt;- tibble(species = sw_species) |&gt; \n  unnest_wider(species) |&gt; \n  select(url, name)\n\nspecies\n\n\n  \n\n\n\ndmでは，dm()を用いて，リレーショナルデータモデルに新たにデータを追加することができます． ここでは，dm_starwars_1にspeciesデータを追加して，dm_starwars_2を作成してみましょう． dm_draw()を用いることで，モデルが更新されたことがわかります．\n\ndm_starwars_2 &lt;- dm_starwars_1 |&gt; \n  dm(species) |&gt; \n  dm_add_pk(species, url) |&gt; \n  dm_add_fk(people, species, species)\n\ndm_draw(dm_starwars_2)\n\n\n\n\n\n次に，結合のためのキーの整合性を確認してみましょう．こうした検証は，dm_examine_constraints()を用いることで可能です． ここでは，上でありがちなミスとして挙げた，2種類のミスを起こしたモデルを作成して，dm_examine_constraints()の挙動を確認してみましょう． ここで，dm_starwars_2_wrong_dataは，speciesデータの1行目が削除されたデータで，データがMECE（「漏れなく・ダブりなく」）でないものです． また，dm_starwars_2_wrong_pkは，speciesデータの主キーを取り違えたものです．\n\ndm_starwars_2_wrong_data &lt;- dm_starwars_1 |&gt; \n  dm(species = species |&gt; \n       slice(-1)) |&gt; \n  dm_add_pk(species, url) |&gt; \n  dm_add_fk(people, species, species)\n\ndm_starwars_2_wrong_pk &lt;- dm_starwars_1 |&gt; \n  dm(species) |&gt; \n  dm_add_pk(species, name) |&gt; \n  dm_add_fk(people, species, species)\n\ndm_examine_constraints()の結果を見てみましょう． 正しいモデルであるdm_starwars_2では，ℹ All constraints satisfied.というメッセージが表示され，モデルのキーが整合していることがわかります． 一方で，dm_starwars_2_wrong_dataとdm_starwars_2_wrong_pkでは，! Unsatisfied constraints:というメッセージが表示されています． これは，speciesデータの主キーに含まれるはずのデータが含まれていないことに起因します． このように，dm_examine_constraints()を用いることで，簡単にモデルのキーの整合性を確認することができます．\n\nprint(dm_examine_constraints(dm_starwars_2))\n\nℹ All constraints satisfied.\n\nprint(dm_examine_constraints(dm_starwars_2_wrong_data))\n\n! Unsatisfied constraints:\n\n\n• Table `people`: foreign key `species` into table `species`: values of `people$species` not in `species$url`: http://swapi.co/api/species/5/ (1)\n\nprint(dm_examine_constraints(dm_starwars_2_wrong_pk))\n\n! Unsatisfied constraints:\n\n\n• Table `people`: foreign key `species` into table `species`: values of `people$species` not in `species$name`: http://swapi.co/api/species/1/ (35), http://swapi.co/api/species/2/ (5), http://swapi.co/api/species/12/ (3), http://swapi.co/api/species/15/ (2), http://swapi.co/api/species/22/ (2), …\n\n\n以上のように，dmでは，dm()でリレーショナルデータモデルに新たなデータを追加したり，dm_examine_constraints()で結合のためのキーの整合性を確認したりすることができることがわかりました． 最後に，作成したリレーショナルデータモデルdm_starwars_2を用いて，StarWars作品の登場人物の種族の構成比をグラフ化したものが以下の図です．ここでも，考察は割愛します．\n\n\n登場人物の故郷の種族の構成比のグラフ\ndm_starwars_2 |&gt; \n  dm_flatten_to_tbl(films_x_characters,\n                    .recursive = TRUE) |&gt; \n  mutate(name.species = name.species |&gt; \n           fct_na_value_to_level(\"Other\") |&gt; \n           fct_lump_n(7,\n                      ties.method = \"first\") |&gt; \n           fct_relevel(\"Other\", \n                       after = Inf)) |&gt; \n  count(title, name.species) |&gt; \n  mutate(prop = n / sum(n),\n         .by = title,\n         .keep = \"unused\") |&gt; \n  ggplot(aes(fct_rev(title), prop,\n             fill = name.species)) +\n  geom_col(position = position_stack(reverse = TRUE)) +\n  geom_text(aes(label = if_else(prop &lt; 5e-2, \n                                \"\",\n                                scales::label_percent(accuracy = 1)(prop))),\n            position = position_stack(vjust = 0.5,\n                                      reverse = TRUE)) +\n  scale_x_discrete(\"作品タイトル\") +\n  scale_y_continuous(\"登場人物の故郷の種族の構成比\",\n                     labels = scales::percent) +\n  scale_fill_brewer(\"種族名\",\n                    palette = \"Set2\") +\n  coord_flip() +\n  theme(legend.position = \"bottom\") +\n  guides(fill = guide_legend(nrow = 2,\n                             byrow = TRUE))"
  },
  {
    "objectID": "posts/2024/01/relational-data-models-with-r's-dm.html#まとめ",
    "href": "posts/2024/01/relational-data-models-with-r's-dm.html#まとめ",
    "title": "Rのdmパッケージでデータ前処理の質を高めよう",
    "section": "まとめ",
    "text": "まとめ\nこの記事では，dmを使ってリレーショナルデータモデルを構築する方法を紹介しました． dmを使って，ひとたびリレーショナルデータモデルを構築してしまえば， データ間の関係を自ら管理する必要がなくなり，dm_flatten_to_tbl()でデータの結合を自動的に行うことができます． それ以外にも，dmでは，dm()によるモデル拡張やdm_examine_constraints()結合のためのキーの整合性の確認など， データ前処理の質を高めるための便利な機能が提供されています．"
  },
  {
    "objectID": "posts/2024/01/relational-data-models-with-r's-dm.html#参考文献",
    "href": "posts/2024/01/relational-data-models-with-r's-dm.html#参考文献",
    "title": "Rのdmパッケージでデータ前処理の質を高めよう",
    "section": "参考文献",
    "text": "参考文献\n\ndmパッケージのサイト\n前処理大全［データ分析のためのSQL/R/Python実践テクニック］"
  },
  {
    "objectID": "posts/2024/01/relational-data-models-with-r's-dm.html#footnotes",
    "href": "posts/2024/01/relational-data-models-with-r's-dm.html#footnotes",
    "title": "Rのdmパッケージでデータ前処理の質を高めよう",
    "section": "脚注",
    "text": "脚注\n\n\n幸いなことに，最近のdplyrでは，結合先のデータの”ダブり”に対して警告が出るようになりました．↩︎\nその作業を行ったのが過去の自分であっても他の誰かであっても，完全に作業が正しかったという自信は持てないものです．↩︎\nrepurrrsiveのエクスポートするデータのうち，名前がsw_で始まるデータがStarWarsに関するもので，sw_以降の部分がデータの内容を表しています．↩︎\nrepurrrsiveのデータはリスト形式で提供されているため，こちらの記事を参考にデータフレームに変換しました．↩︎\nここでは，sw_peopleのspecies列は不要ですが，次の分析で使用するため選択しておきます．↩︎\nここでは，データフレーム間の関係を図示するために，mermaidを使用しました．↩︎\n作品と登場人物には，明確な上下関係はありませんので，characters_x_filmsという名称でも構いません．↩︎\nfilms・people・planetsについては，url列が主キーとなり，films_x_charactersについては，url・characters列の2列の組合せが主キーとなります．↩︎\n上のイメージの矢印に従って，films_x_charactersのurl・characters列を，それぞれfilms・peopleのurl列に対応付けます．さらに，peopleのhomeworld列をplanetsのurl列に対応付けます．↩︎\ndmでは，各データを”テーブル”と呼びます．↩︎"
  },
  {
    "objectID": "posts/2023/09/circle-area-by-numerical-integration-in-r.html",
    "href": "posts/2023/09/circle-area-by-numerical-integration-in-r.html",
    "title": "Rの数値積分で円の面積を求める",
    "section": "",
    "text": "最近，R statsパッケージ1のintegrate() 関数で一次元関数の数値積分ができることを知りました．そこで，この記事では，こちらの記事を参考に積分で円の面積を計算してみました．"
  },
  {
    "objectID": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#はじめに",
    "href": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#はじめに",
    "title": "Rの数値積分で円の面積を求める",
    "section": "",
    "text": "最近，R statsパッケージ1のintegrate() 関数で一次元関数の数値積分ができることを知りました．そこで，この記事では，こちらの記事を参考に積分で円の面積を計算してみました．"
  },
  {
    "objectID": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#半円を描く関数",
    "href": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#半円を描く関数",
    "title": "Rの数値積分で円の面積を求める",
    "section": "半円を描く関数",
    "text": "半円を描く関数\n半径\\(r\\)の半円を描く関数は 式 1 と表せます．Rで書くとsemicircle() 関数のようになります．\n\\[\ny = \\sqrt{r^2 - x^2} \\qquad (-r \\le x \\le r)\n\\tag{1}\\]\n\nsemicircle &lt;- function(x, radius) {\n  sqrt(radius^2 - x^2)\n}\n\n実装したsemicircle() 関数で半径\\(r = 5\\)の半円を描いてみましょう．\n\nradius &lt;- 5\ncurve(semicircle(x, radius), -radius, radius,\n      asp = 1) # アスペクト比を1:1にする"
  },
  {
    "objectID": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#数値積分で円の面積を求める",
    "href": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#数値積分で円の面積を求める",
    "title": "Rの数値積分で円の面積を求める",
    "section": "数値積分で円の面積を求める",
    "text": "数値積分で円の面積を求める\n次に，stats::integrate() 関数を用いて，さきほど書いたsemicircle() を数値積分してみましょう．半径\\(r = 5\\)の場合，積分すると半円の面積\\(\\frac{1}{2}\\pi r^2\\)とほぼ等しくなることが確認できます．\n\n# 半径を5とする\nradius &lt;- 5\nintegrate(semicircle, -radius, radius, # -radiusからradiusまでの範囲で積分する\n          radius = radius)\n\n39.26991 with absolute error &lt; 2.5e-08\n\npi * 5^2 / 2\n\n[1] 39.26991\n\n\nそのため，円の面積を近似的に求めるcircle_area_approx()が以下のように書けます（数値積分の結果は，stats::integrate() 関数の戻り値のvalue に格納されています）．\n\ncircle_area_approx &lt;- function(radius) {\n  out &lt;- integrate(semicircle, -radius, radius,\n                   radius = radius)\n  out$value * 2\n}\n\ncircle_area_approx(5)\n\n[1] 78.53982\n\n\n最後に，半径\\(1 \\le r \\le 10\\)の範囲で近似値circle_area_approx()と理論値circle_area_true()（\\(\\pi r^2\\)）を比較してみましょう．\n計算の結果，近似値と理論値で円の面積がほぼ等しいことが確認できました．\n\ncircle_area_true &lt;- function(radius) {\n  pi * radius ^ 2\n}\n\ndata &lt;- data.frame(radius = 1:10)\ndata$circle_area_approx &lt;- sapply(data$radius, circle_area_approx)\ndata$circle_area_true &lt;- sapply(data$radius, circle_area_true)\nknitr::kable(data)\n\n\n\n\nradius\ncircle_area_approx\ncircle_area_true\n\n\n\n\n1\n3.141593\n3.141593\n\n\n2\n12.566371\n12.566371\n\n\n3\n28.274334\n28.274334\n\n\n4\n50.265482\n50.265482\n\n\n5\n78.539816\n78.539816\n\n\n6\n113.097335\n113.097335\n\n\n7\n153.938040\n153.938040\n\n\n8\n201.061930\n201.061930\n\n\n9\n254.469005\n254.469005\n\n\n10\n314.159265\n314.159265"
  },
  {
    "objectID": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#おわりに",
    "href": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#おわりに",
    "title": "Rの数値積分で円の面積を求める",
    "section": "おわりに",
    "text": "おわりに\nstats::integrate() 関数を使えば，簡単に一次元関数の数値積分ができることがわかりました．\n\n注意点\nstats::integrate() 関数では，\\(-\\infty \\le x \\le \\infty\\)の範囲での数値積分も可能ですが，\\(10^{-6} \\le x \\le 10^6\\)のような大きな値を代入すると数値積分が適切に行われませんのでご注意ください．\n\n# OK\nintegrate(dnorm, -Inf, Inf)\n\n1 with absolute error &lt; 9.4e-05\n\n# NG\nintegrate(dnorm, -1e6, 1e6)\n\n0 with absolute error &lt; 0"
  },
  {
    "objectID": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#footnotes",
    "href": "posts/2023/09/circle-area-by-numerical-integration-in-r.html#footnotes",
    "title": "Rの数値積分で円の面積を求める",
    "section": "脚注",
    "text": "脚注\n\n\nstatsパッケージは，Rにデフォルトで入っているパッケージの一つです．↩︎"
  },
  {
    "objectID": "posts/2023/04/quantify-vote-disparity-between-generations.html",
    "href": "posts/2023/04/quantify-vote-disparity-between-generations.html",
    "title": "世代間の「1票の格差」を定量化してみる",
    "section": "",
    "text": "ちょうど選挙シーズンですので1，オープンデータを使って，しばしば問題になる「1票の格差」を定量化してみたいと思います．\n「1票の格差」は，通常，議員1人あたりの有権者数が地域（選挙区）によって異なる（≒議員1人を当選させるために必要な票数が地域によって異なる）ことを指します．たとえば，2022年の参議院選挙では，「1票の格差」が最大で3.03倍であったとされています2．\n現在，日本の都市部と地方は以下の表のような関係にあるとされ，「1票の格差」が「地方で新幹線が整備される一方で東京の通勤ラッシュが解消されない」といった経済効率性の低下などを引き起こすことが問題視されています3．\n\n\n\n\n\n\n\n\n地域\nお金の流れ（地方交付税など）\n政治的平等（「1票の格差」）\n\n\n\n\n都市部\n地方にお金を「支払う」\n「1票の価値」が軽く\n都市部「冷遇」\n\n\n地方\n都市部からお金を「受け取る」\n「1票の価値」が重く\n地方「優遇」\n\n\n\n一方で，今後，東京一極集中などにより地方の社会課題が一層深刻になることが予想されます．そのため，「1票の価値」を完全に等しくすれば，むしろ地方の「冷遇」につながるといった懸念もあります．\nこのように，「1票の格差」の是正は，決して簡単な道のりとはいえませんが，引き続き是正に向けた取り組みを進めていく必要があるといえるでしょう．\n\n\nここまで紹介した地域間の「1票の格差」に加えて，世代間にも「1票の格差」が存在するといわれています4．これは，少子高齢化により，若年層の有権者数に対して高齢者層の有権者数が多くなることにより引き起こされるものです5．\nさきほど示した都市・地方部の関係と同様に，若年層と高齢者層は，以下の表のような関係にあると考えられます．地方における人口減少・人手不足が深刻となった最近になってようやく，国は，少子化対策を国の最重要課題に位置づけましたが，これまで，こうした若年層向けの政策が十分に行われなかった6のは世代間の「1票の格差」の影響によるものかもしれません．\n\n\n\n\n\n\n\n\n世代\nお金の流れ（社会保障費など）\n政治的平等（「1票の格差」）\n\n\n\n\n若年層\n高齢者層にお金を「支払う」\n「1票の価値」が軽く\n若年層「冷遇」\n\n\n高齢者層\n若年層からお金を「受け取る」\n「1票の価値」が重く\n高齢者層「優遇」"
  },
  {
    "objectID": "posts/2023/04/quantify-vote-disparity-between-generations.html#票の格差とは",
    "href": "posts/2023/04/quantify-vote-disparity-between-generations.html#票の格差とは",
    "title": "世代間の「1票の格差」を定量化してみる",
    "section": "",
    "text": "ちょうど選挙シーズンですので1，オープンデータを使って，しばしば問題になる「1票の格差」を定量化してみたいと思います．\n「1票の格差」は，通常，議員1人あたりの有権者数が地域（選挙区）によって異なる（≒議員1人を当選させるために必要な票数が地域によって異なる）ことを指します．たとえば，2022年の参議院選挙では，「1票の格差」が最大で3.03倍であったとされています2．\n現在，日本の都市部と地方は以下の表のような関係にあるとされ，「1票の格差」が「地方で新幹線が整備される一方で東京の通勤ラッシュが解消されない」といった経済効率性の低下などを引き起こすことが問題視されています3．\n\n\n\n\n\n\n\n\n地域\nお金の流れ（地方交付税など）\n政治的平等（「1票の格差」）\n\n\n\n\n都市部\n地方にお金を「支払う」\n「1票の価値」が軽く\n都市部「冷遇」\n\n\n地方\n都市部からお金を「受け取る」\n「1票の価値」が重く\n地方「優遇」\n\n\n\n一方で，今後，東京一極集中などにより地方の社会課題が一層深刻になることが予想されます．そのため，「1票の価値」を完全に等しくすれば，むしろ地方の「冷遇」につながるといった懸念もあります．\nこのように，「1票の格差」の是正は，決して簡単な道のりとはいえませんが，引き続き是正に向けた取り組みを進めていく必要があるといえるでしょう．\n\n\nここまで紹介した地域間の「1票の格差」に加えて，世代間にも「1票の格差」が存在するといわれています4．これは，少子高齢化により，若年層の有権者数に対して高齢者層の有権者数が多くなることにより引き起こされるものです5．\nさきほど示した都市・地方部の関係と同様に，若年層と高齢者層は，以下の表のような関係にあると考えられます．地方における人口減少・人手不足が深刻となった最近になってようやく，国は，少子化対策を国の最重要課題に位置づけましたが，これまで，こうした若年層向けの政策が十分に行われなかった6のは世代間の「1票の格差」の影響によるものかもしれません．\n\n\n\n\n\n\n\n\n世代\nお金の流れ（社会保障費など）\n政治的平等（「1票の格差」）\n\n\n\n\n若年層\n高齢者層にお金を「支払う」\n「1票の価値」が軽く\n若年層「冷遇」\n\n\n高齢者層\n若年層からお金を「受け取る」\n「1票の価値」が重く\n高齢者層「優遇」"
  },
  {
    "objectID": "posts/2023/04/quantify-vote-disparity-between-generations.html#世代間の1票の格差を定量化してみる",
    "href": "posts/2023/04/quantify-vote-disparity-between-generations.html#世代間の1票の格差を定量化してみる",
    "title": "世代間の「1票の格差」を定量化してみる",
    "section": "世代間の「1票の格差」を定量化してみる",
    "text": "世代間の「1票の格差」を定量化してみる\n地域間の「1票の格差」は，（都市部基準で）約〇倍といった定量化がなされることが一般的ですが，世代間の「1票の格差」については，これまで，あまり定量化されていないようです．\n単純な定量化の方法としては，年齢層別の人口を何らかの基準人口で割るといったものが考えられますが，このような方法では，加齢により亡くなる方がいることが考慮されず，「人口が少ないので100歳以上の1票の価値が軽い」といった評価をすることになってしまいます．\nそこで，2020年国勢調査人口と2020年生命表を用いて，世代間の「1票の格差」を定量化してみようと思います．生命表とは，「ある期間における死亡状況が今後変化しないとの仮定のもとで各年齢の者が1年以内に死亡する確率などの指標を表したもの」です7．\n以下で示す世代間の「1票の格差」は，あくまで，オープンデータに基づく簡易的な試算であることにご注意ください．\n\n使用データについて\n今回は，以下の表に示すデータを使用します．ここで，表中の定常人口（nLx）とは，「一定の出生・（生命表上の）死亡率のもとで得られる年齢階級別人口」のことです8．\nデータ入手・整形方法については，下に折りたたまれているコードも参考にしてください．\n\n\n\n内容\n出典\n入手方法\n\n\n\n\n男女・年齢別人口\n2020年国勢調査\njpstatパッケージで\ne-Stat APIを使用\n\n\n男女・年齢別定常人口（nLx）\n2020年生命表\nURLからエクセルファイルを\nダウンロード\n\n\n\n\n\nパッケージのローディングなど\nlibrary(tidyverse)\nlibrary(fs)\nlibrary(arrow)\nlibrary(readxl)\nlibrary(jpstat)\n\ntheme_set(theme_light())\n\ndir_create(\"quantify-vote-disparity-between-generations\")\n\n\n\n\n2020年国勢調査人口のダウンロード・データ整形\n# jpstatパッケージを使って2020年国勢調査データをダウンロードしています\nif (!file_exists(\"quantify-vote-disparity-between-generations/pop_2020.parquet\")) {\n  # 注意: jpstatパッケージはe-Stat APIを利用するためAPIキーが必要です\n  census_2020 &lt;- estat(keyring::key_get(\"estat-api\"),\n                       \"https://www.e-stat.go.jp/dbview?sid=0003445139\")\n\n  pop_2020 &lt;- census_2020 |&gt;\n    activate(tab) |&gt;\n    select() |&gt;\n  \n    activate(cat01) |&gt;\n    filter(name == \"うち日本人\") |&gt;\n    select() |&gt;\n  \n    activate(cat02) |&gt;\n    rekey(\"sex\") |&gt;\n    filter(name %in% c(\"男\", \"女\")) |&gt;\n    select(name) |&gt;\n  \n    activate(cat03) |&gt;\n    rekey(\"age\") |&gt;\n    select(name) |&gt;\n  \n    activate(area) |&gt;\n    filter(name == \"全国\") |&gt;\n    select() |&gt;\n  \n    activate(time) |&gt;\n    select() |&gt;\n  \n    collect(n = \"pop\")\n  \n  pop_2020 &lt;- pop_2020 |&gt; \n    filter(str_detect(age_name, \"^\\\\d+歳$\") | age_name == \"100歳以上\") |&gt; \n    mutate(sex = as_factor(sex_name),\n           age = case_when(str_detect(age_name, \"^\\\\d+歳$\") ~ age_name |&gt; \n                             str_extract(\"\\\\d+\"),\n                           age_name == \"100歳以上\" ~ \"100--Inf\") |&gt; \n             as_factor(),\n           pop = parse_number(pop),\n           .keep = \"unused\") |&gt; \n    relocate(sex, age, pop)\n  \n  write_parquet(pop_2020, \"quantify-vote-disparity-between-generations/pop_2020.parquet\") \n}\n\n\n\n\n2020年生命表のダウンロード\n# 第23回生命表（男）\nfile_lifetable_male_2020 &lt;- \"quantify-vote-disparity-between-generations/lifetable_male_2020.xlsx\"\nif (!file_exists(file_lifetable_male_2020)) {\n  curl::curl_download(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000032173232&fileKind=0\", file_lifetable_male_2020) \n}\n\n# 第23回生命表（女）\nfile_lifetable_female_2020 &lt;- \"quantify-vote-disparity-between-generations/lifetable_female_2020.xlsx\"\nif (!file_exists(file_lifetable_female_2020)) {\n  curl::curl_download(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000032173233&fileKind=0\", file_lifetable_female_2020)\n}\n\n\n\n\n2020年生命表の定常人口のデータ整形\ncol_names_lifetable &lt;- read_excel(file_lifetable_male_2020, \n                        range = \"B3:J5\",\n                        col_names = as.character(1:9)) |&gt; \n  t() |&gt; \n  as_tibble(.name_repair = \\(x) c(\"col_name_1\", \"col_name_2\", \"col_name_3\")) |&gt; \n  unite(\"col_name\", starts_with(\"col_name\"),\n        na.rm = TRUE) |&gt; \n  mutate(col_name = col_name |&gt; \n           str_remove_all(\"\\\\s\")) |&gt; \n  pull(col_name)\n\nrange_lifetable &lt;- \"B6:J127\"\n\nlifetable_male_2020 &lt;- read_excel(file_lifetable_male_2020,\n                                  range = range_lifetable,\n                                  col_names = col_names_lifetable)\n\nlifetable_female_2020 &lt;- read_excel(file_lifetable_female_2020,\n                                    range = range_lifetable,\n                                    col_names = col_names_lifetable)\n\nstatic_pop_2020 &lt;- list(男 = lifetable_male_2020,\n                        女 = lifetable_female_2020) |&gt; \n  bind_rows(.id = \"sex\") |&gt; \n  rename(age = 年齢_x,\n         static_pop = 定常人口_nLx_人) |&gt; \n  select(sex, age, static_pop) |&gt; \n  filter(str_ends(age, \"年\")) |&gt; \n  mutate(sex = as_factor(sex),\n         age = age |&gt; \n           str_extract(\"^\\\\d+\") |&gt; \n           parse_integer(),\n         # 100歳以上はまとめる\n         age = if_else(age &gt;= 100,\n                       \"100--Inf\",\n                       as.character(age)) |&gt; \n           as_factor()) |&gt; \n  summarise(static_pop = sum(static_pop),\n            .by = c(sex, age))\n\nwrite_parquet(static_pop_2020, \"quantify-vote-disparity-between-generations/static_pop_2020.parquet\")\n\n\n\n\n国勢調査の人口・生命表の定常人口の「人口ピラミッド」の比較\n入手・整形したデータを使って人口ピラミッドを作成してみましょう．以下のグラフは，2020年国勢調査の人口に生命表の定常人口（赤線）を重ねたものです9．ただし，定常人口は，0歳定常人口が2020年国勢調査の0歳人口と等しくなるように基準化しています10．また，100歳以上の人口・定常人口については，100歳に集計して表示しています．\n\n\n人口ピラミッドの図示\n# 100歳以上を数値100で置き換える\nas_integer_age &lt;- function(age) {\n  if_else(age == \"100--Inf\",\n          100,\n          parse_integer(as.character(age),\n                        na = \"100--Inf\"))\n}\n\npop_2020 &lt;- read_parquet(\"quantify-vote-disparity-between-generations/pop_2020.parquet\") |&gt; \n  mutate(age = as_integer_age(age))\nstatic_pop_2020 &lt;- read_parquet(\"quantify-vote-disparity-between-generations/static_pop_2020.parquet\") |&gt; \n  mutate(age = as_integer_age(age))\n\nratio_pop_static_pop &lt;- static_pop_2020 |&gt; \n  filter(age == 0) |&gt; \n  select(!age) |&gt; \n  left_join(pop_2020 |&gt; \n              filter(age == 0) |&gt; \n              select(!age),\n            by = join_by(sex)) |&gt; \n  mutate(ratio_pop_static_pop = pop / static_pop,\n         .keep = \"unused\")\n\nstatic_pop_2020 &lt;- static_pop_2020 |&gt; \n  left_join(ratio_pop_static_pop,\n            by = join_by(sex)) |&gt; \n  mutate(pop = static_pop * ratio_pop_static_pop,\n         .keep = \"unused\")\n\npop_2020 |&gt;\n  mutate(pop = if_else(sex == \"男\",\n                       -pop,\n                       pop)) |&gt; \n  ggplot(aes(age, pop,\n             fill = sex)) +\n  geom_col() +\n  geom_line(data = static_pop_2020 |&gt; \n               mutate(pop = if_else(sex == \"男\",\n                                    -pop,\n                                    pop)),\n            aes(group = sex,\n                color = \"定常人口\\n（参考値）\")) +\n  scale_x_continuous(\"年齢\",\n                     breaks = seq(0, 100, 10)) +\n  scale_y_continuous(\"人口［千人］\",\n                     labels = \\(x) {\n                       scales::label_comma(scale = 1e-3)(abs(x))\n                     }) +\n  scale_fill_manual(\"性別\",\n                    values = c(男 = \"cornflowerblue\",\n                               女 = \"lightcoral\")) +\n  scale_color_manual(NULL,\n                     values = c(`定常人口\\n（参考値）` = \"red\")) +\n  coord_flip() +\n  guides(fill = guide_legend(order = 1),\n         color = guide_legend(order = 2))\n\n\n\n\n\n\n\n\n\n2020年の人口ピラミッドより，70歳前半および40歳後半において人口のピークがあることがわかります．これらは，それぞれ「団塊世代」「団塊ジュニア」と呼ばれる世代にあたります11．一方で，若年層の人口は，「団塊世代」「団塊ジュニア」の人口を大きく下回っていることがわかり，近年の少子化の深刻さがみてとれます．\n\n\n「人口ピラミッド」に基づく世代間の「1票の格差」の定量化\n赤線の定常人口（参考値）に対する国勢調査人口の比を用いて，世代間の「1票の格差」を定量化してみましょう．\n以下のグラフは，選挙権を有する18歳以上を対象に，おおよそ10歳間隔で世代間の「1票の格差」を定量化したものです．ただし，ここでは18～29歳の「1票の価値」を1として基準化しています．\nグラフより，40代～60代の1票は，18～29歳の約1.5倍，70代の1票は，18～29歳の約1.7倍の価値を有するという試算が得られました．また，（生命表の性質によるものかもしれませんが）「団塊世代」「団塊ジュニア」ではない30代や80代以上の1票の価値は，40代～60代・70代と比べると低くなっていることがわかりました．\n\n\n世代間の「1票の格差」の定量化\nvote_disparity &lt;- pop_2020 |&gt; \n  left_join(static_pop_2020 |&gt; \n              rename(static_pop = pop),\n            by = join_by(sex, age)) |&gt;\n  filter(age &gt;= 18) |&gt; \n  mutate(ageclass = case_when(between(age, 18, 29) ~ \"18～29歳\",\n                              between(age, 30, 39) ~ \"30代\",\n                              between(age, 40, 49) ~ \"40代\",\n                              between(age, 50, 59) ~ \"50代\",\n                              between(age, 60, 69) ~ \"60代\",\n                              between(age, 70, 79) ~ \"70代\",\n                              between(age, 80, 89) ~ \"80代\",\n                              90 &lt;= age ~ \"90代以上\")) |&gt; \n  summarise(across(c(pop, static_pop),\n                   sum),\n            .by = ageclass) |&gt; \n  mutate(vote_disparity = pop / static_pop,\n         .keep = \"unused\")\n\nvote_disparity &lt;- vote_disparity |&gt; \n  bind_cols(vote_disparity |&gt; \n              filter(ageclass == \"18～29歳\") |&gt; \n              select(!ageclass) |&gt; \n              rename(vote_disparity_18to29 = vote_disparity)) |&gt; \n  mutate(vote_disparity = vote_disparity / vote_disparity_18to29,\n         .keep = \"unused\")\n\nplot_vote_disparity &lt;- vote_disparity |&gt; \n  ggplot(aes(ageclass, vote_disparity)) +\n  geom_col(fill = \"lightblue\") +\n  geom_text(aes(label = scales::label_comma(accuracy = 1e-2)(vote_disparity)),\n            y = 1,\n            vjust = -0.5,\n            color = \"red\") +\n  geom_hline(yintercept = 1,\n             color = \"red\",\n             linetype = \"dashed\") +\n  scale_x_discrete(\"年齢層\") +\n  scale_y_continuous(\"世代間の「1票の格差」（18～29歳基準）\")\n\n\nggsave(\"quantify-vote-disparity-between-generations/plot_vote_disparity.png\",\n       plot = plot_vote_disparity)\n\nplot_vote_disparity"
  },
  {
    "objectID": "posts/2023/04/quantify-vote-disparity-between-generations.html#まとめ",
    "href": "posts/2023/04/quantify-vote-disparity-between-generations.html#まとめ",
    "title": "世代間の「1票の格差」を定量化してみる",
    "section": "まとめ",
    "text": "まとめ\nオープンデータである国勢調査と生命表を用いて，世代間の「1票の格差」を定量化してみました．\n実は，若者の投票率の低さも世代間の「1票の格差」の大きな要因となっているといわれています．今後は，世代間の「1票の格差」に対する議論を深めつつ，若者の投票率が上がるような魅力的な政策を多く打ち出していくことが必要であると考えられます．"
  },
  {
    "objectID": "posts/2023/04/quantify-vote-disparity-between-generations.html#footnotes",
    "href": "posts/2023/04/quantify-vote-disparity-between-generations.html#footnotes",
    "title": "世代間の「1票の格差」を定量化してみる",
    "section": "脚注",
    "text": "脚注\n\n\n地方公共団体の議員・長を決める第20回統一地方選挙が，2023年4月9日（日）と2023年4月23日（日）に行われました．↩︎\n参院選 “1票の格差 最大3.03倍” 最高裁が大法廷で審理へ↩︎\n「一票の格差」の問題点とは？↩︎\n世代間における「1票の格差」↩︎\nこういった考え方は，東京一極集中に伴う都市部への人口集積のもとで，「1票の価値」を完全に等しくすれば，むしろ地方「冷遇」につながるといった考え方とも類似します．↩︎\n選択する未来 （4）少子化対策↩︎\n生命表について↩︎\n参考資料１生命表諸関数の定義↩︎\n赤線で示した定常人口（参考値）は，2020年の0歳の男女が，死亡率一定の仮定のもとで，ある年齢で何人生存しているかを表しています．↩︎\n0歳人口の男女比は，おおよそ105：100となっています．↩︎\n「人口ピラミッド」から日本の未来が見えてくる！？～高齢化と「団塊世代」、少子化と「団塊ジュニア」～↩︎"
  },
  {
    "objectID": "posts/2023/01/create-an-animation-of-a-population-pyramid-in-r.html",
    "href": "posts/2023/01/create-an-animation-of-a-population-pyramid-in-r.html",
    "title": "Rで人口ピラミッドのアニメーションを作る",
    "section": "",
    "text": "国立社会保障・人口問題研究所（社人研）の公開している人口ピラミッドの推移アニメーションを参考に，以下のようなアニメーションをRのggplot2で作成してみました．"
  },
  {
    "objectID": "posts/2023/01/create-an-animation-of-a-population-pyramid-in-r.html#この記事について",
    "href": "posts/2023/01/create-an-animation-of-a-population-pyramid-in-r.html#この記事について",
    "title": "Rで人口ピラミッドのアニメーションを作る",
    "section": "",
    "text": "国立社会保障・人口問題研究所（社人研）の公開している人口ピラミッドの推移アニメーションを参考に，以下のようなアニメーションをRのggplot2で作成してみました．"
  },
  {
    "objectID": "posts/2023/01/create-an-animation-of-a-population-pyramid-in-r.html#国勢調査の時系列データの取得",
    "href": "posts/2023/01/create-an-animation-of-a-population-pyramid-in-r.html#国勢調査の時系列データの取得",
    "title": "Rで人口ピラミッドのアニメーションを作る",
    "section": "国勢調査の時系列データの取得",
    "text": "国勢調査の時系列データの取得\nまず，e-Statで公開されている国勢調査の男女・5最階級別人口の時系列データをRのjpstatパッケージを用いて取得します．\njpstatパッケージからe-Stat APIを用いるためには，アプリケーションID（appId）を取得する必要があります．\n\nlibrary(tidyverse)\nlibrary(jpstat)\n\n\n# ご自身のappIdに置き換えてください\nSys.setenv(ESTAT_API_KEY = \"Your appId\")\n\n\ncensus &lt;- estat(statsDataId = \"https://www.e-stat.go.jp/dbview?sid=0003410380\")\n\npop &lt;- census |&gt; \n  activate(tab) |&gt; \n  filter(name == \"人口\") |&gt; \n  select() |&gt; \n  \n  # 性別の抽出\n  activate(cat01) |&gt; \n  rekey(\"sex\") |&gt; \n  filter(name %in% c(\"男\", \"女\")) |&gt; \n  select(name) |&gt; \n  \n  # 年齢階級の抽出\n  activate(cat02) |&gt; \n  rekey(\"ageclass\") |&gt; \n  filter(str_detect(name, \"^\\\\d+～\\\\d+歳$\") |\n           name == \"85歳以上\" |\n           name == \"110歳以上\") |&gt; \n  select(name) |&gt; \n  \n  # 年の抽出\n  activate(time) |&gt; \n  rekey(\"year\") |&gt; \n  filter(str_detect(name, \"^\\\\d+年$\")) |&gt; \n  select(name) |&gt; \n  \n  # e-Statデータの取得\n  collect(n = \"pop\") |&gt; \n  \n  rename_with(~ .x |&gt; \n                str_remove(\"_name$\")) |&gt; \n  mutate(sex = as_factor(sex),\n         year = parse_number(year),\n         \n         # 各年齢階級の最低年齢を取得\n         age_from = ageclass |&gt; \n           str_extract(\"^\\\\d+\") |&gt; \n           stringi::stri_trans_nfkc() |&gt; \n           as.integer(),\n         \n         # 最高の年齢階級を「85歳以上」とする\n         ageclass = case_when(age_from &gt;= 85 ~ \"85歳以上\",\n                              TRUE ~ ageclass) |&gt; \n           as_factor(),\n         \n         # 年齢層を追加\n         agegroup = case_when(between(age_from, 0, 10) ~ \"年少人口\",\n                              between(age_from, 15, 60) ~ \"生産年齢人口\",\n                              between(age_from, 65, 70) ~ \"前期老年人口\",\n                              age_from &gt;= 75 ~ \"後期老年人口\") |&gt; \n           as_factor(),\n         pop = parse_number(pop)) |&gt; \n  \n  # 「85歳以上」人口を集計\n  group_by(year, sex, ageclass, agegroup) |&gt; \n  summarise(pop = sum(pop),\n            .groups = \"drop\")\n\nThe total number of data is 796.\n\nknitr::kable(head(pop))\n\n\n\n\nyear\nsex\nageclass\nagegroup\npop\n\n\n\n\n1920\n男\n０～４歳\n年少人口\n3752627\n\n\n1920\n男\n５～９歳\n年少人口\n3467156\n\n\n1920\n男\n10～14歳\n年少人口\n3089225\n\n\n1920\n男\n15～19歳\n生産年齢人口\n2749022\n\n\n1920\n男\n20～24歳\n生産年齢人口\n2316479\n\n\n1920\n男\n25～29歳\n生産年齢人口\n2008005"
  },
  {
    "objectID": "posts/2023/01/create-an-animation-of-a-population-pyramid-in-r.html#人口ピラミッドアニメーションの作成",
    "href": "posts/2023/01/create-an-animation-of-a-population-pyramid-in-r.html#人口ピラミッドアニメーションの作成",
    "title": "Rで人口ピラミッドのアニメーションを作る",
    "section": "人口ピラミッドアニメーションの作成",
    "text": "人口ピラミッドアニメーションの作成\nRのgganimateパッケージを用いることでggplot2のグラフをアニメーションにすることができます．\n\nlibrary(gganimate)\n\nWarning: package 'gganimate' was built under R version 4.3.1\n\n# 年齢層を表示するためのデータ\nagegroup &lt;- pop |&gt; \n  group_by(sex, agegroup) |&gt;\n  summarise(ageclass = mean(as.integer(ageclass)),\n            .groups = \"drop\") |&gt; \n  mutate(hjust = case_when(sex == \"男\" ~ 1.25,\n                           sex == \"女\" ~ -0.25))\n\npoppyramid &lt;- pop |&gt; \n  \n  # 人口ピラミッドを作成するため男性人口をマイナスに変換\n  mutate(pop = if_else(sex == \"男\", -pop, pop)) |&gt; \n  \n  ggplot(aes(ageclass, pop,\n             group = sex,\n             fill = agegroup)) +\n  geom_col(show.legend = FALSE) +\n  geom_text(data = agegroup,\n            aes(label = agegroup,\n                hjust = hjust),\n            y = 0) +\n  scale_x_discrete(NULL) +\n  scale_y_continuous(\"人口［千人］\",\n                     \n                     # ラベルを絶対値・千人単位に変換\n                     labels = purrr::compose(scales::label_comma(scale = 1e-3), abs)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  coord_flip() +\n  facet_wrap(~ sex,\n             scales = \"free_x\") +\n  labs(title = \"{frame_time %/% 5 * 5}年\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  \n  # アニメーションに変換\n  transition_time(year)\n\n# 幅・高さを変更\nanimate(poppyramid, \n        width = 800,\n        height = 600,\n        res = 150,\n        renderer = gifski_renderer())"
  },
  {
    "objectID": "posts/2022/06/use-parquet-instead-of-csv-ja.html",
    "href": "posts/2022/06/use-parquet-instead-of-csv-ja.html",
    "title": "CSVの代わりにParquetを使ってみよう",
    "section": "",
    "text": "本記事では，CSVの代替として有望かつビッグデータ分析にも適しているParquetを紹介します．\nさて，データフレーム（Data Frames）は，データ分析において最も基本的なデータ構造の1つです．Rのtibble・dplyrやPythonのpandasなどのデータフレーム操作のためのパッケージを使えば，これまでExcelなどの表計算ソフトで行っていたデータ分析をさらに効率的に行うことができます．\nこのようにデータ分析ツールが充実している一方で，データの保存にはExcelなどとの互換性が高いCSVが未だに広く使われています．しかし，CSVは，必ずしもデータ分析に適したファイル形式とは言えません．そこで，CSVの代替として使われることが多くなっているParquetをCSVと比較してみましょう．"
  },
  {
    "objectID": "posts/2022/06/use-parquet-instead-of-csv-ja.html#サンプルデータの準備",
    "href": "posts/2022/06/use-parquet-instead-of-csv-ja.html#サンプルデータの準備",
    "title": "CSVの代わりにParquetを使ってみよう",
    "section": "サンプルデータの準備",
    "text": "サンプルデータの準備\nCSVとParquetを比較するため，まずは，データ分析にありがちなサンプルデータを用意しましょう．今回は，tidyrパッケージで提供されているwho （世界保健機関（WHO）結核データ）からサンプルデータをつくります．\n近年，データ分析では，整然データ（tidy data）の概念が普及しています．tidy dataは，個々の変数が1つの列をなし，個々の観測（値）が1つの行をなすようなデータです．\nそれでは，whoは，tidy dataと言えるでしょうか？whoには，\"new_sp_m014\" ～\"newrel_f65\" といったたくさんの列が存在しますが，これらには，1列ごとに，診断結果（spやsel）・性別（mとf）・年齢階級（014や65）といった複数の変数が含まれています．そのため，who は，tidy dataでないといえます．そこで，こちらに従ってtidy dataであるwho_longerに変形します．\nデータ分析では，who よりtidy dataであるwho_longer のほうを分析が行いやすい一方で，行数はwho（約7,000行）よりwho_longer （約400,000行）のほうが約50倍多いことがわかります．そのため，tidy dataであるwho_longerのようなデータをテキストファイルであるCSVで保存すると容量が増大してしまいます．\nこのように，tidy dataはデータ分析に適している一方で，CSVのようなテキストファイルでの保存に適していないことがわかります．しかし，このようなデータ保存上の課題はParquetを使えば解決することができます．\nここで，tidy dataでないwho とtidy dataであるwho_longer を見比べてみましょう．\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\nlibrary(fs)\n\n\n\nコード\nlevels_gender &lt;- c(\"f\", \"m\")\nlevels_age &lt;- c(\"014\", \"1524\", \"2534\", \"3544\", \"4554\", \"5564\", \"65\")\n\nwho_longer &lt;- who |&gt; \n  pivot_longer(cols = new_sp_m014:newrel_f65,\n               names_to = c(\"diagnosis\", \"gender\", \"age\"), \n               names_pattern = \"new_?(.*)_(.)(.*)\",\n               names_transform = list(gender = ~ .x |&gt; \n                                        readr::parse_factor(levels = levels_gender),\n                                      age = ~ .x |&gt; \n                                        readr::parse_factor(levels = levels_age,\n                                                            ordered = TRUE)),\n               values_to = \"count\")\n\n\n\n# データ整形前\nprint(who, n = 5)\n\n# A tibble: 7,240 × 60\n  country   iso2  iso3   year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544\n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Afghanis… AF    AFG    1980          NA           NA           NA           NA\n2 Afghanis… AF    AFG    1981          NA           NA           NA           NA\n3 Afghanis… AF    AFG    1982          NA           NA           NA           NA\n4 Afghanis… AF    AFG    1983          NA           NA           NA           NA\n5 Afghanis… AF    AFG    1984          NA           NA           NA           NA\n# ℹ 7,235 more rows\n# ℹ 52 more variables: new_sp_m4554 &lt;dbl&gt;, new_sp_m5564 &lt;dbl&gt;,\n#   new_sp_m65 &lt;dbl&gt;, new_sp_f014 &lt;dbl&gt;, new_sp_f1524 &lt;dbl&gt;,\n#   new_sp_f2534 &lt;dbl&gt;, new_sp_f3544 &lt;dbl&gt;, new_sp_f4554 &lt;dbl&gt;,\n#   new_sp_f5564 &lt;dbl&gt;, new_sp_f65 &lt;dbl&gt;, new_sn_m014 &lt;dbl&gt;,\n#   new_sn_m1524 &lt;dbl&gt;, new_sn_m2534 &lt;dbl&gt;, new_sn_m3544 &lt;dbl&gt;,\n#   new_sn_m4554 &lt;dbl&gt;, new_sn_m5564 &lt;dbl&gt;, new_sn_m65 &lt;dbl&gt;, …\n\n# データ整形後\nprint(who_longer, n = 5)\n\n# A tibble: 405,440 × 8\n  country     iso2  iso3   year diagnosis gender age   count\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;fct&gt;  &lt;ord&gt; &lt;dbl&gt;\n1 Afghanistan AF    AFG    1980 sp        m      014      NA\n2 Afghanistan AF    AFG    1980 sp        m      1524     NA\n3 Afghanistan AF    AFG    1980 sp        m      2534     NA\n4 Afghanistan AF    AFG    1980 sp        m      3544     NA\n5 Afghanistan AF    AFG    1980 sp        m      4554     NA\n# ℹ 405,435 more rows"
  },
  {
    "objectID": "posts/2022/06/use-parquet-instead-of-csv-ja.html#csvparquetの保存方法",
    "href": "posts/2022/06/use-parquet-instead-of-csv-ja.html#csvparquetの保存方法",
    "title": "CSVの代わりにParquetを使ってみよう",
    "section": "CSV・Parquetの保存方法",
    "text": "CSV・Parquetの保存方法\nRでは，write_csv() でCSVを保存できます．同様に，arrowパッケージのwrite_parquet() でParquetを保存することができます．who_longerをCSVとParquetで保存してみましょう．\nCSVとParquetでは，どちらも簡単にデータ保存ができることがわかります．\n\nlibrary(arrow)\n\nWarning: package 'arrow' was built under R version 4.2.3\n\n# CSVを保存\nwrite_csv(who_longer, \"who_longer.csv\")\n\n# Parquetを保存\nwrite_parquet(who_longer, \"who_longer.parquet\")"
  },
  {
    "objectID": "posts/2022/06/use-parquet-instead-of-csv-ja.html#parquetのメリットcsvとの比較",
    "href": "posts/2022/06/use-parquet-instead-of-csv-ja.html#parquetのメリットcsvとの比較",
    "title": "CSVの代わりにParquetを使ってみよう",
    "section": "Parquetのメリット・CSVとの比較",
    "text": "Parquetのメリット・CSVとの比較\nここからは，保存したwho_longer のCSV・Parquetファイルを比較して，CSVに対するParquetのメリットを紹介していきます．\n\nメリット1：CSVよりデータ容量が軽い\ntidy dataは行数が多くなるため，CSVでの保存に適しておらず，Parquetを使ったほうがよいことを既に述べました．\n実際に，who_longer のCSV・Parquetのデータ容量は，それぞれ，14.1 MBと154 KBとなり，ParquetはCSVの約1 %のデータ容量しかないことがわかります．\nどのようなケースでもこのようなデータ容量の削減が見込めるわけではありませんが，Parquetは列指向でデータ圧縮を行うため，Rなどでよく用いられるtidy dataの保存に適したデータ形式であるといえます．\n\n# CSV\nfile_size(\"who_longer.csv\")\n\n14.1M\n\n# Parquet\nfile_size(\"who_longer.parquet\")\n\n156K\n\nunits::set_units(file_size(\"who_longer.parquet\") / file_size(\"who_longer.csv\")) |&gt; \n  units::set_units(`%`)\n\n1.080502 [%]\n\n\n\n\nメリット2：CSVより読み込みが簡単\nwrite_csv()・write_parquet() でデータを書き込めるのと同様に，read_csv()・read_parquet() でCSV・Parquetデータを読み込むことができます．\nCSVはテキスト形式であるため，読み込み時にcol_typesで各列の型を指定する必要があります（デフォルトでは自動で型を推測）．\n一方，Parquetは，書き込み時に各列の型情報も保存されているため読み込み時に型を指定する必要がありません．\n\n# CSVの読み込み\nread_csv(\"who_longer.csv\",\n         col_types = cols(.default = \"c\",\n                          year = \"i\",\n                          count = \"i\"))\n\n# Parquetの読み込み\nread_parquet(\"who_longer.parquet\")\n\n\n\nメリット3：CSVよりビッグデータの読み込み・集計に適している\nCSVはビッグデータの保存に適しておらず，これまでは，ビッグデータの保存にはSQLを用いるなどの使い分けが必要でした．\nRでは，dplyr（dbplyr）・DBIなどのパッケージで簡単にSQLが使えますが，データベースへの接続・切断などが必要なSQLは，CSVと使い勝手が異なり，初学者にとってはハードルがあるかもしれません．\nまた，（ほとんどの？）SQLは行指向であるため，データの追加・更新・削除などに適していますが，データ分析に用いられるデータの保存・集計には列指向であるParquetのほうが適していると思われます．\nCSVファイルを用いてビッグデータを集計する場合には，一度，全データをメモリに移す必要があります．そのため，データの読み込みでメモリが逼迫するおそれがあります．\nParquetでは，読み込み時にas_data_frame = FALSEとすることで，SQLと同様にメモリにデータを移すことなくデータのフィルタリング・集計などが可能です．\nここでは，日本の年・症例別の患者数を計算してみましょう．dplyrのfilter() ・group_by() ・summarise() などを使って効率的にクエリを作成することができます．最後にcollect() を行えばデータフレームを出力することができます．\n\nread_parquet(\"who_longer.parquet\",\n             as_data_frame = FALSE) |&gt; \n  filter(country == \"Japan\",\n         !is.na(count)) |&gt; \n  group_by(country, year, diagnosis) |&gt; \n  summarise(count = sum(count),\n            .groups = \"drop\") |&gt; \n  collect()\n\n# A tibble: 33 × 4\n   country  year diagnosis count\n   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 Japan    1995 sp        14367\n 2 Japan    1996 sp        12867\n 3 Japan    1997 sp        13571\n 4 Japan    1998 sp        11935\n 5 Japan    2001 sp        11408\n 6 Japan    2002 sp        10807\n 7 Japan    2003 sp        10843\n 8 Japan    2004 sp        10471\n 9 Japan    1999 sp        12909\n10 Japan    2000 sp        11853\n# ℹ 23 more rows\n\n\n\n\nメリット4：複数のデータからなるデータセットを扱える\nParquetは列指向であるため，行指向であるSQLと違い，データの追加・更新・削除などに適していません．しかし，Parquetでは，複数のデータからなるデータセットの読み込みが簡単に行えるため，このようなデメリットを簡単に解決することができます．\nここでは，who_longerを年齢階級別に分割したParquetファイルを格納した\"who_longer_byage\" フォルダをデータセットのサンプルとして用いましょう．\nopen_dataset(\"who_longer_byage\") とすることで，複数のParquetファイルを含むにもかかわらず，さきほどと同様のデータ集計を簡単に行うことができます．\n\n\nコード\ndir_create(\"who_longer_byage\")\nwho_longer |&gt; \n  group_by(age) |&gt; \n  group_walk(~ .x |&gt; \n               write_parquet(str_glue(\"who_longer_byage/who_longer_{.y$age}.parquet\")),\n  .keep = TRUE)\n\n\n\nopen_dataset(\"who_longer_byage\") |&gt; \n  filter(country == \"Japan\",\n         !is.na(count)) |&gt; \n  group_by(country, year, diagnosis) |&gt; \n  summarise(count = sum(count),\n            .groups = \"drop\") |&gt; \n  collect()\n\n# A tibble: 33 × 4\n   country  year diagnosis count\n   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 Japan    1995 sp        14367\n 2 Japan    1996 sp        12867\n 3 Japan    1997 sp        13571\n 4 Japan    1998 sp        11935\n 5 Japan    2001 sp        11408\n 6 Japan    2002 sp        10807\n 7 Japan    2003 sp        10843\n 8 Japan    2004 sp        10471\n 9 Japan    2005 sp        10931\n10 Japan    2006 sp        10159\n# ℹ 23 more rows\n\n\n\n\nメリット5：R・Python間でのデータのやり取りに適している\nPythonのpandasパッケージはParquetの読み書きに対応しているため，Parquetは，R・Python間でのデータのやり取りにも適しています．\nRで作成した'who_longer.parquet' をpandasで読み込んでみましょう．\n\nimport pandas as pd\n\npd.read_parquet('who_longer.parquet')\n\n            country iso2 iso3    year diagnosis gender   age   count\n0       Afghanistan   AF  AFG  1980.0        sp      m   014     NaN\n1       Afghanistan   AF  AFG  1980.0        sp      m  1524     NaN\n2       Afghanistan   AF  AFG  1980.0        sp      m  2534     NaN\n3       Afghanistan   AF  AFG  1980.0        sp      m  3544     NaN\n4       Afghanistan   AF  AFG  1980.0        sp      m  4554     NaN\n...             ...  ...  ...     ...       ...    ...   ...     ...\n405435     Zimbabwe   ZW  ZWE  2013.0       rel      f  2534  4649.0\n405436     Zimbabwe   ZW  ZWE  2013.0       rel      f  3544  3526.0\n405437     Zimbabwe   ZW  ZWE  2013.0       rel      f  4554  1453.0\n405438     Zimbabwe   ZW  ZWE  2013.0       rel      f  5564   811.0\n405439     Zimbabwe   ZW  ZWE  2013.0       rel      f    65   725.0\n\n[405440 rows x 8 columns]"
  },
  {
    "objectID": "posts/2022/06/use-parquet-instead-of-csv-ja.html#まとめ",
    "href": "posts/2022/06/use-parquet-instead-of-csv-ja.html#まとめ",
    "title": "CSVの代わりにParquetを使ってみよう",
    "section": "まとめ",
    "text": "まとめ\nここまで，R・Pythonで利用可能なParquetのメリットを紹介しました．Parquetは，近年，データ分析で普及しているtidy dataの保存・集計に適しています．\nまた，最近では，地理データを扱えるsfパッケージのデータをparquetとして保存できるsfarrowなども登場しています．\nCSVの代わりにParquetを用いることでデータ分析がさらに簡単になることが期待されます．"
  },
  {
    "objectID": "posts/2022/05/ioanalysis-in-r-ja.html",
    "href": "posts/2022/05/ioanalysis-in-r-ja.html",
    "title": "Rで産業連関分析",
    "section": "",
    "text": "産業連関分析は，経済波及効果の算出に広く用いられている分析手法です． 日本では，国や都道府県によって，約5年に1度，産業連関表と呼ばれる統計データが 作成・公開されており，産業連関分析における基礎データとなっています．\nこれまで，産業連関分析では，Excel・VBAが用いられることが多かったようです．\n一方で，近年は，Python・R・Juliaなどのプログラミング言語の普及が進んでいます． これらのプログラミング言語は以下のような特長を持っています．\nそのため今後は，産業連関分析においても，これらのプログラミング言語の利用が 進むのではないかと思われます．\nここでは，Rを用いて産業連関分析を行います． Rでは近年，tidyverseなどモダンなデータ分析を行うためのパッケージが 多く提供されており，プログラミング初心者でも習得しやすい言語であると思います．\n産業連関表として，e-Statのデータベースで公開されている日本（国）の 2013年・13部門産業連関表を用います． ここで使用するデータは， こちら からダウンロードできます．"
  },
  {
    "objectID": "posts/2022/05/ioanalysis-in-r-ja.html#産業連関分析の基礎",
    "href": "posts/2022/05/ioanalysis-in-r-ja.html#産業連関分析の基礎",
    "title": "Rで産業連関分析",
    "section": "産業連関分析の基礎",
    "text": "産業連関分析の基礎\n産業連関分析は一般的に以下の流れに従って行われます．\n\n産業連関表の整形\n投入係数行列の算出\nレオンチェフ逆行列の算出\n経済波及効果の算出\n\nまず，産業連関分析において重要な投入係数行列・レオンチェフ逆行列・経済波及効果の算出方法について解説します．\n\n投入係数行列とは\n投入係数は，産業の「クッキングレシピ」として呼ばれており，産業\\(j\\)の生産物を1単位生産するのに必要な産業\\(i\\)の生産物の量を表すものです．具体的には，以下のように中間投入\\(x_{ij}\\)を生産額\\(X_j\\)（産出額）で割ることで算出できます．\n\\[\na_{ij}=\\frac{x_{ij}}{X_j}\n\\]\n産業連関分析では，「クッキングレシピ」に相当する投入係数\\(a_{ij}\\)に基づく生産額のバランス式（行方向）を連立方程式として解きます．そこで，以下のように，投入係数行列（通常，\\(A\\)と表される）と呼ばれる行列を作成することで，連立方程式が簡単に解けるようになります．\n\\[\nA = \\begin{pmatrix}\n  a_{11} & \\cdots & a_{1n} \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  a_{n1} & \\cdots & a_{nn} \\\\\n\\end{pmatrix}\n\\]\n\n\nレオンチェフ逆行列による経済波及効果の推計について\n生産額のバランス式（行方向）は，行列を用いて以下のように表せます．変数の意味は以下の表の通りです．\n\\[\nAX + F + E - M = X\n\\]\n\n\n\n変数\n意味\n\n\n\n\n\\(A\\)\n投入係数行列\n\n\n\\(X = (X_1, \\cdots, X_n) ^ \\top\\)\n生産額ベクトル\n\n\n\\(F = (F_1, \\cdots, F_n) ^ \\top\\)\n最終需要ベクトル\n\n\n\\(E = (E_1, \\cdots, E_n) ^ \\top\\)\n移輸出ベクトル\n\n\n\\(M = (M_1, \\cdots, M_n) ^ \\top\\)\n移輸入ベクトル\n\n\n\n経済波及効果の推計では，最終需要の変化が生産額に与える波及効果を算出します．\n特に，日本の産業連関表での経済波及効果の推計では，移輸入\\(M\\)の扱いに注意が必要です（これは，日本表の多くが競争移輸入型表と呼ばれる形式を採用しており，投入係数に移輸入分が含まれているためです）．\n最終需要による経済波及効果は，域内の生産額だけでなく域外からの移輸入を誘発すると考えられます．この効果を無視すると経済波及効果を過大評価することにつながるため，通常，投入係数から移輸入相当分を差し引くという処理が行われます．\n移輸入は域内需要におおよそ比例すると考えられるため，以下のように，移輸入係数\\(\\hat{M_i}\\)が算出できます．\n\\[\n\\hat{M_i} = \\frac{M_i}{\\sum_{j}a_{ij}X_j + F_i}\n\\]\nさらに，行列での計算に適した移輸入係数行列\\(\\hat{M}\\)が，以下のように定義されます．\n\\[\n\\hat{M} =\n\\begin{pmatrix}\n  \\hat{M_1} & & 0 \\\\\n  & \\ddots & \\\\\n  0 & & \\hat{M_n} \\\\\n\\end{pmatrix}\n\\]\n以上より，生産額のバランス式（行方向）は，移輸入係数行列\\(\\hat{M}\\)を用いて，以下のように変形されます．ただし，\\(I\\)は単位行列（対角成分が1，それ以外が0の正方行列）です．\n\\[\n\\begin{align}\n  AX + F + E - \\hat{M} (AX + F) &= X \\\\\n  (I - \\hat{M}) (AX + F) + E &= X\n\\end{align}\n\\]\n上のバランス式より，経済波及効果の算出式が，以下のように導出されます．ここで，\\(\\Delta X\\)，\\(\\Delta F\\)は，それぞれ，生産額の変化量，最終需要の変化量です．\n\\[\n\\begin{align}\n  X &= (I - \\hat{M}) (AX + F) + E \\\\\n  [I - (I - \\hat{M}) A] X &= (I - \\hat{M}) F + E \\\\\n  X &= [I - (I - \\hat{M}) A] ^ {-1} [(I - \\hat{M}) F + E] \\\\\n  \\Delta X &= [I - (I - \\hat{M}) A] ^ {-1} (I - \\hat{M}) \\Delta F\n\\end{align}\n\\]\n生産額の変化量\\(\\Delta X\\)の式の右辺の\\((I - \\hat{M}) \\Delta F\\)は，最終需要の変化量に自給率\\(I - \\hat{M}\\)を掛けた値となっています．\nまた，\\([I - (I - \\hat{M}) A] ^ {-1}\\)は，最終需要の変化による直接・間接の波及効果を表す行列であり（開放型または競争移輸入型の）レオンチェフ逆行列と呼ばれています．\n以上のように，最終需要の変化量\\(\\Delta F\\)から生産額の変化量\\(\\Delta X\\)を推計するというのが，最も一般的な産業連関分析の方法となっています．"
  },
  {
    "objectID": "posts/2022/05/ioanalysis-in-r-ja.html#rによる産業連関分析",
    "href": "posts/2022/05/ioanalysis-in-r-ja.html#rによる産業連関分析",
    "title": "Rで産業連関分析",
    "section": "Rによる産業連関分析",
    "text": "Rによる産業連関分析\n\n産業連関表の整形\nここでは， こちら からダウンロードできる日本の2011年の3部門表（iotable_3sector_2011_wider.csv）を使用します．\nこちらの表は，以下のように，日本の2011年の13部門表より作成したもので，単位は「百万円」です．\n\n13部門の産業分類を第1次・第2次・第3次産業に集計（注：「分類不明」を第3次産業に分類）\n付加価値部門を1部門に集計\n最終需要部門を域内最終需要（finaldemand）・輸出（export）・輸入（import）の3部門に集計\n\n産業連関表のデータ形式は，e-Statのデータベースで提供されている表などを除いて， 行に投入部門（input）・列に産出部門（output）を持つ「横長データ」であることが多いと思われます．\nここでも，以下の通り，まずは横長の産業連関表データを読み込みます．\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\niotable_wider &lt;- read_csv(\"iotable_3sector_2011_wider.csv\",\n                          col_types = cols(.default = \"c\")) |&gt; \n  \n  # input (投入) 列以外を数値に変換\n  mutate(across(!input, parse_number))\n\nknitr::kable(iotable_wider)\n\n\n\n\n\n\n\n\n\n\n\n\n\ninput\nindustry/01_primary\nindustry/02_secondary\nindustry/03_tertiary\nfinaldemand/04_finaldemand\nexport/05_export\nimport/06_import\n\n\n\n\nindustry/01_primary\n1456611\n7850628\n1373767\n3869875\n47890\n-2562809\n\n\nindustry/02_secondary\n2715710\n161897553\n62841827\n132924323\n54473273\n-71673715\n\n\nindustry/03_tertiary\n2025270\n66811645\n155796589\n352324555\n16423417\n-8921553\n\n\nvalueadded/04_valueadded\n5838371\n106619145\n364447740\nNA\nNA\nNA\n\n\n\n\n\nデータ分析においては，「横長データ」よりも，以下のような「縦長データ」のほうが， 分析しやすい場合が多くあります． ここでも，横長の産業連関表を「縦長データ」に変換します．\n\niotable &lt;- iotable_wider |&gt;\n  \n  # input (投入) 列を分類・名称に分割\n  separate(input, c(\"input_type\", \"input_name\"),\n           sep = \"/\") |&gt;\n  \n  # input (投入) と同様にoutput (産出) の分類・名称列を追加し縦長データに\n  pivot_longer(!c(input_type, input_name),\n               names_to = c(\"output_type\", \"output_name\"),\n               names_sep = \"/\",\n               values_to = \"value_M\") |&gt;\n  \n  # 数値が存在しない行を削除\n  drop_na(value_M)\n\nknitr::kable(iotable)\n\n\n\n\ninput_type\ninput_name\noutput_type\noutput_name\nvalue_M\n\n\n\n\nindustry\n01_primary\nindustry\n01_primary\n1456611\n\n\nindustry\n01_primary\nindustry\n02_secondary\n7850628\n\n\nindustry\n01_primary\nindustry\n03_tertiary\n1373767\n\n\nindustry\n01_primary\nfinaldemand\n04_finaldemand\n3869875\n\n\nindustry\n01_primary\nexport\n05_export\n47890\n\n\nindustry\n01_primary\nimport\n06_import\n-2562809\n\n\nindustry\n02_secondary\nindustry\n01_primary\n2715710\n\n\nindustry\n02_secondary\nindustry\n02_secondary\n161897553\n\n\nindustry\n02_secondary\nindustry\n03_tertiary\n62841827\n\n\nindustry\n02_secondary\nfinaldemand\n04_finaldemand\n132924323\n\n\nindustry\n02_secondary\nexport\n05_export\n54473273\n\n\nindustry\n02_secondary\nimport\n06_import\n-71673715\n\n\nindustry\n03_tertiary\nindustry\n01_primary\n2025270\n\n\nindustry\n03_tertiary\nindustry\n02_secondary\n66811645\n\n\nindustry\n03_tertiary\nindustry\n03_tertiary\n155796589\n\n\nindustry\n03_tertiary\nfinaldemand\n04_finaldemand\n352324555\n\n\nindustry\n03_tertiary\nexport\n05_export\n16423417\n\n\nindustry\n03_tertiary\nimport\n06_import\n-8921553\n\n\nvalueadded\n04_valueadded\nindustry\n01_primary\n5838371\n\n\nvalueadded\n04_valueadded\nindustry\n02_secondary\n106619145\n\n\nvalueadded\n04_valueadded\nindustry\n03_tertiary\n364447740\n\n\n\n\n\n上で構築した表データは，各行のフィルタリングなどが容易にできる一方で， 産業連関分析に用いられる行列計算などに適していません．\nそこで，表データの基本的な演算と行列計算を同時に行えるdibbleパッケージを用います． 以下のように，産業連関表をdibbleに変換します．\n\n# pak::pak(\"UchidaMizuki/dibble\")\nlibrary(dibble)\n\niotable &lt;- iotable |&gt;\n  dibble_by(input = c(input_type, input_name),\n            output = c(output_type, output_name),\n            \n            # \"_\"で列名を分割してinput (投入)・output (産出) 軸を設定\n            .names_sep = \"_\")\n\niotable\n\n# A dibble:   24 x 1\n# Dimensions: input [4], output [6]\n# Measures:   value_M\n   input$type $name        output$type $name            value_M\n   &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;       &lt;chr&gt;              &lt;dbl&gt;\n 1 industry   01_primary   industry    01_primary       1456611\n 2 industry   01_primary   industry    02_secondary     7850628\n 3 industry   01_primary   industry    03_tertiary      1373767\n 4 industry   01_primary   finaldemand 04_finaldemand   3869875\n 5 industry   01_primary   export      05_export          47890\n 6 industry   01_primary   import      06_import       -2562809\n 7 industry   02_secondary industry    01_primary       2715710\n 8 industry   02_secondary industry    02_secondary   161897553\n 9 industry   02_secondary industry    03_tertiary     62841827\n10 industry   02_secondary finaldemand 04_finaldemand 132924323\n# ℹ 14 more rows\n\n\n\n\n投入係数行列の算出\n産業の「クッキングレシピ」と呼ばれる投入係数行列\\(A\\)を以下のように中間投入を生産額で割って算出します．\n注：dibbleではブロードキャストが自動で行われますが，安全のため，ブロードキャストを行う際に，警告を発するように設計されています．そのため，broadcast()でブロードキャスト後の軸名c(\"input\", \"output\")を与えて警告が出ないようにする必要があります．\n\n# 生産額\ntotal_input &lt;- iotable |&gt;\n  filter(output$type == \"industry\") |&gt;\n  apply(\"output\", sum)\n\n# 中間投入\ninterindustry &lt;- iotable |&gt;\n  filter(input$type == \"industry\",\n         output$type == \"industry\")\n\n# 投入係数\ninputcoeff &lt;- broadcast(interindustry / total_input,\n                        c(\"input\", \"output\"))\n\ninputcoeff\n\n# A dibble:   9\n# Dimensions: input [3], output [3]\n  input$type $name        output$type $name              .\n  &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 industry   01_primary   industry    01_primary   0.121  \n2 industry   01_primary   industry    02_secondary 0.0229 \n3 industry   01_primary   industry    03_tertiary  0.00235\n4 industry   02_secondary industry    01_primary   0.226  \n5 industry   02_secondary industry    02_secondary 0.472  \n6 industry   02_secondary industry    03_tertiary  0.108  \n7 industry   03_tertiary  industry    01_primary   0.168  \n8 industry   03_tertiary  industry    02_secondary 0.195  \n9 industry   03_tertiary  industry    03_tertiary  0.267  \n\n\n\n\nレオンチェフ逆行列の算出\n経済波及効果を表すレオンチェフ逆行列は以下のように，移輸入係数と投入係数を用いて算出できます．\n注：solve()で逆行列を算出すると行列の軸名が入れ替わるため注意してください．\n\n# 域内需要\nlocaldemand &lt;- iotable |&gt;\n  filter(input$type == \"industry\",\n         !output$type %in% c(\"export\", \"import\")) |&gt;\n  apply(\"input\", sum)\n\n# (移) 輸入\nimport &lt;- iotable |&gt;\n  filter(input$type == \"industry\",\n         output$type == \"import\") |&gt;\n  apply(\"input\", sum)\n# 符号を正に\nimport &lt;- -import\n\n# (移) 輸入係数\nimportcoeff &lt;- import / localdemand\n\nI &lt;- eye(inputcoeff) # 単位行列\nM &lt;- importcoeff     # 移輸入係数ベクトル (broadcastが行われるため行列でなくてよい)\nA &lt;- inputcoeff      # 投入係数行列\n\n# レオンチェフ逆行列\nleontiefinv &lt;- broadcast(I - (1 - M) * A,\n                         c(\"input\", \"output\")) |&gt;\n  solve()\n\nleontiefinv\n\n# A dibble:   9\n# Dimensions: output [3], input [3]\n  output$type $name        input$type $name              .\n  &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;\n1 industry    01_primary   industry   01_primary   1.12   \n2 industry    01_primary   industry   02_secondary 0.0361 \n3 industry    01_primary   industry   03_tertiary  0.00716\n4 industry    02_secondary industry   01_primary   0.374  \n5 industry    02_secondary industry   02_secondary 1.68   \n6 industry    02_secondary industry   03_tertiary  0.197  \n7 industry    03_tertiary  industry   01_primary   0.348  \n8 industry    03_tertiary  industry   02_secondary 0.445  \n9 industry    03_tertiary  industry   03_tertiary  1.41   \n\n\n\n\n経済波及効果の算出\nこちら からダウンロードできる最終需要がそれぞれ百万円ずつ増加する（finaldemand_change_3sector.csv）ケースで経済波及効果を算出しています．\n\n# 最終需要変化量\nfinaldemand_change &lt;- read_csv(\"finaldemand_change_3sector.csv\",\n                               col_types = cols(.default = \"c\",\n                                                value_M = \"n\")) |&gt; \n  dibble_by(input = c(input_type, input_name),\n            .names_sep = \"_\")\n\nL &lt;- leontiefinv         # レオンチェフ逆行列\nM &lt;- importcoeff         # 移輸入係数\nFD &lt;- finaldemand_change # 最終需要変化量\n\n# 経済波及効果\nspillover &lt;- L %*% ((1 - M) * FD)\n\nspillover\n\n# A dibble:   3\n# Dimensions: output [3]\n  output$type $name            .\n  &lt;chr&gt;       &lt;chr&gt;        &lt;dbl&gt;\n1 industry    01_primary   0.958\n2 industry    02_secondary 1.85 \n3 industry    03_tertiary  2.03 \n\n\n\ntheme_set(theme_light())\n\nspillover |&gt; \n  as_tibble(n = \"value_M\") |&gt; \n  unpack(output, \n         names_sep = \"_\") |&gt; \n  ggplot(aes(output_name, value_M,\n             fill = output_name)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_brewer(palette = \"Set2\")"
  },
  {
    "objectID": "posts/2022/05/ioanalysis-in-r-ja.html#まとめ",
    "href": "posts/2022/05/ioanalysis-in-r-ja.html#まとめ",
    "title": "Rで産業連関分析",
    "section": "まとめ",
    "text": "まとめ\nRを用いた産業連関分析の方法について紹介しました．\nここまでの計算を，jpioにパッケージ形式でまとめました．以下のように，ここまでの計算と同様の計算を行うことができます．\n\n# pak::pak(\"UchidaMizuki/jpio\")\n\n# 産業連関表\niotable &lt;- read_csv(\"iotable_3sector_2011.csv\",\n                    col_types = cols(.default = \"c\",\n                                     value_M = \"n\")) |&gt; \n  jpio::as_iotable()\n\niotable\n\n# A dibble:   24\n# Dimensions: input [4], output [6]\n   input$type $name        output$type $name                  .\n   &lt;fct&gt;      &lt;chr&gt;        &lt;fct&gt;       &lt;chr&gt;              &lt;dbl&gt;\n 1 industry   01_primary   industry    01_primary       1456611\n 2 industry   01_primary   industry    02_secondary     7850628\n 3 industry   01_primary   industry    03_tertiary      1373767\n 4 industry   01_primary   finaldemand 04_finaldemand   3869875\n 5 industry   01_primary   export      05_export          47890\n 6 industry   01_primary   import      06_import       -2562809\n 7 industry   02_secondary industry    01_primary       2715710\n 8 industry   02_secondary industry    02_secondary   161897553\n 9 industry   02_secondary industry    03_tertiary     62841827\n10 industry   02_secondary finaldemand 04_finaldemand 132924323\n# ℹ 14 more rows\n\n# 投入係数\njpio::input_coef(iotable)\n\n# A dibble:   9\n# Dimensions: input [3], output [3]\n  input$type $name        output$type $name              .\n  &lt;fct&gt;      &lt;chr&gt;        &lt;fct&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 industry   01_primary   industry    01_primary   0.121  \n2 industry   01_primary   industry    02_secondary 0.0229 \n3 industry   01_primary   industry    03_tertiary  0.00235\n4 industry   02_secondary industry    01_primary   0.226  \n5 industry   02_secondary industry    02_secondary 0.472  \n6 industry   02_secondary industry    03_tertiary  0.108  \n7 industry   03_tertiary  industry    01_primary   0.168  \n8 industry   03_tertiary  industry    02_secondary 0.195  \n9 industry   03_tertiary  industry    03_tertiary  0.267  \n\n# レオンチェフ逆行列\njpio::leontief_inv(iotable)\n\n# A dibble:   9\n# Dimensions: output [3], input [3]\n  output$type $name        input$type $name              .\n  &lt;fct&gt;       &lt;chr&gt;        &lt;fct&gt;      &lt;chr&gt;          &lt;dbl&gt;\n1 industry    01_primary   industry   01_primary   1.12   \n2 industry    01_primary   industry   02_secondary 0.0361 \n3 industry    01_primary   industry   03_tertiary  0.00716\n4 industry    02_secondary industry   01_primary   0.374  \n5 industry    02_secondary industry   02_secondary 1.68   \n6 industry    02_secondary industry   03_tertiary  0.197  \n7 industry    03_tertiary  industry   01_primary   0.348  \n8 industry    03_tertiary  industry   02_secondary 0.445  \n9 industry    03_tertiary  industry   03_tertiary  1.41   \n\n# 経済波及効果\njpio::spillover_effect(iotable,\n                       list(`01_primary` = 1,\n                            `02_secondary` = 1,\n                            `03_tertiary` = 1))\n\n# A dibble:   3\n# Dimensions: output [3]\n  output$type $name            .\n  &lt;fct&gt;       &lt;chr&gt;        &lt;dbl&gt;\n1 industry    01_primary   0.958\n2 industry    02_secondary 1.85 \n3 industry    03_tertiary  2.03 \n\n# スカイラインチャート\njpio::skyline_chart(iotable, \n                    ylim = c(-0.5, NA))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Uchida Mizuki.\nI am a classical music lover."
  },
  {
    "objectID": "about.html#apps",
    "href": "about.html#apps",
    "title": "About",
    "section": "Apps",
    "text": "Apps\njpgrid App"
  },
  {
    "objectID": "about.html#games",
    "href": "about.html#games",
    "title": "About",
    "section": "Games",
    "text": "Games\nmultpl"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UchidaMizuki",
    "section": "",
    "text": "Rのdmパッケージでデータ前処理の質を高めよう\n\n\n\n\n\n\ndm\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nJan 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRの数値積分で円の面積を求める\n\n\n\n\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nSep 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nQuartoを活用してTokyo.Rで発表しました\n\n\n\n\n\n\ne-Stat\n\n\nLT\n\n\nTokyo.R\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nSep 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nなぜベイズの定理が重要なのかーPCR検査を例にー\n\n\n\n\n\n\nBayes\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nApr 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n世代間の「1票の格差」を定量化してみる\n\n\n\n\n\n\nPolitics\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nApr 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n地域メッシュデータのためのWEBアプリをつくりました（R Shiny&jpgrid）\n\n\n\n\n\n\nShiny\n\n\njpgrid\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRで人口ピラミッドのアニメーションを作る\n\n\n\n\n\n\nggplot2\n\n\ngganimate\n\n\ne-Stat\n\n\njpstat\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）\n\n\n\n\n\n\ne-Stat\n\n\njpstat\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nDec 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nCSVの代わりにParquetを使ってみよう\n\n\n\n\n\n\nparquet\n\n\narrow\n\n\nR\n\n\nPython\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nJun 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRで日本地図を描いてみよう\n\n\n\n\n\n\nggplot2\n\n\nsf\n\n\njpmap\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nJun 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRで産業連関分析\n\n\n\n\n\n\nioanalysis\n\n\ndibble\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html",
    "href": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html",
    "title": "Rで日本地図を描いてみよう",
    "section": "",
    "text": "Rでは，ggplot2などのパッケージを利用するだけで，きれいな日本地図（都道府県別）を描くことができます．\nここでは，日本地図をggplot2で描画する方法をいくつか紹介します．"
  },
  {
    "objectID": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#地図描画用のサンプルデータ",
    "href": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#地図描画用のサンプルデータ",
    "title": "Rで日本地図を描いてみよう",
    "section": "地図描画用のサンプルデータ",
    "text": "地図描画用のサンプルデータ\nここでは，こちらからダウンロードできる社会・人口統計体系の2015年の都道府県別外国人人口比率データ（10万人あたり外国人人口）を地図描画用のサンプルデータとしました．\n\n\nパッケージの読み込み\nlibrary(tidyverse)\n\n\n\n\nデータのダウンロード\nlibrary(jpstat)\nlibrary(arrow)\n\nappId &lt;- keyring::key_get(\"estat-api\")\nforeigner_ratio_2015 &lt;- estat(appId, \"https://www.e-stat.go.jp/en/dbview?sid=0000010201\",\n                              lang = \"E\")\nforeigner_ratio_2015 &lt;- foreigner_ratio_2015 |&gt; \n  activate(tab) |&gt; \n  select() |&gt; \n  \n  activate(cat01) |&gt; \n  # Ratio of population of foreigners (per 100,000 persons)\n  filter(code == \"#A01601\") |&gt; \n  select() |&gt; \n  \n  activate(area) |&gt; \n  filter(name != \"All Japan\") |&gt; \n  select(code, name) |&gt; \n  rekey(\"pref\") |&gt; \n  \n  activate(time) |&gt; \n  filter(name == \"2015\") |&gt; \n  select()\nforeigner_ratio_2015 &lt;- foreigner_ratio_2015 |&gt; \n  collect(\"foreigners_per_100K\")\n\nwrite_parquet(foreigner_ratio_2015, \"foreigner_ratio_2015.parquet\")\n\n\n\n\nデータの読み込み\nlibrary(arrow)\n\nforeigner_ratio_2015 &lt;- read_parquet(\"foreigner_ratio_2015.parquet\") |&gt; \n  mutate(pref_code = pref_code |&gt; \n           str_extract(\"^\\\\d{2}\") |&gt; \n           parse_integer(),\n         \n         pref_name = pref_name |&gt; \n           str_remove(\"-.+$\"),\n         pref_name = case_when(pref_name == \"Gumma\" ~ \"Gunma\",\n                               TRUE ~ pref_name),\n         \n         foreigner_ratio = parse_number(foreigners_per_100K) / 1e5,\n         .keep = \"unused\")\n\n\n\nforeigner_ratio_2015\n\n# A tibble: 47 × 3\n   pref_code pref_name foreigner_ratio\n       &lt;int&gt; &lt;chr&gt;               &lt;dbl&gt;\n 1         1 Hokkaido          0.00403\n 2         2 Aomori            0.00264\n 3         3 Iwate             0.00392\n 4         4 Miyagi            0.00599\n 5         5 Akita             0.00285\n 6         6 Yamagata          0.00490\n 7         7 Fukushima         0.00456\n 8         8 Ibaraki           0.0142 \n 9         9 Tochigi           0.0134 \n10        10 Gunma             0.0188 \n# ℹ 37 more rows"
  },
  {
    "objectID": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#geom_map-を使って日本地図を描く",
    "href": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#geom_map-を使って日本地図を描く",
    "title": "Rで日本地図を描いてみよう",
    "section": "geom_map() を使って日本地図を描く",
    "text": "geom_map() を使って日本地図を描く\nggplot2では，map_data() やgeom_map() を使うことで，世界の国々を描画することができます．これには，mapsパッケージを予めダウンロードする必要があります．また，日本地図を利用するには，mapsパッケージに加えて，mapdataパッケージが必要になります．\nmap_data(\"japan\") とすることで，mapsパッケージの地図データがデータフレームに変換されます．このデータフレームのregion 列が都道府県のIDとなるため，aes(map_id = region)を設定した上で，geom_map() することで，描画したいデータのregion 列と都道府県ジオメトリがリンクします．\nただし，map_data(\"japan\") は，以下の点に注意が必要です．\n\nregion 列はすべてアルファベット表記である\n他の都道府県と違い，奈良県だけががNARA と大文字表記になっているなど，元データに問題あり\n\nここでは，str_to_title()で修正\n\n\nまた，日本地図全体を表示するためには，expand_limits() などで軸を設定すること必要になります．\n\n# pak::pak(\"maps\")\n# pak::pak(\"mapdata\")\nlibrary(tidyverse)\nlibrary(mapdata)\n\nmap_data_japan &lt;- map_data(\"japan\") |&gt; \n  as_tibble() |&gt; \n  mutate(region = str_to_title(region))\nmap_data_japan\n\n# A tibble: 46,975 × 6\n    long   lat group order region   subregion\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;    \n 1  140.  42.3     1     1 Hokkaido &lt;NA&gt;     \n 2  140.  42.3     1     2 Hokkaido &lt;NA&gt;     \n 3  140.  42.3     1     3 Hokkaido &lt;NA&gt;     \n 4  140.  42.3     1     4 Hokkaido &lt;NA&gt;     \n 5  140.  42.3     1     5 Hokkaido &lt;NA&gt;     \n 6  140.  42.3     1     6 Hokkaido &lt;NA&gt;     \n 7  140.  42.3     1     7 Hokkaido &lt;NA&gt;     \n 8  140.  42.3     1     8 Hokkaido &lt;NA&gt;     \n 9  140.  42.3     1     9 Hokkaido &lt;NA&gt;     \n10  140.  42.3     1    10 Hokkaido &lt;NA&gt;     \n# ℹ 46,965 more rows\n\nggplot(foreigner_ratio_2015 |&gt; \n         rename(region = pref_name),\n       aes(map_id = region)) +\n  geom_map(aes(fill = foreigner_ratio),\n           map = map_data_japan) +\n  expand_limits(x = map_data_japan$long,\n                y = map_data_japan$lat) +\n  scale_fill_viridis_c(\"外国人人口比率\",\n                       limits = c(0, 0.03),\n                       labels = scales::label_percent(),\n                       option = \"turbo\")"
  },
  {
    "objectID": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#sfパッケージを使って日本地図を描く",
    "href": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#sfパッケージを使って日本地図を描く",
    "title": "Rで日本地図を描いてみよう",
    "section": "sfパッケージを使って日本地図を描く",
    "text": "sfパッケージを使って日本地図を描く\n最近では，sfパッケージのジオメトリがggplot2で簡単に描画できるようになっています．\nまた，maps・mapdataパッケージの提供する地図データは，sfパッケージのst_as_sf() でsfのジオメトリデータに変換することができます．\n日本地図データをsfに変換することで，先ほどよりも直感的に地図を描くことができます．\n\nlibrary(sf)\n\nmap_japan &lt;- maps::map(\"japan\", \n                       plot = FALSE,\n                       fill = TRUE) |&gt; \n  st_as_sf() |&gt; \n  rename(pref_name = ID) |&gt; \n  mutate(pref_name = str_to_title(pref_name))\n\nmap_japan |&gt; \n  left_join(foreigner_ratio_2015,\n            by = \"pref_name\") |&gt; \n  ggplot(aes(fill = foreigner_ratio)) +\n  geom_sf(color = \"transparent\") +\n  scale_fill_viridis_c(\"外国人人口比率\",\n                       limits = c(0, 0.03),\n                       labels = scales::label_percent(),\n                       option = \"turbo\")"
  },
  {
    "objectID": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#もっと簡単に日本地図を描く",
    "href": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#もっと簡単に日本地図を描く",
    "title": "Rで日本地図を描いてみよう",
    "section": "もっと簡単に日本地図を描く",
    "text": "もっと簡単に日本地図を描く\njpmapは，ggplot2による日本地図の描画をより簡単にするためのパッケージです．\njpmapは，以下の2つの機能を持ちます．\n\n日本語の都道府県名や都道府県コードが含む都道府県データを提供（jpmap::prefecture）\n琉球諸島・小笠原諸島を再配置したレイアウトを可能に（jpmap::layout_islands()）\n\njpmap::layout_islands() で地図のレイアウトを変更することで，都道府県ごとの傾向がよりわかりやすくなります．\n\n# pak::pak(\"UchidaMizuki/jpmap\")\njpmap::prefecture\n\nSimple feature collection with 47 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 122.9382 ymin: 24.2121 xmax: 153.9856 ymax: 45.52041\nGeodetic CRS:  JGD2011\n# A tibble: 47 × 4\n   pref_code pref_name pref_name_ja                                     geometry\n       &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;                                  &lt;MULTIPOLYGON [°]&gt;\n 1         1 Hokkaido  北海道       (((143.8965 44.15815, 143.9118 44.15229, 14…\n 2         2 Aomori    青森県       (((139.9438 40.42928, 139.9426 40.43439, 13…\n 3         3 Iwate     岩手県       (((141.681 40.45101, 141.6909 40.44229, 141…\n 4         4 Miyagi    宮城県       (((141.6403 38.9675, 141.6406 38.9652, 141.…\n 5         5 Akita     秋田県       (((139.8809 39.11511, 139.8919 39.13321, 13…\n 6         6 Yamagata  山形県       (((139.5487 38.545, 139.5801 38.60688, 139.…\n 7         7 Fukushima 福島県       (((140.9332 37.8898, 140.9334 37.88923, 140…\n 8         8 Ibaraki   茨城県       (((140.7973 36.84649, 140.7931 36.83755, 14…\n 9         9 Tochigi   栃木県       (((139.6537 36.20314, 139.6385 36.22575, 13…\n10        10 Gunma     群馬県       (((138.6795 36.73065, 138.7227 36.74918, 13…\n# ℹ 37 more rows\n\nplot &lt;- jpmap::prefecture |&gt; \n  left_join(foreigner_ratio_2015,\n            by = c(\"pref_code\", \"pref_name\")) |&gt; \n  ggplot(aes(fill = foreigner_ratio)) +\n  geom_sf(color = \"transparent\") +\n  scale_fill_viridis_c(\"外国人人口比率\",\n                       limits = c(0, 0.03),\n                       labels = scales::label_percent(),\n                       option = \"turbo\")\n\njpmap::layout_islands(plot,\n                      ogasawara = FALSE)\n\nWarning: `layout_islands()` was deprecated in jpmap 0.2.0.\nℹ Please use `layout_japan()` instead."
  },
  {
    "objectID": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#まとめ地図からわかったこと",
    "href": "posts/2022/06/draw-a-map-of-japan-in-r-ja.html#まとめ地図からわかったこと",
    "title": "Rで日本地図を描いてみよう",
    "section": "まとめ（地図からわかったこと）",
    "text": "まとめ（地図からわかったこと）\n2015年の都道府県別外国人人口比率に関する日本地図から以下のことがわかりました．\n\n2015年ではどの都道府県でも外国人人口比率が3％以下である\n東京都は外国人人口比率が最も多く，愛知県や群馬県なども外国人口比率が高い．\n\nここまで，ggplot2などのパッケージを活用した日本地図の描画を試してみました．\nその結果，Rを使えば，自前でデータを整備しなくても，簡単に日本地図を描けることがわかりました．みなさんもぜひ，ggplot2を使って，色々な地図を使ってみてください！"
  },
  {
    "objectID": "posts/2022/12/call-e-stat-api-in-r.html",
    "href": "posts/2022/12/call-e-stat-api-in-r.html",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "",
    "text": "この記事は「R Advent Calendar 2022」の12日目の記事です．\n昨年，日本で政府統計の整備が始まってから150年を迎えました（平成・令和の統計年表）．最近では，政府統計の総合窓口（e-Stat）で，様々な政府統計データを閲覧・ダウンロードすることができるようになりました．\ne-Statには，便利なAPI機能も提供されています（利用ガイドはこちら．あらかじめ利用規約を確認してください．API機能を利用する際は，事前にユーザ登録を行ってください）．\nこの記事では，Rのjpstatパッケージを使って，e-Stat APIを効率的に用いる方法を紹介します．"
  },
  {
    "objectID": "posts/2022/12/call-e-stat-api-in-r.html#この記事について",
    "href": "posts/2022/12/call-e-stat-api-in-r.html#この記事について",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "",
    "text": "この記事は「R Advent Calendar 2022」の12日目の記事です．\n昨年，日本で政府統計の整備が始まってから150年を迎えました（平成・令和の統計年表）．最近では，政府統計の総合窓口（e-Stat）で，様々な政府統計データを閲覧・ダウンロードすることができるようになりました．\ne-Statには，便利なAPI機能も提供されています（利用ガイドはこちら．あらかじめ利用規約を確認してください．API機能を利用する際は，事前にユーザ登録を行ってください）．\nこの記事では，Rのjpstatパッケージを使って，e-Stat APIを効率的に用いる方法を紹介します．"
  },
  {
    "objectID": "posts/2022/12/call-e-stat-api-in-r.html#e-statについて",
    "href": "posts/2022/12/call-e-stat-api-in-r.html#e-statについて",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "e-Statについて",
    "text": "e-Statについて\ne-Statには，様々な政府統計のデータベースが整理されていますが，ここでは，2015年国民健康・栄養調査の調査結果から睡眠時間に関するデータベースを見てみましょう．\nデータベースを開くと以下のように統計表が表示され，右上の「ダウンロード」ボタンからデータをダウンロードすることができます．\n\n\n\ne-Statデータベース：統計表表示画面\n\n\n画面左上の「表示項目選択」ボタンをクリックすると，表示するデータの項目（年齢階級・性別など）を選択することができます．\n\n\n\ne-Statデータベース：表示項目選択画面\n\n\nたとえば，年齢階級を選択したい場合は，年齢階級の「項目を選択」ボタンをクリックすると以下のような画面で年齢階級を選択することができます．\n\n\n\ne-Statデータベース：表示項目の設定画面\n\n\n表示項目を選択した後に，「ダウンロード」ボタンをクリックすると，選択した項目のデータのみをダウンロードすることができます．\nこのように，e-Statでは，簡単にデータを抽出・ダウンロードすることができます．しかし，データ取得作業の再現性を高めたり，プログラムを用いたデータ抽出・取得の効率化を行ったりしたい場合は，e-Stat APIを用いるのがおすすめです．"
  },
  {
    "objectID": "posts/2022/12/call-e-stat-api-in-r.html#jpstatパッケージでe-stat-apiを使う",
    "href": "posts/2022/12/call-e-stat-api-in-r.html#jpstatパッケージでe-stat-apiを使う",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "jpstatパッケージでe-Stat APIを使う",
    "text": "jpstatパッケージでe-Stat APIを使う\n上で説明したe-Statでのデータの抽出・ダウンロードをe-Stat APIで行うためには，以下のようなステップを踏む必要があります．\n\nメタ情報取得・パラメータ設定：表示項目データを取得・選択，選択項目に対応するAPIパラメータを設定\n統計データ取得：選択したデータを取得・表データに整形する\n\njpstatパッケージは，これらの一連の作業をR上で効率的に行うため開発されたものです1．jpstatパッケージは，CRANからインストールすることができます．\nここでは，男女・年齢階級別の睡眠時間をグラフ化することを目標として，さきほど取り上げた睡眠時間に関するデータベース（2015年）からデータを取得してみましょう．まず，必要なパッケージを読み込みます．\n\ninstall.packages(\"jpstat\")\n\n\nlibrary(tidyverse)\nlibrary(jpstat)\n\n\nステップ1：メタ情報（表示項目）を表示・抽出する\ne-Stat APIを用いるためには，事前にユーザ登録を行い，appId と呼ばれるアプリケーションIDを取得する必要があります2．\nestat() 関数に，appId とデータベースのURL（または統計表ID：statsDataId）を入力することでメタ情報（表示項目）を取得することができます3．\nはじめに，メタ情報のうち「年齢階級（cat01）」のデータを見てみましょう（cat01はAPI上での分類名です）．activate() 関数によりメタ情報を表示することができます．さらに，filter() 関数により項目を選択することができます．ここでは，年齢階級別データのみが必要であるため，「総数」データを削除します4．\nパイプ演算子|&gt; を使うことで，以下のように，cat01以外のメタ情報のデータ抽出を続けて行うことができます．ここでは，男女・年齢階級・睡眠時間別の回答者数データを抽出しています．\n\n# ご自身のappIdに置き換えてください\nSys.setenv(ESTAT_API_KEY = \"Your appId\")\n\n\nestat_sleeptime_2015 &lt;- estat(statsDataId = \"https://www.e-stat.go.jp/dbview?sid=0003224282\")\n\n\n# メタ情報の閲覧・選択\nestat_sleeptime_2015 |&gt; \n  activate(cat01) |&gt; \n  filter(name != \"総数\")\n\n# ☐ tab:   表章項目     [2] &lt;code, name, level, unit&gt;\n# ☒ cat01: 年齢階級     [6] &lt;code, name, level, parentCode&gt;\n# ☐ cat02: 睡眠の質     [8] &lt;code, name, level, parentCode&gt;\n# ☐ cat03: 性別         [3] &lt;code, name, level, parentCode&gt;\n# ☐ cat04: 平均睡眠時間 [6] &lt;code, name, level, parentCode&gt;\n# ☐ time:  時間軸(年次) [1] &lt;code, name, level&gt;\n# \n# A tibble: 6 × 4\n  code  name      level parentCode\n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     \n1 160   20歳-29歳 2     100       \n2 170   30歳-39歳 2     100       \n3 180   40歳-49歳 2     100       \n4 190   50歳-59歳 2     100       \n5 210   60歳-69歳 2     100       \n6 220   70歳以上  2     100       \n\n\n\nestat_sleeptime_2015_filtered &lt;- estat_sleeptime_2015 |&gt; \n  \n  # 表章項目\n  activate(tab) |&gt; \n  filter(name == \"人数\") |&gt; \n  \n  # 年齢階級\n  activate(cat01) |&gt; \n  filter(name != \"総数\") |&gt; \n  \n  # 睡眠の質\n  activate(cat02) |&gt; \n  filter(name == \"総数\") |&gt; \n  \n  # 性別\n  activate(cat03) |&gt; \n  filter(name %in% c(\"男性\", \"女性\"))\n\n\n\nステップ2：統計データを取得（ダウンロード）する\nデータの抽出後にcollect() を適用することで統計データを取得することができます．また，collect()のn引数で，取得するデータの列を名付けることができます．ここでは，\"person\"と名付けます．\n取得したデータdata_sleeptime_2015を見ると，（たくさんの列が存在する）分析しづらいデータになっていることがわかります．ステップ2+αで，データ取得とデータ整形を同時に行う方法について説明します．\n\ndata_sleeptime_2015 &lt;- estat_sleeptime_2015_filtered |&gt; \n  \n  # データ取得・数値に変換\n  collect(n = \"person\") |&gt; \n  mutate(person = parse_number(person))\n\nThe total number of data is 72.\n\nknitr::kable(head(data_sleeptime_2015, 10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntab_code\ntab_name\ntab_level\ntab_unit\ncat01_code\ncat01_name\ncat01_level\ncat01_parentCode\ncat02_code\ncat02_name\ncat02_level\ncat02_parentCode\ncat03_code\ncat03_name\ncat03_level\ncat03_parentCode\ncat04_code\ncat04_name\ncat04_level\ncat04_parentCode\ntime_code\ntime_name\ntime_level\nperson\n\n\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n110\n５時間未満\n2\n100\n2015000000\n2015年\n1\n23\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n120\n５時間以上６時間未満\n2\n100\n2015000000\n2015年\n1\n86\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n130\n６時間以上７時間未満\n2\n100\n2015000000\n2015年\n1\n88\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n140\n７時間以上８時間未満\n2\n100\n2015000000\n2015年\n1\n37\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n150\n８時間以上９時間未満\n2\n100\n2015000000\n2015年\n1\n19\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n160\n９時間以上\n2\n100\n2015000000\n2015年\n1\n3\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n120\n女性\n2\n100\n110\n５時間未満\n2\n100\n2015000000\n2015年\n1\n28\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n120\n女性\n2\n100\n120\n５時間以上６時間未満\n2\n100\n2015000000\n2015年\n1\n106\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n120\n女性\n2\n100\n130\n６時間以上７時間未満\n2\n100\n2015000000\n2015年\n1\n94\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n120\n女性\n2\n100\n140\n７時間以上８時間未満\n2\n100\n2015000000\n2015年\n1\n55\n\n\n\n\n\n\n\nステップ2+α：データ取得とデータ整形を同時に行う\njpstatでe-Statのデータを取得すると，パラメータ名（cat01など）と各項目の列名（code， nameなど）から列（cat01_code，cat01_nameなど）が作成されます．\njpstatでは，rekey() 関数によりパラメータ名を変更したり，select() 関数で項目別に列を選択したりすることでデータを整理することができます5．以下のように書くことで，すっきりとしたデータを作成することができます．\n\ndata_sleeptime_2015 &lt;- estat_sleeptime_2015 |&gt; \n  activate(tab) |&gt; \n  filter(name == \"人数\") |&gt; \n  select() |&gt; \n  \n  activate(cat01) |&gt; \n  rekey(\"ageclass\") |&gt; \n  filter(name != \"総数\") |&gt; \n  select(name) |&gt; \n  \n  activate(cat02) |&gt; \n  filter(name == \"総数\") |&gt; \n  select() |&gt; \n  \n  activate(cat03) |&gt; \n  rekey(\"sex\") |&gt; \n  filter(name %in% c(\"男性\", \"女性\")) |&gt; \n  select(name) |&gt; \n  \n  activate(cat04) |&gt; \n  rekey(\"sleeptime\") |&gt; \n  select(name) |&gt; \n  \n  activate(time) |&gt; \n  select() |&gt; \n  \n  collect(n = \"person\") |&gt; \n  mutate(person = parse_number(person))\n\nThe total number of data is 72.\n\nknitr::kable(head(data_sleeptime_2015, 10))\n\n\n\n\nageclass_name\nsex_name\nsleeptime_name\nperson\n\n\n\n\n20歳-29歳\n男性\n５時間未満\n23\n\n\n20歳-29歳\n男性\n５時間以上６時間未満\n86\n\n\n20歳-29歳\n男性\n６時間以上７時間未満\n88\n\n\n20歳-29歳\n男性\n７時間以上８時間未満\n37\n\n\n20歳-29歳\n男性\n８時間以上９時間未満\n19\n\n\n20歳-29歳\n男性\n９時間以上\n3\n\n\n20歳-29歳\n女性\n５時間未満\n28\n\n\n20歳-29歳\n女性\n５時間以上６時間未満\n106\n\n\n20歳-29歳\n女性\n６時間以上７時間未満\n94\n\n\n20歳-29歳\n女性\n７時間以上８時間未満\n55\n\n\n\n\n\n\n\nおまけ：取得したデータのグラフ化\n最後に，取得した2015年の男女・年齢階級別の睡眠時間データをグラフ化してみましょう．グラフより，男性と女性では年齢階級別の睡眠時間の傾向が異なることがわかります．\n\ndata_sleeptime_2015 |&gt; \n  mutate(ageclass_name = as_factor(ageclass_name),\n         sex_name = as_factor(sex_name),\n         sleeptime_name = as_factor(sleeptime_name)) |&gt; \n  group_by(ageclass_name, sex_name) |&gt; \n  mutate(prop = person / sum(person)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(ageclass_name, prop,\n             fill = fct_rev(sleeptime_name))) +\n  geom_col() +\n  geom_text(aes(label = if_else(prop &gt; 0.05,\n                                scales::label_percent(accuracy = 1)(prop),\n                                \"\")),\n            position = position_stack(vjust = 0.5)) +\n  scale_x_discrete(\"年齢階級\") +\n  scale_y_continuous(\"割合\", \n                     labels = scales::label_percent(accuracy = 1)) +\n  scale_fill_brewer(\"睡眠時間\",\n                    palette = \"Spectral\") +\n  facet_wrap(~ sex_name) +\n  guides(x = guide_axis(n.dodge = 2))"
  },
  {
    "objectID": "posts/2022/12/call-e-stat-api-in-r.html#まとめ",
    "href": "posts/2022/12/call-e-stat-api-in-r.html#まとめ",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "まとめ",
    "text": "まとめ\n本記事では，e-Stat APIとjpstatパッケージで日本の統計データを効率的に取得する方法について紹介しました．\nRで統計データを取得することで，作業の再現性や効率性を高めることができます．また，jpstatパッケージを使うことで，データ取得とデータ整形を同時に行うことができるため便利です．みなさんもぜひ使ってみてください．"
  },
  {
    "objectID": "posts/2022/12/call-e-stat-api-in-r.html#footnotes",
    "href": "posts/2022/12/call-e-stat-api-in-r.html#footnotes",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "脚注",
    "text": "脚注\n\n\ne-Stat APIでは，メタ情報取得・統計データ取得以外にも，様々な機能が提供されています（API仕様）．↩︎\nアプリケーションIDの取得には，URLを登録する必要があります．公開サイトで利用しない場合には，http://test.localhost/などのローカルアドレスを入力することが推奨されています（詳しくは利用ガイドを参照）．↩︎\ne-Statのページの右上の「API」ボタンを押すとAPIのクエリが表示されます．クエリ内のstatsDataId を直接入力することでメタ情報を取得することもできます．↩︎\nただし，各パラメータの項目数には，100件という上限が設定されているため，フィルタリング後の項目数が多くなる場合には，フィルタリングを行わず，全ての項目を選択することをおすすめします．↩︎\nselect() 関数である項目の列を全て削除することもできます．これは，「総数」のみを選択する場合など，分析に不要な項目を削除する場合に便利です．↩︎"
  },
  {
    "objectID": "posts/2023/02/web-app-for-grid-square-codes-in-japan.html",
    "href": "posts/2023/02/web-app-for-grid-square-codes-in-japan.html",
    "title": "地域メッシュデータのためのWEBアプリをつくりました（R Shiny&jpgrid）",
    "section": "",
    "text": "R Shinyを使って地域メッシュデータを使うためのWEBアプリをつくってみました．\n地域メッシュとは，経度・緯度にもとづいて（日本の）地域をほぼ正方形のメッシュに分割したもので，統計データの集計区分としてよく利用されています．\n今回つくったアプリは，Rパッケージのjpgridパッケージの機能の一部を提供しています． このアプリの提供機能は以下の通りです．\n\n市区町村別の地域メッシュデータ生成\nメッシュ文字列を含む表データから地域メッシュデータ生成\n経度・緯度を含む表データから地域メッシュデータ生成\n\n\n\n\nアプリの外観（クリックするとアプリが開きます）"
  },
  {
    "objectID": "posts/2023/02/web-app-for-grid-square-codes-in-japan.html#このアプリについて",
    "href": "posts/2023/02/web-app-for-grid-square-codes-in-japan.html#このアプリについて",
    "title": "地域メッシュデータのためのWEBアプリをつくりました（R Shiny&jpgrid）",
    "section": "",
    "text": "R Shinyを使って地域メッシュデータを使うためのWEBアプリをつくってみました．\n地域メッシュとは，経度・緯度にもとづいて（日本の）地域をほぼ正方形のメッシュに分割したもので，統計データの集計区分としてよく利用されています．\n今回つくったアプリは，Rパッケージのjpgridパッケージの機能の一部を提供しています． このアプリの提供機能は以下の通りです．\n\n市区町村別の地域メッシュデータ生成\nメッシュ文字列を含む表データから地域メッシュデータ生成\n経度・緯度を含む表データから地域メッシュデータ生成\n\n\n\n\nアプリの外観（クリックするとアプリが開きます）"
  },
  {
    "objectID": "posts/2023/02/web-app-for-grid-square-codes-in-japan.html#アプリの提供機能について",
    "href": "posts/2023/02/web-app-for-grid-square-codes-in-japan.html#アプリの提供機能について",
    "title": "地域メッシュデータのためのWEBアプリをつくりました（R Shiny&jpgrid）",
    "section": "アプリの提供機能について",
    "text": "アプリの提供機能について\n\n市区町村別の地域メッシュデータ生成\n総務省統計局の公開する市区町村別メッシュ・コード一覧から市区町村別のメッシュを取得します．\n以下のような手順で市区町村別のメッシュを生成・保存できます．\n\n都道府県を選択（複数選択可）\n市区町村を選択（複数選択可）\nメッシュサイズ（1 km／10 km／80 kmのいずれか）を選択し「メッシュ表示」を押す\nデータ形式（GeoPackageまたはCSV）を選択し「ダウンロード」を押す\n\n\n\n\n市区町村別メッシュの表示イメージ\n\n\njpgridパッケージでは，grid_city データで市区町村別メッシュデータが提供されています．\n以下のように，市区町村別メッシュデータを図示することができます．\n\nlibrary(jpgrid)\nlibrary(tidyverse)\n\nJGD2011 &lt;- 6668\n\ngrid_city |&gt; \n  filter(city_name_ja %in% c(\"千葉市中央区\", \"千葉市花見川区\", \"千葉市稲毛区\")) |&gt; \n  grid_as_sf(crs = 6668) |&gt; \n  ggplot(aes(fill = city_name_ja)) +\n  geom_sf() +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\nメッシュ文字列を含む表データから地域メッシュデータ生成\n以下のような手順でメッシュ文字列を含む表データから地域メッシュを生成・保存できます．\n\nデータを選択（CSVまたはExcel）\nメッシュ文字列の列名を指定（地点IDも指定可能）し「メッシュ表示」を押す\nデータ形式（GeoPackageまたはCSV）を選択し「ダウンロード」を押す\n\njpgridパッケージでは，parse_grid() で文字列から地域メッシュを生成することができます．\n\n\n\n経度・緯度を含む表データから地域メッシュデータ生成\n同様に，以下の手順で経度・緯度を含む表データから地域メッシュを生成・保存できます．\n\nデータを選択（CSVまたはExcel）\n経度（X）・緯度（Y）の列名を指定（地点IDも指定可能）し「メッシュ表示」を押す\nデータ形式（GeoPackageまたはCSV）を選択し「ダウンロード」を押す\n\njpgridパッケージでは，coords_to_grid() で文字列から地域メッシュを生成することができます．"
  },
  {
    "objectID": "posts/2023/02/web-app-for-grid-square-codes-in-japan.html#おわりに",
    "href": "posts/2023/02/web-app-for-grid-square-codes-in-japan.html#おわりに",
    "title": "地域メッシュデータのためのWEBアプリをつくりました（R Shiny&jpgrid）",
    "section": "おわりに",
    "text": "おわりに\nR Shinyで作成した地域メッシュデータのためのWEBアプリについて紹介しました．\nWEBアプリの作成に利用したjpgridパッケージでは，このアプリで提供していない様々な機能が提供されています．詳しくは，こちらをご覧ください．\n例として，ジオメトリをメッシュに変換するgeometry_to_grid() などがあります．\nぜひ地域メッシュデータの分析にjpgridパッケージも活用してみてください．\n\njapan &lt;- rnaturalearth::ne_countries(country = \"japan\",\n                                     scale = \"medium\",\n                                     returnclass = \"sf\")\ngrid_japan &lt;- japan |&gt; \n  geometry_to_grid(\"80km\") |&gt; \n  dplyr::first() |&gt; \n  grid_as_sf(crs = sf::st_crs(japan))\n\njapan |&gt; \n  ggplot() +\n  geom_sf() +\n  geom_sf(data = grid_japan,\n          fill = \"transparent\")"
  },
  {
    "objectID": "posts/2023/04/why-is-bayes-theorem-important.html",
    "href": "posts/2023/04/why-is-bayes-theorem-important.html",
    "title": "なぜベイズの定理が重要なのかーPCR検査を例にー",
    "section": "",
    "text": "この記事では，コロナ禍で普及したPCR検査を例に，統計学において最も有名な定理の一つであるベイズの定理の重要性について説明したいと思います．\nベイズの定理は， 式 1 のように表すことができます．\n\\[\nP(A|B) \\propto P(B|A) P(A)\n\\tag{1}\\]\n式 1 は，以下のことを示しています．\n\nある結果\\(B\\)が生じた場合に，それが原因\\(A\\)によるものである確率\\(P(A|B)\\)は\nある原因\\(A\\)の生じる確率\\(P(A)\\)とある原因\\(A\\)のもとで結果\\(B\\)が生じる確率\\(P(B|A)\\)の掛け算に比例（\\(\\propto\\)）する\n\nもっと身近なもので例えてみましょう． たとえば，\n\n原因\\(A\\)：新型コロナへの感染の有無\n結果\\(B\\)：PCR検査などでの診断結果\n\nと考えれば， 式 1 を 式 2 のように置き換えることができます．\n\\[\nP(感染の有無|診断結果) \\propto P(診断結果|感染の有無) P(感染の有無)\n\\tag{2}\\]"
  },
  {
    "objectID": "posts/2023/04/why-is-bayes-theorem-important.html#ベイズの定理とは",
    "href": "posts/2023/04/why-is-bayes-theorem-important.html#ベイズの定理とは",
    "title": "なぜベイズの定理が重要なのかーPCR検査を例にー",
    "section": "",
    "text": "この記事では，コロナ禍で普及したPCR検査を例に，統計学において最も有名な定理の一つであるベイズの定理の重要性について説明したいと思います．\nベイズの定理は， 式 1 のように表すことができます．\n\\[\nP(A|B) \\propto P(B|A) P(A)\n\\tag{1}\\]\n式 1 は，以下のことを示しています．\n\nある結果\\(B\\)が生じた場合に，それが原因\\(A\\)によるものである確率\\(P(A|B)\\)は\nある原因\\(A\\)の生じる確率\\(P(A)\\)とある原因\\(A\\)のもとで結果\\(B\\)が生じる確率\\(P(B|A)\\)の掛け算に比例（\\(\\propto\\)）する\n\nもっと身近なもので例えてみましょう． たとえば，\n\n原因\\(A\\)：新型コロナへの感染の有無\n結果\\(B\\)：PCR検査などでの診断結果\n\nと考えれば， 式 1 を 式 2 のように置き換えることができます．\n\\[\nP(感染の有無|診断結果) \\propto P(診断結果|感染の有無) P(感染の有無)\n\\tag{2}\\]"
  },
  {
    "objectID": "posts/2023/04/why-is-bayes-theorem-important.html#なぜベイズの定理が重要なのか",
    "href": "posts/2023/04/why-is-bayes-theorem-important.html#なぜベイズの定理が重要なのか",
    "title": "なぜベイズの定理が重要なのかーPCR検査を例にー",
    "section": "なぜベイズの定理が重要なのか？",
    "text": "なぜベイズの定理が重要なのか？\n式 2 に基づき，ベイズの定理の重要性について考えてみましょう． 実は， 式 2 に示したベイズの定理に出てくる3つの確率は，どれも非常に重要な指標と対応しています（下表参照）． つまり， 式 2 からは，検査の精度（感度・特異度）が高くても，検査前確率が低ければ陽性的中率が低くなることなどがわかります．\n\n\n\n\n\n\n\n確率\n医療分野で対応する指標\n\n\n\n\n\\(P(診断結果|感染の有無)\\)\n検査後確率：統計学では事後確率と呼ばれる\n\n陽性的中率：陽性と診断されたとき実際に感染\n陰性的中率：陰性と診断されたとき実際に未感染\n\n\n\n\\(P(診断結果|感染の有無)\\)\n\n感度：感染者が陽性と診断される確率↔︎偽陰性に関連\n特異度：未感染者が陰性と診断される確率↔︎偽陽性に関連\n\n\n\n\\(P(感染の有無)\\)\n検査前確率：統計学では事前確率と呼ばれる\n\n検査対象者のなかでの感染者の割合\n\n\n\n\nたとえば，以下のような状況を考えてみましょう．\n\n感度・特異度はともに99 %（偽陰性・偽陽性がいずれも1 %の確率で生じる）\n検査前確率は1 %（感染者は100 人中1 人で残りの99 人は未感染者）\n\nこの場合，陽性と診断された場合に感染者である確率\\(P(感染|陽性)\\)と，陽性と診断された場合に未感染者である確率\\(P(未感染|陽性)\\)は， それぞれ 式 3 となります．\n\\[\n\\begin{align}\n  P(感染|陽性) \\propto P(陽性|感染)P(感染) &= 0.99 \\times 0.01 = 0.0099 \\\\\n  P(未感染|陽性) \\propto P(陽性|未感染)P(未感染) &= (1 - 0.99) \\times (1 - 0.01) = 0.0099\n\\end{align}\n\\tag{3}\\]\n式 3 より，\\(P(感染|陽性)\\)と\\(P(未感染|陽性)\\)は等しいことがわかり， 陽性的中率は50 %となります． つまり，陽性と診断された検査対象者のなかで，実際に，感染者である人は2人に1人しかいないことがわかります．\nこのように，ベイズの定理を用いることで 「検査の精度（感度・特異度）が高くても検査前確率が低ければ陽性的中率が低くなってしまう」といった 重要な関係性が明らかとなります．"
  },
  {
    "objectID": "posts/2023/04/why-is-bayes-theorem-important.html#まとめ",
    "href": "posts/2023/04/why-is-bayes-theorem-important.html#まとめ",
    "title": "なぜベイズの定理が重要なのかーPCR検査を例にー",
    "section": "まとめ",
    "text": "まとめ\nコロナ禍で普及したPCR検査を例に，ベイズの定理の重要性について説明しました．\n現実に即した計算事例に興味がある場合は， 統計局の公開しているコラムもご一読されることをおすすめします．"
  },
  {
    "objectID": "posts/2023/09/presented-at-tokyor-using-quarto.html",
    "href": "posts/2023/09/presented-at-tokyor-using-quarto.html",
    "title": "Quartoを活用してTokyo.Rで発表しました",
    "section": "",
    "text": "第108回R勉強会@東京（#TokyoR）のLTにてe-Stat APIを利用するためのRパッケージであるjpstatパッケージについて紹介しました1．\nLTとは，Lightning Talks（ライトニングトーク）の略で，短時間のプレゼンテーションのことです．Tokyo.Rでは，1人あたりの発表時間は5分でした．\n当日のプレゼンテーション資料はこちらです．"
  },
  {
    "objectID": "posts/2023/09/presented-at-tokyor-using-quarto.html#発表概要",
    "href": "posts/2023/09/presented-at-tokyor-using-quarto.html#発表概要",
    "title": "Quartoを活用してTokyo.Rで発表しました",
    "section": "",
    "text": "第108回R勉強会@東京（#TokyoR）のLTにてe-Stat APIを利用するためのRパッケージであるjpstatパッケージについて紹介しました1．\nLTとは，Lightning Talks（ライトニングトーク）の略で，短時間のプレゼンテーションのことです．Tokyo.Rでは，1人あたりの発表時間は5分でした．\n当日のプレゼンテーション資料はこちらです．"
  },
  {
    "objectID": "posts/2023/09/presented-at-tokyor-using-quarto.html#スライド作成について",
    "href": "posts/2023/09/presented-at-tokyor-using-quarto.html#スライド作成について",
    "title": "Quartoを活用してTokyo.Rで発表しました",
    "section": "スライド作成について",
    "text": "スライド作成について\nこれまでQuartoをGitHubのREADMEやサイト作成などに活用してきましたが，今回，はじめてスライド作成に挑戦してみました．\n以下のページを参考にしながら，自作パッケージのjpstatを紹介するスライドを試しに作ってみたところ，案外，簡単にスライドが作成でき，折角なのでR勉強会で発表してみました．\n\nhttps://quarto.org/docs/presentations/\nhttps://quarto.org/docs/presentations/revealjs/\n\nソースコードはこちらです．Quartoは，こちらのqmd（Quarto Markdown）ファイルで記述されてます．\n以下では，Quartoとreveal.jsによるスライド作成で今回，特に便利と感じた機能を紹介します．\n\n便利機能①：コードのハイライティング機能\n以下のようにcode-line-numbers を指定することでコードの一部の行をハイライトすることができます．\nここでは，code-line-numbers: \"2-3\" で2・3行目をハイライトしています．さらに，code-line-numbers: \"1|2-3\" のように，| で区切ることでハイライト先を推移させることもできるようです．\nハイライト機能は，一部のコードのみに注目を集めたい場合に，非常に便利です．\n```{r}\n#| echo: true\n#| code-line-numbers: \"2-3\"\n\nestat(statsDataId = \"0003343671\") |&gt; \n  activate(cat01) |&gt; \n  filter(str_detect(name, \"チョコレート\"))\n```\n\n\n便利機能②：自動アニメーション・フェードイン機能\n## から始まる各スライドのタイトルの右などに{auto-animate=\"true\"} をつけることで次のページの記述と共通する記述を自動で探し出してアニメーション化してくれます．\n前後のスライドで記述の繰り返しがある場合には，自動アニメーション機能を使うことで文脈のつながりがわかりやすくなるのではないかと感じました．\nまた，::: {.fragment .fade-in} を使用することで，スライドの途中で記述を表示させることもできます．こちらも特定の記述に注目してほしい場合に有用かと思います．\n\n\n便利機能③：タイトル・フッター設定機能\nタイトルスライドや全スライド共通のフッターは，qmdファイルの上部に以下のように記載することで自動でレイアウトされます．\nここでは，タイトル以外にも，サブタイトル・著者・日付も設定していますが，これらのフォントサイズなどを別途指定しなくても大丈夫でした．\nまた，今回はreveal.jsのデフォルトのテーマを使用しましたが，こちらのようにテーマを変更することもできます．\n---\ntitle: \"e-Stat🤝R\"\nsubtitle: \"Tokyo.R #108\"\nauthor: UchidaMizuki\ndate: \"2023-09-02\"\nfooter: &lt;https://github.com/UchidaMizuki/jpstat&gt;\nformat: \n  revealjs\n---"
  },
  {
    "objectID": "posts/2023/09/presented-at-tokyor-using-quarto.html#まとめ",
    "href": "posts/2023/09/presented-at-tokyor-using-quarto.html#まとめ",
    "title": "Quartoを活用してTokyo.Rで発表しました",
    "section": "まとめ",
    "text": "まとめ\nQuartoを使うことでLT発表にちょうどよいプレゼンテーション資料を簡単につくれることが実感できました．\nちなみに，これまでもQuartoで作成したページのGitHub Pagesへの公開を行ってきましたが，今回のreveal.jsのスライドもPublish Commandを利用することで簡単に公開することができました2．"
  },
  {
    "objectID": "posts/2023/09/presented-at-tokyor-using-quarto.html#footnotes",
    "href": "posts/2023/09/presented-at-tokyor-using-quarto.html#footnotes",
    "title": "Quartoを活用してTokyo.Rで発表しました",
    "section": "脚注",
    "text": "脚注\n\n\n第108回Tokyo.Rのイベント申込者はちょうど108人だったようです．↩︎\nGitHub Actionsによる自動更新はうまくいかなったため，今回は，RStudioのTerminalから手動でquarto publish gh-pages を実行しました．↩︎"
  }
]