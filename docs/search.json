[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Uchida Mizuki.\nI am a classical music lover."
  },
  {
    "objectID": "about.html#apps",
    "href": "about.html#apps",
    "title": "About",
    "section": "Apps",
    "text": "Apps\njpgrid App"
  },
  {
    "objectID": "about.html#games",
    "href": "about.html#games",
    "title": "About",
    "section": "Games",
    "text": "Games\nmultpl"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UchidaMizuki",
    "section": "",
    "text": "Rで人口ピラミッドのアニメーションを作る\n\n\n\n\n\n\n\nggplot2\n\n\ngganimate\n\n\ne-Stat\n\n\njpstat\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nRで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）\n\n\n\n\n\n\n\ne-Stat\n\n\njpstat\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\n\n\nDec 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🗾CSVの代わりにParquetを使ってみよう\n\n\n\n\n\n\n\nparquet\n\n\narrow\n\n\nR\n\n\nPython\n\n\nJapanese\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2022\n\n\n\n\n\n\n  \n\n\n\n\n🗾Rで日本地図を描いてみよう\n\n\n\n\n\n\n\nggplot2\n\n\nsf\n\n\njpmap\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\n\n\nJun 11, 2022\n\n\n\n\n\n\n  \n\n\n\n\n🗾Rで地域メッシュ統計（jpgridパッケージ）\n\n\n\n\n\n\n\ngrid-square-stats\n\n\njpgrid\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\n\n\nJun 4, 2022\n\n\n\n\n\n\n  \n\n\n\n\n🗾Rで産業連関分析\n\n\n\n\n\n\n\nioanalysis\n\n\ndibble\n\n\nR\n\n\nJapanese\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/call-e-stat-api-in-r/call-e-stat-api-in-r.html",
    "href": "posts/call-e-stat-api-in-r/call-e-stat-api-in-r.html",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "",
    "text": "この記事は「R Advent Calendar 2022」の12日目の記事です．\n昨年，日本で政府統計の整備が始まってから150年を迎えました（平成・令和の統計年表）．最近では，政府統計の総合窓口（e-Stat）で，様々な政府統計データを閲覧・ダウンロードすることができるようになりました．\ne-Statには，便利なAPI機能も提供されています（利用ガイドはこちら．あらかじめ利用規約を確認してください．API機能を利用する際は，事前にユーザ登録を行ってください）．\nこの記事では，Rのjpstatパッケージを使って，e-Stat APIを効率的に用いる方法を紹介します．"
  },
  {
    "objectID": "posts/call-e-stat-api-in-r/call-e-stat-api-in-r.html#e-statについて",
    "href": "posts/call-e-stat-api-in-r/call-e-stat-api-in-r.html#e-statについて",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "e-Statについて",
    "text": "e-Statについて\ne-Statには，様々な政府統計のデータベースが整理されていますが，ここでは，2015年国民健康・栄養調査の調査結果から睡眠時間に関するデータベースを見てみましょう．\nデータベースを開くと以下のように統計表が表示され，右上の「ダウンロード」ボタンからデータをダウンロードすることができます．\n\n\n\ne-Statデータベース：統計表表示画面\n\n\n画面左上の「表示項目選択」ボタンをクリックすると，表示するデータの項目（年齢階級・性別など）を選択することができます．\n\n\n\ne-Statデータベース：表示項目選択画面\n\n\nたとえば，年齢階級を選択したい場合は，年齢階級の「項目を選択」ボタンをクリックすると以下のような画面で年齢階級を選択することができます．\n\n\n\ne-Statデータベース：表示項目の設定画面\n\n\n表示項目を選択した後に，「ダウンロード」ボタンをクリックすると，選択した項目のデータのみをダウンロードすることができます．\nこのように，e-Statでは，簡単にデータを抽出・ダウンロードすることができます．しかし，データ取得作業の再現性を高めたり，プログラムを用いたデータ抽出・取得の効率化を行ったりしたい場合は，e-Stat APIを用いるのがおすすめです．"
  },
  {
    "objectID": "posts/call-e-stat-api-in-r/call-e-stat-api-in-r.html#jpstatパッケージでe-stat-apiを使う",
    "href": "posts/call-e-stat-api-in-r/call-e-stat-api-in-r.html#jpstatパッケージでe-stat-apiを使う",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "jpstatパッケージでe-Stat APIを使う",
    "text": "jpstatパッケージでe-Stat APIを使う\n上で説明したe-Statでのデータの抽出・ダウンロードをe-Stat APIで行うためには，以下のようなステップを踏む必要があります．\n\nメタ情報取得・パラメータ設定：表示項目データを取得・選択，選択項目に対応するAPIパラメータを設定\n統計データ取得：選択したデータを取得・表データに整形する\n\njpstatパッケージは，これらの一連の作業をR上で効率的に行うため開発されたものです1．jpstatパッケージは，CRANからインストールすることができます．\nここでは，男女・年齢階級別の睡眠時間をグラフ化することを目標として，さきほど取り上げた睡眠時間に関するデータベース（2015年）からデータを取得してみましょう．まず，必要なパッケージを読み込みます．\n\ninstall.packages(\"jpstat\")\n\n\nlibrary(tidyverse)\nlibrary(jpstat)\n\n\n\n\n\nステップ1：メタ情報（表示項目）を表示・抽出する\ne-Stat APIを用いるためには，事前にユーザ登録を行い，appId と呼ばれるアプリケーションIDを取得する必要があります2．\nestat() 関数に，appId とデータベースのURL（または統計表ID：statsDataId）を入力することでメタ情報（表示項目）を取得することができます3．\nはじめに，メタ情報のうち「年齢階級（cat01）」のデータを見てみましょう（cat01はAPI上での分類名です）．activate() 関数によりメタ情報を表示することができます．さらに，filter() 関数により項目を選択することができます．ここでは，年齢階級別データのみが必要であるため，「総数」データを削除します4．\nパイプ演算子|> を使うことで，以下のように，cat01以外のメタ情報のデータ抽出を続けて行うことができます．ここでは，男女・年齢階級・睡眠時間別の回答者数データを抽出しています．\n\n# ご自身のappIdに置き換えてください\nappId <- \"Your appId\"\n\n\nestat_sleeptime_2015 <- estat(appId, \"https://www.e-stat.go.jp/dbview?sid=0003224282\")\n\n\n# メタ情報の閲覧・選択\nestat_sleeptime_2015 |> \n  activate(cat01) |> \n  filter(name != \"総数\")\n\n# ☐ tab:   表章項目     [2] <code, name, level, unit>\n# ☒ cat01: 年齢階級     [6] <code, name, level, parentCode>\n# ☐ cat02: 睡眠の質     [8] <code, name, level, parentCode>\n# ☐ cat03: 性別         [3] <code, name, level, parentCode>\n# ☐ cat04: 平均睡眠時間 [6] <code, name, level, parentCode>\n# ☐ time:  時間軸(年次) [1] <code, name, level>\n# \n# A tibble: 6 × 4\n  code  name      level parentCode\n  <chr> <chr>     <chr> <chr>     \n1 160   20歳-29歳 2     100       \n2 170   30歳-39歳 2     100       \n3 180   40歳-49歳 2     100       \n4 190   50歳-59歳 2     100       \n5 210   60歳-69歳 2     100       \n6 220   70歳以上  2     100       \n\n\n\nestat_sleeptime_2015_filtered <- estat_sleeptime_2015 |> \n  \n  # 表章項目\n  activate(tab) |> \n  filter(name == \"人数\") |> \n  \n  # 年齢階級\n  activate(cat01) |> \n  filter(name != \"総数\") |> \n  \n  # 睡眠の質\n  activate(cat02) |> \n  filter(name == \"総数\") |> \n  \n  # 性別\n  activate(cat03) |> \n  filter(name %in% c(\"男性\", \"女性\"))\n\n\n\nステップ2：統計データを取得（ダウンロード）する\nデータの抽出後にcollect() を適用することで統計データを取得することができます．また，collect()のn引数で，取得するデータの列を名付けることができます．ここでは，\"person\"と名付けます．\n取得したデータdata_sleeptime_2015を見ると，（たくさんの列が存在する）分析しづらいデータになっていることがわかります．ステップαで，データ取得とデータ整形を同時に行う方法について説明します．\n\ndata_sleeptime_2015 <- estat_sleeptime_2015_filtered |> \n  \n  # データ取得・数値に変換\n  collect(n = \"person\") |> \n  mutate(person = parse_number(person))\n\nThe total number of data is 72.\n\nknitr::kable(head(data_sleeptime_2015, 10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntab_code\ntab_name\ntab_level\ntab_unit\ncat01_code\ncat01_name\ncat01_level\ncat01_parentCode\ncat02_code\ncat02_name\ncat02_level\ncat02_parentCode\ncat03_code\ncat03_name\ncat03_level\ncat03_parentCode\ncat04_code\ncat04_name\ncat04_level\ncat04_parentCode\ntime_code\ntime_name\ntime_level\nperson\n\n\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n110\n５時間未満\n2\n100\n2015000000\n2015年\n1\n23\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n120\n５時間以上６時間未満\n2\n100\n2015000000\n2015年\n1\n86\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n130\n６時間以上７時間未満\n2\n100\n2015000000\n2015年\n1\n88\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n140\n７時間以上８時間未満\n2\n100\n2015000000\n2015年\n1\n37\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n150\n８時間以上９時間未満\n2\n100\n2015000000\n2015年\n1\n19\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n110\n男性\n2\n100\n160\n９時間以上\n2\n100\n2015000000\n2015年\n1\n3\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n120\n女性\n2\n100\n110\n５時間未満\n2\n100\n2015000000\n2015年\n1\n28\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n120\n女性\n2\n100\n120\n５時間以上６時間未満\n2\n100\n2015000000\n2015年\n1\n106\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n120\n女性\n2\n100\n130\n６時間以上７時間未満\n2\n100\n2015000000\n2015年\n1\n94\n\n\n100\n人数\n\n人\n160\n20歳-29歳\n2\n100\n100\n総数\n1\nNA\n120\n女性\n2\n100\n140\n７時間以上８時間未満\n2\n100\n2015000000\n2015年\n1\n55\n\n\n\n\n\n\n\nステップα：データ取得とデータ整形を同時に行う\njpstatでe-Statのデータを取得すると，パラメータ名（cat01など）と各項目の列名（code， nameなど）から列（cat01_code，cat01_nameなど）が作成されます．\njpstatでは，rekey() 関数によりパラメータ名を変更したり，select() 関数で項目別に列を選択したりすることでデータを整理することができます5．以下のように書くことで，すっきりとしたデータを作成することができます．\n\ndata_sleeptime_2015 <- estat_sleeptime_2015 |> \n  activate(tab) |> \n  filter(name == \"人数\") |> \n  select() |> \n  \n  activate(cat01) |> \n  rekey(\"ageclass\") |> \n  filter(name != \"総数\") |> \n  select(name) |> \n  \n  activate(cat02) |> \n  filter(name == \"総数\") |> \n  select() |> \n  \n  activate(cat03) |> \n  rekey(\"sex\") |> \n  filter(name %in% c(\"男性\", \"女性\")) |> \n  select(name) |> \n  \n  activate(cat04) |> \n  rekey(\"sleeptime\") |> \n  select(name) |> \n  \n  activate(time) |> \n  select() |> \n  \n  collect(n = \"person\") |> \n  mutate(person = parse_number(person))\n\nThe total number of data is 72.\n\nknitr::kable(head(data_sleeptime_2015, 10))\n\n\n\n\nageclass_name\nsex_name\nsleeptime_name\nperson\n\n\n\n\n20歳-29歳\n男性\n５時間未満\n23\n\n\n20歳-29歳\n男性\n５時間以上６時間未満\n86\n\n\n20歳-29歳\n男性\n６時間以上７時間未満\n88\n\n\n20歳-29歳\n男性\n７時間以上８時間未満\n37\n\n\n20歳-29歳\n男性\n８時間以上９時間未満\n19\n\n\n20歳-29歳\n男性\n９時間以上\n3\n\n\n20歳-29歳\n女性\n５時間未満\n28\n\n\n20歳-29歳\n女性\n５時間以上６時間未満\n106\n\n\n20歳-29歳\n女性\n６時間以上７時間未満\n94\n\n\n20歳-29歳\n女性\n７時間以上８時間未満\n55\n\n\n\n\n\n\n\nおまけ：取得したデータのグラフ化\n最後に，取得した2015年の男女・年齢階級別の睡眠時間データをグラフ化してみましょう．グラフより，男性と女性では年齢階級別の睡眠時間の傾向が異なることがわかります．\n\ndata_sleeptime_2015 |> \n  mutate(ageclass_name = as_factor(ageclass_name),\n         sex_name = as_factor(sex_name),\n         sleeptime_name = as_factor(sleeptime_name)) |> \n  group_by(ageclass_name, sex_name) |> \n  mutate(prop = person / sum(person)) |> \n  ungroup() |> \n  ggplot(aes(ageclass_name, prop,\n             fill = fct_rev(sleeptime_name))) +\n  geom_col() +\n  geom_text(aes(label = if_else(prop > 0.05,\n                                scales::label_percent(accuracy = 1)(prop),\n                                \"\")),\n            position = position_stack(vjust = 0.5)) +\n  scale_x_discrete(\"年齢階級\") +\n  scale_y_continuous(\"割合\", \n                     labels = scales::label_percent(accuracy = 1)) +\n  scale_fill_brewer(\"睡眠時間\",\n                    palette = \"Spectral\") +\n  facet_wrap(~ sex_name) +\n  guides(x = guide_axis(n.dodge = 2))"
  },
  {
    "objectID": "posts/call-e-stat-api-in-r/call-e-stat-api-in-r.html#まとめ",
    "href": "posts/call-e-stat-api-in-r/call-e-stat-api-in-r.html#まとめ",
    "title": "Rで日本の統計データを効率的に取得しよう（e-Stat APIとjpstatパッケージで）",
    "section": "まとめ",
    "text": "まとめ\n本記事では，e-Stat APIとjpstatパッケージで日本の統計データを効率的に取得する方法について紹介しました．\nRで統計データを取得することで，作業の再現性や効率性を高めることができます．また，jpstatパッケージを使うことで，データ取得とデータ整形を同時に行うことができるため便利です．みなさんもぜひ使ってみてください．"
  },
  {
    "objectID": "posts/create-an-animation-of-a-population-pyramid-in-r/create-an-animation-of-a-population-pyramid-in-r.html",
    "href": "posts/create-an-animation-of-a-population-pyramid-in-r/create-an-animation-of-a-population-pyramid-in-r.html",
    "title": "Rで人口ピラミッドのアニメーションを作る",
    "section": "",
    "text": "国立社会保障・人口問題研究所（社人研）の公開している人口ピラミッドの推移アニメーションを参考に，以下のようなアニメーションをRのggplot2で作成してみました．"
  },
  {
    "objectID": "posts/create-an-animation-of-a-population-pyramid-in-r/create-an-animation-of-a-population-pyramid-in-r.html#国勢調査の時系列データの取得",
    "href": "posts/create-an-animation-of-a-population-pyramid-in-r/create-an-animation-of-a-population-pyramid-in-r.html#国勢調査の時系列データの取得",
    "title": "Rで人口ピラミッドのアニメーションを作る",
    "section": "国勢調査の時系列データの取得",
    "text": "国勢調査の時系列データの取得\nまず，e-Statで公開されている国勢調査の男女・5最階級別人口の時系列データをRのjpstatパッケージを用いて取得します．\njpstatパッケージからe-Stat APIを用いるためには，アプリケーションID（appId）を取得する必要があります．\n\nlibrary(tidyverse)\nlibrary(jpstat)\n\n\n\n\n\nappId <- \"Your e-Stat appId\"\n\n\ncensus <- estat(appId, \"https://www.e-stat.go.jp/dbview?sid=0003410380\")\n\npop <- census |> \n  activate(tab) |> \n  filter(name == \"人口\") |> \n  select() |> \n  \n  # 性別の抽出\n  activate(cat01) |> \n  rekey(\"sex\") |> \n  filter(name %in% c(\"男\", \"女\")) |> \n  select(name) |> \n  \n  # 年齢階級の抽出\n  activate(cat02) |> \n  rekey(\"ageclass\") |> \n  filter(str_detect(name, \"^\\\\d+～\\\\d+歳$\") |\n           name == \"85歳以上\" |\n           name == \"110歳以上\") |> \n  select(name) |> \n  \n  # 年の抽出\n  activate(time) |> \n  rekey(\"year\") |> \n  filter(str_detect(name, \"^\\\\d+年$\")) |> \n  select(name) |> \n  \n  # e-Statデータの取得\n  collect(n = \"pop\") |> \n  \n  rename_with(~ .x |> \n                str_remove(\"_name$\")) |> \n  mutate(sex = as_factor(sex),\n         year = parse_number(year),\n         \n         # 各年齢階級の最低年齢を取得\n         age_from = ageclass |> \n           str_extract(\"^\\\\d+\") |> \n           stringi::stri_trans_nfkc() |> \n           as.integer(),\n         \n         # 最高の年齢階級を「85歳以上」とする\n         ageclass = case_when(age_from >= 85 ~ \"85歳以上\",\n                              TRUE ~ ageclass) |> \n           as_factor(),\n         \n         # 年齢層を追加\n         agegroup = case_when(between(age_from, 0, 10) ~ \"年少人口\",\n                              between(age_from, 15, 60) ~ \"生産年齢人口\",\n                              between(age_from, 65, 70) ~ \"前期老年人口\",\n                              age_from >= 75 ~ \"後期老年人口\") |> \n           as_factor(),\n         pop = parse_number(pop)) |> \n  \n  # 「85歳以上」人口を集計\n  group_by(year, sex, ageclass, agegroup) |> \n  summarise(pop = sum(pop),\n            .groups = \"drop\")\n\nThe total number of data is 796.\n\nknitr::kable(head(pop))\n\n\n\n\nyear\nsex\nageclass\nagegroup\npop\n\n\n\n\n1920\n男\n０～４歳\n年少人口\n3752627\n\n\n1920\n男\n５～９歳\n年少人口\n3467156\n\n\n1920\n男\n10～14歳\n年少人口\n3089225\n\n\n1920\n男\n15～19歳\n生産年齢人口\n2749022\n\n\n1920\n男\n20～24歳\n生産年齢人口\n2316479\n\n\n1920\n男\n25～29歳\n生産年齢人口\n2008005"
  },
  {
    "objectID": "posts/create-an-animation-of-a-population-pyramid-in-r/create-an-animation-of-a-population-pyramid-in-r.html#人口ピラミッドアニメーションの作成",
    "href": "posts/create-an-animation-of-a-population-pyramid-in-r/create-an-animation-of-a-population-pyramid-in-r.html#人口ピラミッドアニメーションの作成",
    "title": "Rで人口ピラミッドのアニメーションを作る",
    "section": "人口ピラミッドアニメーションの作成",
    "text": "人口ピラミッドアニメーションの作成\nRのgganimateパッケージを用いることでggplot2のグラフをアニメーションにすることができます．\n\nlibrary(gganimate)\n\n# macOSで作成\nfamily <- \"HiraKakuProN-W3\"\ntheme_set(theme_light(base_family = family))\n\n# 年齢層を表示するためのデータ\nagegroup <- pop |> \n  group_by(sex, agegroup) |>\n  summarise(ageclass = mean(as.integer(ageclass)),\n            .groups = \"drop\") |> \n  mutate(hjust = case_when(sex == \"男\" ~ 1.25,\n                           sex == \"女\" ~ -0.25))\n\npoppyramid <- pop |> \n  \n  # 人口ピラミッドを作成するため男性人口をマイナスに変換\n  mutate(pop = if_else(sex == \"男\",\n                       -pop,\n                       pop)) |> \n  \n  ggplot(aes(ageclass, pop,\n             group = sex,\n             fill = agegroup)) +\n  geom_col(show.legend = FALSE) +\n  geom_text(data = agegroup,\n            aes(label = agegroup,\n                hjust = hjust),\n            y = 0,\n            family = family) +\n  scale_x_discrete(NULL) +\n  scale_y_continuous(\"人口［千人］\",\n                     \n                     # ラベルを絶対値・千人単位に変換\n                     labels = purrr::compose(scales::label_comma(scale = 1e-3), abs)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  coord_flip() +\n  facet_wrap(~ sex,\n             scales = \"free_x\") +\n  labs(title = \"{frame_time %/% 5 * 5}年\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  \n  # アニメーションに変換\n  transition_time(year)\n\n# 幅・高さを変更\nanimate(poppyramid, \n        width = 800,\n        height = 600,\n        res = 150,\n        renderer = gifski_renderer())"
  },
  {
    "objectID": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html",
    "href": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html",
    "title": "🗾Rで日本地図を描いてみよう",
    "section": "",
    "text": "Rでは，ggplot2などのパッケージを利用するだけで，きれいな日本地図（都道府県別）を描くことができます．\nここでは，日本地図をggplot2で描画する方法をいくつか紹介します．"
  },
  {
    "objectID": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#地図描画用のサンプルデータ",
    "href": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#地図描画用のサンプルデータ",
    "title": "🗾Rで日本地図を描いてみよう",
    "section": "地図描画用のサンプルデータ",
    "text": "地図描画用のサンプルデータ\nここでは，こちらからダウンロードできる社会・人口統計体系の2015年の都道府県別外国人人口比率データ（10万人あたり外国人人口）を地図描画用のサンプルデータとしました．\n\nlibrary(tidyverse)\n\nデータのダウンロード\n\n\nコード\nlibrary(jpstat)\nlibrary(arrow)\n\nappId <- keyring::key_get(\"estat-api\")\nforeigner_ratio_2015 <- estat(appId, \"https://www.e-stat.go.jp/en/dbview?sid=0000010201\",\n                              lang = \"E\")\nforeigner_ratio_2015 <- foreigner_ratio_2015 |> \n  activate(tab) |> \n  select() |> \n  \n  activate(cat01) |> \n  # Ratio of population of foreigners (per 100,000 persons)\n  filter(code == \"#A01601\") |> \n  select() |> \n  \n  activate(area) |> \n  filter(name != \"All Japan\") |> \n  select(code, name) |> \n  rekey(\"pref\") |> \n  \n  activate(time) |> \n  filter(name == \"2015\") |> \n  select()\nforeigner_ratio_2015 <- foreigner_ratio_2015 |> \n  collect(\"foreigners_per_100K\")\n\nwrite_parquet(foreigner_ratio_2015, \"foreigner_ratio_2015.parquet\")\n\n\nデータの読み込み\n\n\nコード\nlibrary(arrow)\n\nforeigner_ratio_2015 <- read_parquet(\"foreigner_ratio_2015.parquet\") |> \n  mutate(pref_code = pref_code |> \n           str_extract(\"^\\\\d{2}\") |> \n           parse_integer(),\n         \n         pref_name = pref_name |> \n           str_remove(\"-.+$\"),\n         pref_name = case_when(pref_name == \"Gumma\" ~ \"Gunma\",\n                               TRUE ~ pref_name),\n         \n         foreigner_ratio = parse_number(foreigners_per_100K) / 1e5,\n         .keep = \"unused\")\n\n\n\nforeigner_ratio_2015\n\n# A tibble: 47 × 3\n   pref_code pref_name foreigner_ratio\n       <int> <chr>               <dbl>\n 1         1 Hokkaido          0.00403\n 2         2 Aomori            0.00264\n 3         3 Iwate             0.00392\n 4         4 Miyagi            0.00599\n 5         5 Akita             0.00285\n 6         6 Yamagata          0.00490\n 7         7 Fukushima         0.00456\n 8         8 Ibaraki           0.0142 \n 9         9 Tochigi           0.0134 \n10        10 Gunma             0.0188 \n# … with 37 more rows"
  },
  {
    "objectID": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#geom_map-を使って日本地図を描く",
    "href": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#geom_map-を使って日本地図を描く",
    "title": "🗾Rで日本地図を描いてみよう",
    "section": "geom_map() を使って日本地図を描く",
    "text": "geom_map() を使って日本地図を描く\nggplot2では，map_data() やgeom_map() を使うことで，世界の国々を描画することができます．これには，mapsパッケージを予めダウンロードする必要があります．また，日本地図を利用するには，mapsパッケージに加えて，mapdataパッケージが必要になります．\nmap_data(\"japan\") とすることで，mapsパッケージの地図データがデータフレームに変換されます．このデータフレームのregion 列が都道府県のIDとなるため，aes(map_id = region)を設定した上で，geom_map() することで，描画したいデータのregion 列と都道府県ジオメトリがリンクします．\nただし，map_data(\"japan\") は，以下の点に注意が必要です．\n\nregion 列はすべてアルファベット表記である\n他の都道府県と違い，奈良県だけががNARA と大文字表記になっているなど，元データに問題あり\n\nここでは，str_to_title()で修正\n\n\nまた，日本地図全体を表示するためには，expand_limits() などで軸を設定すること必要になります．\n\n# pak::pak(\"maps\")\n# pak::pak(\"mapdata\")\nlibrary(tidyverse)\nlibrary(mapdata)\n\nmap_data_japan <- map_data(\"japan\") |> \n  as_tibble() |> \n  mutate(region = str_to_title(region))\nmap_data_japan\n\n# A tibble: 46,975 × 6\n    long   lat group order region   subregion\n   <dbl> <dbl> <dbl> <int> <chr>    <chr>    \n 1  140.  42.3     1     1 Hokkaido <NA>     \n 2  140.  42.3     1     2 Hokkaido <NA>     \n 3  140.  42.3     1     3 Hokkaido <NA>     \n 4  140.  42.3     1     4 Hokkaido <NA>     \n 5  140.  42.3     1     5 Hokkaido <NA>     \n 6  140.  42.3     1     6 Hokkaido <NA>     \n 7  140.  42.3     1     7 Hokkaido <NA>     \n 8  140.  42.3     1     8 Hokkaido <NA>     \n 9  140.  42.3     1     9 Hokkaido <NA>     \n10  140.  42.3     1    10 Hokkaido <NA>     \n# … with 46,965 more rows\n\nggplot(foreigner_ratio_2015 |> \n         rename(region = pref_name),\n       aes(map_id = region)) +\n  geom_map(aes(fill = foreigner_ratio),\n           map = map_data_japan) +\n  expand_limits(x = map_data_japan$long,\n                y = map_data_japan$lat) +\n  scale_fill_viridis_c(\"外国人人口比率\",\n                       limits = c(0, 0.03),\n                       labels = scales::label_percent(),\n                       option = \"turbo\")"
  },
  {
    "objectID": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#sfパッケージを使って日本地図を描く",
    "href": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#sfパッケージを使って日本地図を描く",
    "title": "🗾Rで日本地図を描いてみよう",
    "section": "sfパッケージを使って日本地図を描く",
    "text": "sfパッケージを使って日本地図を描く\n最近では，sfパッケージのジオメトリがggplot2で簡単に描画できるようになっています．\nまた，maps・mapdataパッケージの提供する地図データは，sfパッケージのst_as_sf() でsfのジオメトリデータに変換することができます．\n日本地図データをsfに変換することで，先ほどよりも直感的に地図を描くことができます．\n\nlibrary(sf)\n\nLinking to GEOS 3.9.1, GDAL 3.3.2, PROJ 7.2.1; sf_use_s2() is TRUE\n\nmap_japan <- maps::map(\"japan\", \n                       plot = FALSE,\n                       fill = TRUE) |> \n  st_as_sf() |> \n  rename(pref_name = ID) |> \n  mutate(pref_name = str_to_title(pref_name))\n\nmap_japan |> \n  left_join(foreigner_ratio_2015,\n            by = \"pref_name\") |> \n  ggplot(aes(fill = foreigner_ratio)) +\n  geom_sf(color = \"transparent\") +\n  scale_fill_viridis_c(\"外国人人口比率\",\n                       limits = c(0, 0.03),\n                       labels = scales::label_percent(),\n                       option = \"turbo\")"
  },
  {
    "objectID": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#もっと簡単に日本地図を描く",
    "href": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#もっと簡単に日本地図を描く",
    "title": "🗾Rで日本地図を描いてみよう",
    "section": "もっと簡単に日本地図を描く",
    "text": "もっと簡単に日本地図を描く\njpmapは，ggplot2による日本地図の描画をより簡単にするためのパッケージです．\njpmapは，以下の2つの機能を持ちます．\n\n日本語の都道府県名や都道府県コードが含む都道府県データを提供（jpmap::prefecture）\n琉球諸島・小笠原諸島を再配置したレイアウトを可能に（jpmap::layout_islands()）\n\njpmap::layout_islands() で地図のレイアウトを変更することで，都道府県ごとの傾向がよりわかりやすくなります．\n\n# pak::pak(\"UchidaMizuki/jpmap\")\njpmap::prefecture\n\nSimple feature collection with 47 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 122.935 ymin: 24.0433 xmax: 148.8678 ymax: 45.5386\nGeodetic CRS:  WGS 84\n# A tibble: 47 × 4\n   pref_code pref_name pref_name_ja                                         geom\n       <int> <chr>     <chr>                                  <MULTIPOLYGON [°]>\n 1         1 Hokkaido  北海道       (((145.2498 43.6126, 145.1639 43.6385, 145.…\n 2         2 Aomori    青森県       (((139.8692 40.5863, 139.8745 40.5802, 139.…\n 3         3 Iwate     岩手県       (((140.6595 39.3864, 140.6785 39.3829, 140.…\n 4         4 Miyagi    宮城県       (((141.0347 38.2792, 141.0384 38.2868, 141.…\n 5         5 Akita     秋田県       (((139.8725 39.1156, 139.9496 39.1106, 139.…\n 6         6 Yamagata  山形県       (((139.5506 38.5498, 139.5527 38.5508, 139.…\n 7         7 Fukushima 福島県       (((139.208 37.1909, 139.2164 37.1969, 139.2…\n 8         8 Ibaraki   茨城県       (((139.6911 36.1965, 139.6988 36.1541, 139.…\n 9         9 Tochigi   栃木県       (((139.3358 36.6239, 139.3489 36.6227, 139.…\n10        10 Gunma     群馬県       (((138.4448 36.4195, 138.4606 36.4156, 138.…\n# … with 37 more rows\n\nplot <- jpmap::prefecture |> \n  left_join(foreigner_ratio_2015,\n            by = c(\"pref_code\", \"pref_name\")) |> \n  ggplot(aes(fill = foreigner_ratio)) +\n  geom_sf(color = \"transparent\") +\n  scale_fill_viridis_c(\"外国人人口比率\",\n                       limits = c(0, 0.03),\n                       labels = scales::label_percent(),\n                       option = \"turbo\")\n\njpmap::layout_islands(plot,\n                      ogasawara = FALSE)"
  },
  {
    "objectID": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#まとめ地図からわかったこと",
    "href": "posts/draw-a-map-of-japan-in-r-ja/draw-a-map-of-japan-in-r-ja.html#まとめ地図からわかったこと",
    "title": "🗾Rで日本地図を描いてみよう",
    "section": "まとめ（地図からわかったこと）",
    "text": "まとめ（地図からわかったこと）\n2015年の都道府県別外国人人口比率に関する日本地図から以下のことがわかりました．\n\n2015年ではどの都道府県でも外国人人口比率が3％以下である\n東京都は外国人人口比率が最も多く，愛知県や群馬県なども外国人口比率が高い．\n\nここまで，ggplot2などのパッケージを活用した日本地図の描画を試してみました．\nその結果，Rを使えば，自前でデータを整備しなくても，簡単に日本地図を描けることがわかりました．みなさんもぜひ，ggplot2を使って，色々な地図を使ってみてください！"
  },
  {
    "objectID": "posts/grid-square-stats-in-r-ja/grid-square-stats-in-r-ja.html",
    "href": "posts/grid-square-stats-in-r-ja/grid-square-stats-in-r-ja.html",
    "title": "🗾Rで地域メッシュ統計（jpgridパッケージ）",
    "section": "",
    "text": "地域メッシュ（Grid Squares）とは「緯度・経度に基づいて日本の国土をほぼ正方形の区画に分割したもの」で，約80 km四方～約100 m四方など様々な大きさのメッシュに対してそれぞれメッシュコードが割り振られています．\nこれらのメッシュコードに統計データを対応させたデータは地域メッシュ統計と呼ばれています．\nここでは，地域メッシュを扱うためのRパッケージであるjpgridのサンプルコードを紹介します．\n使用したサンプルデータは，こちらからダウンロードできます．"
  },
  {
    "objectID": "posts/grid-square-stats-in-r-ja/grid-square-stats-in-r-ja.html#東京の主要駅周辺のメッシュ人口",
    "href": "posts/grid-square-stats-in-r-ja/grid-square-stats-in-r-ja.html#東京の主要駅周辺のメッシュ人口",
    "title": "🗾Rで地域メッシュ統計（jpgridパッケージ）",
    "section": "東京の主要駅周辺のメッシュ人口",
    "text": "東京の主要駅周辺のメッシュ人口\n東京の主要駅周辺のメッシュ人口を図示してみましょう．ここでは，駅の位置データ（station_5339_2019.gpkg）と500 mメッシュ人口データ（pop_grid500m_5339_2015）を利用します．\n［データ出典］\n\nstation_5339_2019.gpkg：国土数値情報の2019年鉄道データより作成（80 kmメッシュ：5339のみ）\npop_grid500m_5339_2015.parquet：地図で見る統計の2015年国勢調査の4次メッシュデータより作成\n\n\n駅の位置データ\nstation_5339_2019.gpkg には東京都近辺（80 kmメッシュ：5339）の2019年の駅データが格納されています．\n\n# pak::pak(\"UchidaMizuki/jpgrid\")\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(arrow)\nlibrary(jpgrid)\n\n# crs\nWGS84 <- 4326\n\n# ggspatial\nannotation_map_tile <- function(zoomin = -1, \n                                progress = \"none\", ...) {\n  list(ggspatial::annotation_map_tile(zoomin = zoomin, \n                                      progress = progress, ...),\n       labs(caption = \"© OpenStreetMap contributors\"))\n}\n\nstation <- read_sf(\"station_5339_2019.gpkg\")\n\nggplot(station,\n       aes(color = line)) +\n  annotation_map_tile() +\n  geom_sf(show.legend = FALSE) +\n  scale_color_viridis_d(option = \"turbo\")\n\n\n\n\n\n\n東京主要駅の500 mメッシュ駅勢圏の作成\n東京の主要駅である新宿駅・渋谷駅・池袋駅・東京駅の4つの駅に対して，500 mメッシュで駅勢圏を作成してみます．ここでは，駅の代表点から約1.5 kmを駅勢圏とします．\njpgridでは，geometry_to_grid() でsfパッケージのジオメトリをメッシュコードに変換することができます．また，逆に，grid_as_sf() でメッシュコードを持つデータフレームをsfパッケージのジオメトリデータに変換することもできます．\n\n# 駅勢圏の距離\ndist_station <- units::set_units(1.5, km)\n\n# 主要駅の代表点を中心とする駅勢圏ジオメトリ\nstation_main <- station |>\n  filter(station %in% c(\"新宿\", \"渋谷\", \"池袋\", \"東京\")) |>\n  group_by(station = as_factor(station)) |>\n  summarise(.groups = \"drop\") |>\n  \n  # 重心点を作成\n  st_centroid() |>\n  \n  # 重心点を中心とする円を作成\n  st_buffer(dist_station)\n\n# 駅勢圏の500 mメッシュデータ\nstation_main_grid500m <- station_main |>\n  mutate(grid500m = geom |>\n           \n           # sfジオメトリ -> 500 mメッシュ\n           geometry_to_grid(\"500m\")) |>\n  st_drop_geometry() |>\n  unnest(grid500m) |>\n  \n  # 500 mメッシュ -> sfジオメトリ\n  grid_as_sf(crs = WGS84)\n\nggplot(station_main,\n       aes(fill = station,\n           label = station)) +\n  annotation_map_tile() +\n  geom_sf(data = station_main_grid500m,\n          alpha = 0.5) +\n  geom_sf(fill = \"transparent\",\n          linetype = \"dashed\") +\n  geom_sf_text() +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/grid-square-stats-in-r-ja/grid-square-stats-in-r-ja.html#東京主要駅の駅勢圏におけるメッシュ人口",
    "href": "posts/grid-square-stats-in-r-ja/grid-square-stats-in-r-ja.html#東京主要駅の駅勢圏におけるメッシュ人口",
    "title": "🗾Rで地域メッシュ統計（jpgridパッケージ）",
    "section": "東京主要駅の駅勢圏におけるメッシュ人口",
    "text": "東京主要駅の駅勢圏におけるメッシュ人口\n東京の主要駅の駅勢圏における2015年のメッシュ人口（pop_grid500m_5339_2015.parquet）を図示してみます．grid_500m() などの関数を用いることで文字列のメッシュコード（\"533900054\"など）をjpgridのメッシュコードに変換できます．\nグラフより以下のことが確認できました．\n\n4つの駅の駅勢圏人口は池袋駅で最も多く東京駅で最も少ない\n駅や皇居・公園などの周辺で人口が少ないことが地図からも確認できる\n\n\n# 500 mメッシュ人口\npop_grid500m <- read_parquet(\"pop_grid500m_5339_2015.parquet\") |> \n  mutate(grid500m = grid_500m(grid500m))\n\n# 500 mメッシュ駅勢圏データに人口を付与\nstation_main_grid500m <- station_main_grid500m |> \n  left_join(pop_grid500m,\n            by = \"grid500m\") |> \n  replace_na(list(pop = 0))\n\nlimits <- c(0, max(station_main_grid500m$pop))\n\nstation_main_grid500m |> \n  group_by(station) |> \n  group_map(~ {\n    ggplot(.x,\n           aes(fill = pop)) +\n      annotation_map_tile() +\n      geom_sf(alpha = 0.5) +\n      scale_fill_viridis_c(\"人口\",\n                           limits = limits,\n                           option = \"turbo\") +\n      ggtitle(.y$station) +\n      theme(plot.title = element_text(hjust = 0.5),\n            axis.text = element_blank())\n  }) |> \n  patchwork::wrap_plots() +\n  patchwork::plot_layout(guides = \"collect\")\n\n\n\n\n\nstation_main_grid500m |> \n  st_drop_geometry() |> \n  group_by(station) |> \n  summarise(pop = sum(pop)) |> \n  ggplot(aes(station, pop)) +\n  geom_col(aes(fill = station),\n           show.legend = FALSE) +\n  geom_text(aes(label = scales::label_comma(suffix = \"人\")(pop)),\n            vjust = 2) +\n  scale_x_discrete(\"東京の主要駅\") +\n  scale_y_continuous(\"駅勢圏メッシュ人口 [千人]\",\n                     labels = scales::label_comma(scale = 1e-3)) +\n  scale_fill_brewer(palette = \"Set2\")"
  },
  {
    "objectID": "posts/grid-square-stats-in-r-ja/grid-square-stats-in-r-ja.html#まとめ",
    "href": "posts/grid-square-stats-in-r-ja/grid-square-stats-in-r-ja.html#まとめ",
    "title": "🗾Rで地域メッシュ統計（jpgridパッケージ）",
    "section": "まとめ",
    "text": "まとめ\nRパッケージのjpgridによる地域メッシュ統計のサンプルコードを紹介しました．\njpgridを使うことで，緯度経度やジオメトリのデータを簡単に地域メッシュ統計と紐づけられます．皆さんもぜひ使ってみてください．"
  },
  {
    "objectID": "posts/ioanalysis-in-r-ja/ioanalysis-in-r-ja.html",
    "href": "posts/ioanalysis-in-r-ja/ioanalysis-in-r-ja.html",
    "title": "🗾Rで産業連関分析",
    "section": "",
    "text": "産業連関分析は，経済波及効果の算出に広く用いられている分析手法です． 日本では，国や都道府県によって，約5年に1度，産業連関表と呼ばれる統計データが 作成・公開されており，産業連関分析における基礎データとなっています．\nこれまで，産業連関分析では，Excel・VBAが用いられることが多かったようです．\n一方で，近年は，Python・R・Juliaなどのプログラミング言語の普及が進んでいます． これらのプログラミング言語は以下のような特長を持っています．\nそのため今後は，産業連関分析においても，これらのプログラミング言語の利用が 進むのではないかと思われます．\nここでは，Rを用いて産業連関分析を行います． Rでは近年，tidyverseなどモダンなデータ分析を行うためのパッケージが 多く提供されており，プログラミング初心者でも習得しやすい言語であると思います．\n産業連関表として，e-Statのデータベースで公開されている日本（国）の 2013年・13部門産業連関表を用います． ここで使用するデータは， こちら からダウンロードできます．"
  },
  {
    "objectID": "posts/ioanalysis-in-r-ja/ioanalysis-in-r-ja.html#産業連関分析の基礎",
    "href": "posts/ioanalysis-in-r-ja/ioanalysis-in-r-ja.html#産業連関分析の基礎",
    "title": "🗾Rで産業連関分析",
    "section": "産業連関分析の基礎",
    "text": "産業連関分析の基礎\n産業連関分析は一般的に以下の流れに従って行われます．\n\n産業連関表の整形\n投入係数行列の算出\nレオンチェフ逆行列の算出\n経済波及効果の算出\n\nまず，産業連関分析において重要な投入係数行列・レオンチェフ逆行列・経済波及効果の算出方法について解説します．\n\n投入係数行列とは\n投入係数は，産業の「クッキングレシピ」として呼ばれており，産業\\(j\\)の生産物を1単位生産するのに必要な産業\\(i\\)の生産物の量を表すものです．具体的には，以下のように中間投入\\(x_{ij}\\)を生産額\\(X_j\\)（産出額）で割ることで算出できます．\n\\[\na_{ij}=\\frac{x_{ij}}{X_j}\n\\]\n産業連関分析では，「クッキングレシピ」に相当する投入係数\\(a_{ij}\\)に基づく生産額のバランス式（行方向）を連立方程式として解きます．そこで，以下のように，投入係数行列（通常，\\(A\\)と表される）と呼ばれる行列を作成することで，連立方程式が簡単に解けるようになります．\n\\[\nA = \\begin{pmatrix}\n  a_{11} & \\cdots & a_{1n} \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  a_{n1} & \\cdots & a_{nn} \\\\\n\\end{pmatrix}\n\\]\n\n\nレオンチェフ逆行列による経済波及効果の推計について\n生産額のバランス式（行方向）は，行列を用いて以下のように表せます．変数の意味は以下の表の通りです．\n\\[\nAX + F + E - M = X\n\\]\n\n\n\n変数\n意味\n\n\n\n\n\\(A\\)\n投入係数行列\n\n\n\\(X = (X_1, \\cdots, X_n) ^ \\top\\)\n生産額ベクトル\n\n\n\\(F = (F_1, \\cdots, F_n) ^ \\top\\)\n最終需要ベクトル\n\n\n\\(E = (E_1, \\cdots, E_n) ^ \\top\\)\n移輸出ベクトル\n\n\n\\(M = (M_1, \\cdots, M_n) ^ \\top\\)\n移輸入ベクトル\n\n\n\n経済波及効果の推計では，最終需要の変化が生産額に与える波及効果を算出します．\n特に，日本の産業連関表での経済波及効果の推計では，移輸入\\(M\\)の扱いに注意が必要です（これは，日本表の多くが競争移輸入型表と呼ばれる形式を採用しており，投入係数に移輸入分が含まれているためです）．\n最終需要による経済波及効果は，域内の生産額だけでなく域外からの移輸入を誘発すると考えられます．この効果を無視すると経済波及効果を過大評価することにつながるため，通常，投入係数から移輸入相当分を差し引くという処理が行われます．\n移輸入は域内需要におおよそ比例すると考えられるため，以下のように，移輸入係数\\(\\hat{M_i}\\)が算出できます．\n\\[\n\\hat{M_i} = \\frac{M_i}{\\sum_{j}a_{ij}X_j + F_i}\n\\]\nさらに，行列での計算に適した移輸入係数行列\\(\\hat{M}\\)が，以下のように定義されます．\n\\[\n\\hat{M} =\n\\begin{pmatrix}\n  \\hat{M_1} & & 0 \\\\\n  & \\ddots & \\\\\n  0 & & \\hat{M_n} \\\\\n\\end{pmatrix}\n\\]\n以上より，生産額のバランス式（行方向）は，移輸入係数行列\\(\\hat{M}\\)を用いて，以下のように変形されます．ただし，\\(I\\)は単位行列（対角成分が1，それ以外が0の正方行列）です．\n\\[\n\\begin{align}\n  AX + F + E - \\hat{M} (AX + F) &= X \\\\\n  (I - \\hat{M}) (AX + F) + E &= X\n\\end{align}\n\\]\n上のバランス式より，経済波及効果の算出式が，以下のように導出されます．ここで，\\(\\Delta X\\)，\\(\\Delta F\\)は，それぞれ，生産額の変化量，最終需要の変化量です．\n\\[\n\\begin{align}\n  X &= (I - \\hat{M}) (AX + F) + E \\\\\n  [I - (I - \\hat{M}) A] X &= (I - \\hat{M}) F + E \\\\\n  X &= [I - (I - \\hat{M}) A] ^ {-1} [(I - \\hat{M}) F + E] \\\\\n  \\Delta X &= [I - (I - \\hat{M}) A] ^ {-1} (I - \\hat{M}) \\Delta F\n\\end{align}\n\\]\n生産額の変化量\\(\\Delta X\\)の式の右辺の\\((I - \\hat{M}) \\Delta F\\)は，最終需要の変化量に自給率\\(I - \\hat{M}\\)を掛けた値となっています．\nまた，\\([I - (I - \\hat{M}) A] ^ {-1}\\)は，最終需要の変化による直接・間接の波及効果を表す行列であり（開放型または競争移輸入型の）レオンチェフ逆行列と呼ばれています．\n以上のように，最終需要の変化量\\(\\Delta F\\)から生産額の変化量\\(\\Delta X\\)を推計するというのが，最も一般的な産業連関分析の方法となっています．"
  },
  {
    "objectID": "posts/ioanalysis-in-r-ja/ioanalysis-in-r-ja.html#rによる産業連関分析",
    "href": "posts/ioanalysis-in-r-ja/ioanalysis-in-r-ja.html#rによる産業連関分析",
    "title": "🗾Rで産業連関分析",
    "section": "Rによる産業連関分析",
    "text": "Rによる産業連関分析\n\n産業連関表の整形\nここでは， こちら からダウンロードできる日本の2011年の3部門表（iotable_3sector_2011_wider.csv）を使用します．\nこちらの表は，以下のように，日本の2011年の13部門表より作成したもので，単位は「百万円」です．\n\n13部門の産業分類を第1次・第2次・第3次産業に集計（注：「分類不明」を第3次産業に分類）\n付加価値部門を1部門に集計\n最終需要部門を域内最終需要（finaldemand）・輸出（export）・輸入（import）の3部門に集計\n\n産業連関表のデータ形式は，e-Statのデータベースで提供されている表などを除いて， 行に投入部門（input）・列に産出部門（output）を持つ「横長データ」であることが多いと思われます．\nここでも，以下の通り，まずは横長の産業連関表データを読み込みます．\n\nlibrary(tidyverse)\n\niotable_wider <- read_csv(\"iotable_3sector_2011_wider.csv\",\n                          col_types = cols(.default = \"c\")) |> \n  \n  # input (投入) 列以外を数値に変換\n  mutate(across(!input, parse_number))\n\nknitr::kable(iotable_wider)\n\n\n\n\n\n\n\n\n\n\n\n\n\ninput\nindustry/01_primary\nindustry/02_secondary\nindustry/03_tertiary\nfinaldemand/04_finaldemand\nexport/05_export\nimport/06_import\n\n\n\n\nindustry/01_primary\n1456611\n7850628\n1373767\n3869875\n47890\n-2562809\n\n\nindustry/02_secondary\n2715710\n161897553\n62841827\n132924323\n54473273\n-71673715\n\n\nindustry/03_tertiary\n2025270\n66811645\n155796589\n352324555\n16423417\n-8921553\n\n\nvalueadded/04_valueadded\n5838371\n106619145\n364447740\nNA\nNA\nNA\n\n\n\n\n\nデータ分析においては，「横長データ」よりも，以下のような「縦長データ」のほうが， 分析しやすい場合が多くあります． ここでも，横長の産業連関表を「縦長データ」に変換します．\n\niotable <- iotable_wider |>\n  \n  # input (投入) 列を分類・名称に分割\n  separate(input, c(\"input_type\", \"input_name\"),\n           sep = \"/\") |>\n  \n  # input (投入) と同様にoutput (産出) の分類・名称列を追加し縦長データに\n  pivot_longer(!c(input_type, input_name),\n               names_to = c(\"output_type\", \"output_name\"),\n               names_sep = \"/\",\n               values_to = \"value_M\") |>\n  \n  # 数値が存在しない行を削除\n  drop_na(value_M)\n\nknitr::kable(iotable)\n\n\n\n\ninput_type\ninput_name\noutput_type\noutput_name\nvalue_M\n\n\n\n\nindustry\n01_primary\nindustry\n01_primary\n1456611\n\n\nindustry\n01_primary\nindustry\n02_secondary\n7850628\n\n\nindustry\n01_primary\nindustry\n03_tertiary\n1373767\n\n\nindustry\n01_primary\nfinaldemand\n04_finaldemand\n3869875\n\n\nindustry\n01_primary\nexport\n05_export\n47890\n\n\nindustry\n01_primary\nimport\n06_import\n-2562809\n\n\nindustry\n02_secondary\nindustry\n01_primary\n2715710\n\n\nindustry\n02_secondary\nindustry\n02_secondary\n161897553\n\n\nindustry\n02_secondary\nindustry\n03_tertiary\n62841827\n\n\nindustry\n02_secondary\nfinaldemand\n04_finaldemand\n132924323\n\n\nindustry\n02_secondary\nexport\n05_export\n54473273\n\n\nindustry\n02_secondary\nimport\n06_import\n-71673715\n\n\nindustry\n03_tertiary\nindustry\n01_primary\n2025270\n\n\nindustry\n03_tertiary\nindustry\n02_secondary\n66811645\n\n\nindustry\n03_tertiary\nindustry\n03_tertiary\n155796589\n\n\nindustry\n03_tertiary\nfinaldemand\n04_finaldemand\n352324555\n\n\nindustry\n03_tertiary\nexport\n05_export\n16423417\n\n\nindustry\n03_tertiary\nimport\n06_import\n-8921553\n\n\nvalueadded\n04_valueadded\nindustry\n01_primary\n5838371\n\n\nvalueadded\n04_valueadded\nindustry\n02_secondary\n106619145\n\n\nvalueadded\n04_valueadded\nindustry\n03_tertiary\n364447740\n\n\n\n\n\n上で構築した表データは，各行のフィルタリングなどが容易にできる一方で， 産業連関分析に用いられる行列計算などに適していません．\nそこで，表データの基本的な演算と行列計算を同時に行えるdibbleパッケージを用います． 以下のように，産業連関表をdibbleに変換します．\n\n# pak::pak(\"UchidaMizuki/dibble\")\nlibrary(dibble)\n\niotable <- iotable |>\n  dibble_by(input = c(input_type, input_name),\n            output = c(output_type, output_name),\n            \n            # \"_\"で列名を分割してinput (投入)・output (産出) 軸を設定\n            .names_sep = \"_\")\n\niotable\n\n# A dibble:   24 x 1\n# Dimensions: input [4], output [6]\n# Measures:   value_M\n   input$type $name        output$type $name            value_M\n   <chr>      <chr>        <chr>       <chr>              <dbl>\n 1 industry   01_primary   industry    01_primary       1456611\n 2 industry   01_primary   industry    02_secondary     7850628\n 3 industry   01_primary   industry    03_tertiary      1373767\n 4 industry   01_primary   finaldemand 04_finaldemand   3869875\n 5 industry   01_primary   export      05_export          47890\n 6 industry   01_primary   import      06_import       -2562809\n 7 industry   02_secondary industry    01_primary       2715710\n 8 industry   02_secondary industry    02_secondary   161897553\n 9 industry   02_secondary industry    03_tertiary     62841827\n10 industry   02_secondary finaldemand 04_finaldemand 132924323\n# … with 14 more rows\n\n\n\n\n投入係数行列の算出\n産業の「クッキングレシピ」と呼ばれる投入係数行列\\(A\\)を以下のように中間投入を生産額で割って算出します．\n注：dibbleではブロードキャストが自動で行われますが，安全のため，ブロードキャストを行う際に，警告を発するように設計されています．そのため，broadcast()でブロードキャスト後の軸名c(\"input\", \"output\")を与えて警告が出ないようにする必要があります．\n\n# 生産額\ntotal_input <- iotable |>\n  filter(output$type == \"industry\") |>\n  apply(\"output\", sum)\n\n# 中間投入\ninterindustry <- iotable |>\n  filter(input$type == \"industry\",\n         output$type == \"industry\")\n\n# 投入係数\ninputcoeff <- broadcast(interindustry / total_input,\n                        c(\"input\", \"output\"))\n\ninputcoeff\n\n# A dibble:   9\n# Dimensions: input [3], output [3]\n  input$type $name        output$type $name              .\n  <chr>      <chr>        <chr>       <chr>          <dbl>\n1 industry   01_primary   industry    01_primary   0.121  \n2 industry   01_primary   industry    02_secondary 0.0229 \n3 industry   01_primary   industry    03_tertiary  0.00235\n4 industry   02_secondary industry    01_primary   0.226  \n5 industry   02_secondary industry    02_secondary 0.472  \n6 industry   02_secondary industry    03_tertiary  0.108  \n7 industry   03_tertiary  industry    01_primary   0.168  \n8 industry   03_tertiary  industry    02_secondary 0.195  \n9 industry   03_tertiary  industry    03_tertiary  0.267  \n\n\n\n\nレオンチェフ逆行列の算出\n経済波及効果を表すレオンチェフ逆行列は以下のように，移輸入係数と投入係数を用いて算出できます．\n注：solve()で逆行列を算出すると行列の軸名が入れ替わるため注意してください．\n\n# 域内需要\nlocaldemand <- iotable |>\n  filter(input$type == \"industry\",\n         !output$type %in% c(\"export\", \"import\")) |>\n  apply(\"input\", sum)\n\n# (移) 輸入\nimport <- iotable |>\n  filter(input$type == \"industry\",\n         output$type == \"import\") |>\n  apply(\"input\", sum)\n# 符号を正に\nimport <- -import\n\n# (移) 輸入係数\nimportcoeff <- import / localdemand\n\nI <- eye(inputcoeff) # 単位行列\nM <- importcoeff     # 移輸入係数ベクトル (broadcastが行われるため行列でなくてよい)\nA <- inputcoeff      # 投入係数行列\n\n# レオンチェフ逆行列\nleontiefinv <- broadcast(I - (1 - M) * A,\n                         c(\"input\", \"output\")) |>\n  solve()\n\nleontiefinv\n\n# A dibble:   9\n# Dimensions: output [3], input [3]\n  output$type $name        input$type $name              .\n  <chr>       <chr>        <chr>      <chr>          <dbl>\n1 industry    01_primary   industry   01_primary   1.12   \n2 industry    01_primary   industry   02_secondary 0.0361 \n3 industry    01_primary   industry   03_tertiary  0.00716\n4 industry    02_secondary industry   01_primary   0.374  \n5 industry    02_secondary industry   02_secondary 1.68   \n6 industry    02_secondary industry   03_tertiary  0.197  \n7 industry    03_tertiary  industry   01_primary   0.348  \n8 industry    03_tertiary  industry   02_secondary 0.445  \n9 industry    03_tertiary  industry   03_tertiary  1.41   \n\n\n\n\n経済波及効果の算出\nこちら からダウンロードできる最終需要がそれぞれ百万円ずつ増加する（finaldemand_change_3sector.csv）ケースで経済波及効果を算出しています．\n\n# 最終需要変化量\nfinaldemand_change <- read_csv(\"finaldemand_change_3sector.csv\",\n                               col_types = cols(.default = \"c\",\n                                                value_M = \"n\")) |> \n  dibble_by(input = c(input_type, input_name),\n            .names_sep = \"_\")\n\nL <- leontiefinv         # レオンチェフ逆行列\nM <- importcoeff         # 移輸入係数\nFD <- finaldemand_change # 最終需要変化量\n\n# 経済波及効果\nspillover <- L %*% ((1 - M) * FD)\n\nspillover\n\n# A dibble:   3\n# Dimensions: output [3]\n  output$type $name            .\n  <chr>       <chr>        <dbl>\n1 industry    01_primary   0.958\n2 industry    02_secondary 1.85 \n3 industry    03_tertiary  2.03 \n\n\n\nspillover |> \n  as_tibble(n = \"value_M\") |> \n  unpack(output, \"_\") |> \n  ggplot(aes(output_name, value_M,\n             fill = output_name)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_brewer(palette = \"Set2\")"
  },
  {
    "objectID": "posts/ioanalysis-in-r-ja/ioanalysis-in-r-ja.html#まとめ",
    "href": "posts/ioanalysis-in-r-ja/ioanalysis-in-r-ja.html#まとめ",
    "title": "🗾Rで産業連関分析",
    "section": "まとめ",
    "text": "まとめ\nRを用いた産業連関分析の方法について紹介しました．\nここまでの計算を，jpioにパッケージ形式でまとめました．以下のように，ここまでの計算と同様の計算を行うことができます．\n\n# pak::pak(\"UchidaMizuki/jpio\")\n\n# 産業連関表\niotable <- read_csv(\"iotable_3sector_2011.csv\",\n                    col_types = cols(.default = \"c\",\n                                     value_M = \"n\")) |> \n  jpio::as_iotable()\n\niotable\n\n# A dibble:   24\n# Dimensions: input [4], output [6]\n   input$type $name        output$type $name                  .\n   <fct>      <chr>        <fct>       <chr>              <dbl>\n 1 industry   01_primary   industry    01_primary       1456611\n 2 industry   01_primary   industry    02_secondary     7850628\n 3 industry   01_primary   industry    03_tertiary      1373767\n 4 industry   01_primary   finaldemand 04_finaldemand   3869875\n 5 industry   01_primary   export      05_export          47890\n 6 industry   01_primary   import      06_import       -2562809\n 7 industry   02_secondary industry    01_primary       2715710\n 8 industry   02_secondary industry    02_secondary   161897553\n 9 industry   02_secondary industry    03_tertiary     62841827\n10 industry   02_secondary finaldemand 04_finaldemand 132924323\n# … with 14 more rows\n\n# 投入係数\njpio::input_coeff(iotable)\n\n# A dibble:   9\n# Dimensions: input [3], output [3]\n  input$type $name        output$type $name              .\n  <fct>      <chr>        <fct>       <chr>          <dbl>\n1 industry   01_primary   industry    01_primary   0.121  \n2 industry   01_primary   industry    02_secondary 0.0229 \n3 industry   01_primary   industry    03_tertiary  0.00235\n4 industry   02_secondary industry    01_primary   0.226  \n5 industry   02_secondary industry    02_secondary 0.472  \n6 industry   02_secondary industry    03_tertiary  0.108  \n7 industry   03_tertiary  industry    01_primary   0.168  \n8 industry   03_tertiary  industry    02_secondary 0.195  \n9 industry   03_tertiary  industry    03_tertiary  0.267  \n\n# レオンチェフ逆行列\njpio::leontief_inv(iotable)\n\n# A dibble:   9\n# Dimensions: output [3], input [3]\n  output$type $name        input$type $name              .\n  <fct>       <chr>        <fct>      <chr>          <dbl>\n1 industry    01_primary   industry   01_primary   1.12   \n2 industry    01_primary   industry   02_secondary 0.0361 \n3 industry    01_primary   industry   03_tertiary  0.00716\n4 industry    02_secondary industry   01_primary   0.374  \n5 industry    02_secondary industry   02_secondary 1.68   \n6 industry    02_secondary industry   03_tertiary  0.197  \n7 industry    03_tertiary  industry   01_primary   0.348  \n8 industry    03_tertiary  industry   02_secondary 0.445  \n9 industry    03_tertiary  industry   03_tertiary  1.41   \n\n# 経済波及効果\njpio::spillover_effect(iotable,\n                       list(`01_primary` = 1,\n                            `02_secondary` = 1,\n                            `03_tertiary` = 1))\n\n# A dibble:   3\n# Dimensions: output [3]\n  output$type $name            .\n  <fct>       <chr>        <dbl>\n1 industry    01_primary   0.958\n2 industry    02_secondary 1.85 \n3 industry    03_tertiary  2.03"
  },
  {
    "objectID": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html",
    "href": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html",
    "title": "🗾CSVの代わりにParquetを使ってみよう",
    "section": "",
    "text": "本記事では，CSVの代替として有望かつビッグデータ分析にも適しているParquetを紹介します．\nさて，データフレーム（Data Frames）は，データ分析において最も基本的なデータ構造の1つです．Rのtibble・dplyrやPythonのpandasなどのデータフレーム操作のためのパッケージを使えば，これまでExcelなどの表計算ソフトで行っていたデータ分析をさらに効率的に行うことができます．\nこのようにデータ分析ツールが充実している一方で，データの保存にはExcelなどとの互換性が高いCSVが未だに広く使われています．しかし，CSVは，必ずしもデータ分析に適したファイル形式とは言えません．そこで，CSVの代替として使われることが多くなっているParquetをCSVと比較してみましょう．"
  },
  {
    "objectID": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html#サンプルデータの準備",
    "href": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html#サンプルデータの準備",
    "title": "🗾CSVの代わりにParquetを使ってみよう",
    "section": "サンプルデータの準備",
    "text": "サンプルデータの準備\nCSVとParquetを比較するため，まずは，データ分析にありがちなサンプルデータを用意しましょう．今回は，tidyrパッケージで提供されているwho （世界保健機関（WHO）結核データ）からサンプルデータをつくります．\n近年，データ分析では，整然データ（tidy data）の概念が普及しています．tidy dataは，個々の変数が1つの列をなし，個々の観測（値）が1つの行をなすようなデータです．\nそれでは，whoは，tidy dataと言えるでしょうか？whoには，\"new_sp_m014\" ～\"newrel_f65\" といったたくさんの列が存在しますが，これらには，1列ごとに，診断結果（spやsel）・性別（mとf）・年齢階級（014や65）といった複数の変数が含まれています．そのため，who は，tidy dataでないといえます．そこで，こちらに従ってtidy dataであるwho_longerに変形します．\nデータ分析では，who よりtidy dataであるwho_longer のほうを分析が行いやすい一方で，行数はwho（約7,000行）よりwho_longer （約400,000行）のほうが約50倍多いことがわかります．そのため，tidy dataであるwho_longerのようなデータをテキストファイルであるCSVで保存すると容量が増大してしまいます．\nこのように，tidy dataはデータ分析に適している一方で，CSVのようなテキストファイルでの保存に適していないことがわかります．しかし，このようなデータ保存上の課題はParquetを使えば解決することができます．\nここで，tidy dataでないwho とtidy dataであるwho_longer を見比べてみましょう．\n\nlibrary(tidyverse)\nlibrary(fs)\n\n\n\nコード\nlevels_gender <- c(\"f\", \"m\")\nlevels_age <- c(\"014\", \"1524\", \"2534\", \"3544\", \"4554\", \"5564\", \"65\")\n\nwho_longer <- who |> \n  pivot_longer(cols = new_sp_m014:newrel_f65,\n               names_to = c(\"diagnosis\", \"gender\", \"age\"), \n               names_pattern = \"new_?(.*)_(.)(.*)\",\n               names_transform = list(gender = ~ .x |> \n                                        readr::parse_factor(levels = levels_gender),\n                                      age = ~ .x |> \n                                        readr::parse_factor(levels = levels_age,\n                                                            ordered = TRUE)),\n               values_to = \"count\")\n\n\n\n# データ整形前\nprint(who, n = 5)\n\n# A tibble: 7,240 × 60\n  country     iso2  iso3   year new_sp…¹ new_s…² new_s…³ new_s…⁴ new_s…⁵ new_s…⁶\n  <chr>       <chr> <chr> <int>    <int>   <int>   <int>   <int>   <int>   <int>\n1 Afghanistan AF    AFG    1980       NA      NA      NA      NA      NA      NA\n2 Afghanistan AF    AFG    1981       NA      NA      NA      NA      NA      NA\n3 Afghanistan AF    AFG    1982       NA      NA      NA      NA      NA      NA\n4 Afghanistan AF    AFG    1983       NA      NA      NA      NA      NA      NA\n5 Afghanistan AF    AFG    1984       NA      NA      NA      NA      NA      NA\n# … with 7,235 more rows, 50 more variables: new_sp_m65 <int>,\n#   new_sp_f014 <int>, new_sp_f1524 <int>, new_sp_f2534 <int>,\n#   new_sp_f3544 <int>, new_sp_f4554 <int>, new_sp_f5564 <int>,\n#   new_sp_f65 <int>, new_sn_m014 <int>, new_sn_m1524 <int>,\n#   new_sn_m2534 <int>, new_sn_m3544 <int>, new_sn_m4554 <int>,\n#   new_sn_m5564 <int>, new_sn_m65 <int>, new_sn_f014 <int>,\n#   new_sn_f1524 <int>, new_sn_f2534 <int>, new_sn_f3544 <int>, …\n\n# データ整形後\nprint(who_longer, n = 5)\n\n# A tibble: 405,440 × 8\n  country     iso2  iso3   year diagnosis gender age   count\n  <chr>       <chr> <chr> <int> <chr>     <fct>  <ord> <int>\n1 Afghanistan AF    AFG    1980 sp        m      014      NA\n2 Afghanistan AF    AFG    1980 sp        m      1524     NA\n3 Afghanistan AF    AFG    1980 sp        m      2534     NA\n4 Afghanistan AF    AFG    1980 sp        m      3544     NA\n5 Afghanistan AF    AFG    1980 sp        m      4554     NA\n# … with 405,435 more rows"
  },
  {
    "objectID": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html#csvparquetの保存方法",
    "href": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html#csvparquetの保存方法",
    "title": "🗾CSVの代わりにParquetを使ってみよう",
    "section": "CSV・Parquetの保存方法",
    "text": "CSV・Parquetの保存方法\nRでは，write_csv() でCSVを保存できます．同様に，arrowパッケージのwrite_parquet() でParquetを保存することができます．who_longerをCSVとParquetで保存してみましょう．\nCSVとParquetでは，どちらも簡単にデータ保存ができることがわかります．\n\nlibrary(arrow)\n\n# CSVを保存\nwrite_csv(who_longer, \"who_longer.csv\")\n\n# Parquetを保存\nwrite_parquet(who_longer, \"who_longer.parquet\")"
  },
  {
    "objectID": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html#parquetのメリットcsvとの比較",
    "href": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html#parquetのメリットcsvとの比較",
    "title": "🗾CSVの代わりにParquetを使ってみよう",
    "section": "Parquetのメリット・CSVとの比較",
    "text": "Parquetのメリット・CSVとの比較\nここからは，保存したwho_longer のCSV・Parquetファイルを比較して，CSVに対するParquetのメリットを紹介していきます．\n\nメリット1：CSVよりデータ容量が軽い\ntidy dataは行数が多くなるため，CSVでの保存に適しておらず，Parquetを使ったほうがよいことを既に述べました．\n実際に，who_longer のCSV・Parquetのデータ容量は，それぞれ，14.1 MBと154 KBとなり，ParquetはCSVの約1 %のデータ容量しかないことがわかります．\nどのようなケースでもこのようなデータ容量の削減が見込めるわけではありませんが，Parquetは列指向でデータ圧縮を行うため，Rなどでよく用いられるtidy dataの保存に適したデータ形式であるといえます．\n\n# CSV\nfile_size(\"who_longer.csv\")\n\n14.1M\n\n# Parquet\nfile_size(\"who_longer.parquet\")\n\n154K\n\nunits::set_units(file_size(\"who_longer.parquet\") / file_size(\"who_longer.csv\")) |> \n  units::set_units(`%`)\n\n1.071028 [%]\n\n\n\n\nメリット2：CSVより読み込みが簡単\nwrite_csv()・write_parquet() でデータを書き込めるのと同様に，read_csv()・read_parquet() でCSV・Parquetデータを読み込むことができます．\nCSVはテキスト形式であるため，読み込み時にcol_typesで各列の型を指定する必要があります（デフォルトでは自動で型を推測）．\n一方，Parquetは，書き込み時に各列の型情報も保存されているため読み込み時に型を指定する必要がありません．\n\n# CSVの読み込み\nread_csv(\"who_longer.csv\",\n         col_types = cols(.default = \"c\",\n                          year = \"i\",\n                          count = \"i\"))\n\n# Parquetの読み込み\nread_parquet(\"who_longer.parquet\")\n\n\n\nメリット3：CSVよりビッグデータの読み込み・集計に適している\nCSVはビッグデータの保存に適しておらず，これまでは，ビッグデータの保存にはSQLを用いるなどの使い分けが必要でした．\nRでは，dplyr（dbplyr）・DBIなどのパッケージで簡単にSQLが使えますが，データベースへの接続・切断などが必要なSQLは，CSVと使い勝手が異なり，初学者にとってはハードルがあるかもしれません．\nまた，（ほとんどの？）SQLは行指向であるため，データの追加・更新・削除などに適していますが，データ分析に用いられるデータの保存・集計には列指向であるParquetのほうが適していると思われます．\nCSVファイルを用いてビッグデータを集計する場合には，一度，全データをメモリに移す必要があります．そのため，データの読み込みでメモリが逼迫するおそれがあります．\nParquetでは，読み込み時にas_data_frame = FALSEとすることで，SQLと同様にメモリにデータを移すことなくデータのフィルタリング・集計などが可能です．\nここでは，日本の年・症例別の患者数を計算してみましょう．dplyrのfilter() ・group_by() ・summarise() などを使って効率的にクエリを作成することができます．最後にcollect() を行えばデータフレームを出力することができます．\n\nread_parquet(\"who_longer.parquet\",\n             as_data_frame = FALSE) |> \n  filter(country == \"Japan\",\n         !is.na(count)) |> \n  group_by(country, year, diagnosis) |> \n  summarise(count = sum(count),\n            .groups = \"drop\") |> \n  collect()\n\n# A tibble: 33 × 4\n   country  year diagnosis count\n   <chr>   <int> <chr>     <int>\n 1 Japan    1995 sp        14367\n 2 Japan    1996 sp        12867\n 3 Japan    1997 sp        13571\n 4 Japan    1998 sp        11935\n 5 Japan    1999 sp        12909\n 6 Japan    2000 sp        11853\n 7 Japan    2001 sp        11408\n 8 Japan    2002 sp        10807\n 9 Japan    2003 sp        10843\n10 Japan    2004 sp        10471\n# … with 23 more rows\n\n\n\n\nメリット4：複数のデータからなるデータセットを扱える\nParquetは列指向であるため，行指向であるSQLと違い，データの追加・更新・削除などに適していません．しかし，Parquetでは，複数のデータからなるデータセットの読み込みが簡単に行えるため，このようなデメリットを簡単に解決することができます．\nここでは，who_longerを年齢階級別に分割したParquetファイルを格納した\"who_longer_byage\" フォルダをデータセットのサンプルとして用いましょう．\nopen_dataset(\"who_longer_byage\") とすることで，複数のParquetファイルを含むにもかかわらず，さきほどと同様のデータ集計を簡単に行うことができます．\n\n\nコード\ndir_create(\"who_longer_byage\")\nwho_longer |> \n  group_by(age) |> \n  group_walk(~ .x |> \n               write_parquet(str_glue(\"who_longer_byage/who_longer_{.y$age}.parquet\")),\n  .keep = TRUE)\n\n\n\nopen_dataset(\"who_longer_byage\") |> \n  filter(country == \"Japan\",\n         !is.na(count)) |> \n  group_by(country, year, diagnosis) |> \n  summarise(count = sum(count),\n            .groups = \"drop\") |> \n  collect()\n\n# A tibble: 33 × 4\n   country  year diagnosis count\n   <chr>   <int> <chr>     <int>\n 1 Japan    1995 sp        14367\n 2 Japan    1996 sp        12867\n 3 Japan    1997 sp        13571\n 4 Japan    1998 sp        11935\n 5 Japan    1999 sp        12909\n 6 Japan    2000 sp        11853\n 7 Japan    2001 sp        11408\n 8 Japan    2002 sp        10807\n 9 Japan    2003 sp        10843\n10 Japan    2004 sp        10471\n# … with 23 more rows\n\n\n\n\nメリット5：R・Python間でのデータのやり取りに適している\nPythonのpandasパッケージはParquetの読み書きに対応しているため，Parquetは，R・Python間でのデータのやり取りにも適しています．\nRで作成した'who_longer.parquet' をpandasで読み込んでみましょう．\n\nimport pandas as pd\n\npd.read_parquet('who_longer.parquet')\n\n            country iso2 iso3  year diagnosis gender   age   count\n0       Afghanistan   AF  AFG  1980        sp      m   014     NaN\n1       Afghanistan   AF  AFG  1980        sp      m  1524     NaN\n2       Afghanistan   AF  AFG  1980        sp      m  2534     NaN\n3       Afghanistan   AF  AFG  1980        sp      m  3544     NaN\n4       Afghanistan   AF  AFG  1980        sp      m  4554     NaN\n...             ...  ...  ...   ...       ...    ...   ...     ...\n405435     Zimbabwe   ZW  ZWE  2013       rel      f  2534  4649.0\n405436     Zimbabwe   ZW  ZWE  2013       rel      f  3544  3526.0\n405437     Zimbabwe   ZW  ZWE  2013       rel      f  4554  1453.0\n405438     Zimbabwe   ZW  ZWE  2013       rel      f  5564   811.0\n405439     Zimbabwe   ZW  ZWE  2013       rel      f    65   725.0\n\n[405440 rows x 8 columns]"
  },
  {
    "objectID": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html#まとめ",
    "href": "posts/use-parquet-instead-of-csv-ja/use-parquet-instead-of-csv-ja.html#まとめ",
    "title": "🗾CSVの代わりにParquetを使ってみよう",
    "section": "まとめ",
    "text": "まとめ\nここまで，R・Pythonで利用可能なParquetのメリットを紹介しました．Parquetは，近年，データ分析で普及しているtidy dataの保存・集計に適しています．\nまた，最近では，地理データを扱えるsfパッケージのデータをparquetとして保存できるsfarrowなども登場しています．\nCSVの代わりにParquetを用いることでデータ分析がさらに簡単になることが期待されます．"
  }
]